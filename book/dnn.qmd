# Полносвязные нейросети 

## Пакеты и виртуальное окружение

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
library(textrecipes)
conflicted::conflict_prefer("filter", winner = "dplyr")
load("../data/movie_reviews.Rdata")
```

```{r message=FALSE, warning=FALSE}
# create environment
library(keras3)
library(tensorflow)
library(reticulate)
virtualenv_create("r-reticulate", python = "3.10")
virtualenv_install("r-reticulate", c("tensorflow", "keras"))
use_virtualenv("r-reticulate")
py_config()
```

Убедимся, что все работает.

```{r}
tf$constant("Hello TensorFlow!") 
```

## Данные

Функция `initial_validation_split()` создает случайное разделение данных на три части: обучающую (training set), валидационную (validation set) и тестовую (testing set) выборки.  Функции `training()`, `validation()` и `testing()` позволяют извлекать соответствующие подмножества данных после разбиения.

```{r}
set.seed(11032025)
data_split <- reviews |> 
  mutate(sentiment = as.factor(sentiment)) |> 
  initial_validation_split(strata = sentiment)
data_split
```

```{r}
data_train <- training(data_split)
data_validate <- validation(data_split)
data_test <- testing(data_split)
```

Разделим обучающую выборку на 5 фолдов для перекрестной проверки.

```{r}
# folds
set.seed(11032025)
folds <- vfold_cv(data_train, strata = sentiment, v = 5)
folds
```


## Препроцессинг 

```{r}
library(stopwords)
stopwords_ru <- c(
  stopwords("ru", source = "snowball"),
  stopwords("ru", source = "marimo"),
  stopwords("ru", source = "nltk"))

# уберем повторы и упорядочим по алфавиту
stopwords_ru <- sort(unique(stopwords_ru))
```

Мы начнем с того же рецепта, который использовали в прошлый раз. Каждая рецензия рассматривается как "мешок слов". Число признаков снижено за счет стемминга, удаления цифр, латинских букв, а также стопслов. Снова установим максимальное значение признаков на 1000.  

```{r}
bow_rec <- recipe( ~ review, data = data_train)  |>  
  step_mutate(review = stringr::str_remove_all(review, "\\d+")) |> 
  step_mutate(review = stringr::str_remove_all(review, "[A-Za-z]")) |> 
  step_tokenize(review) |>
  step_stopwords(review, custom_stopword_source = stopwords_ru) |>
  step_stem(review, options = list(language = "russian")) |>
  step_tokenfilter(all_predictors(), 
                   max_tokens = 1000, 
                   min_times = 2) |> 
  step_tfidf(review) |> 
  step_zv(all_predictors()) |> 
  step_normalize(all_predictors())
```

Функция `prep()` вычисляет параметры всех шагов обработки, таких как токенизация, удаление стоп-слов или преобразование в `bag-of-words`. Функция `bake()` применяет подготовленный рецепт к обучающим данным.  

```{r}
# prep and bake
bow_prep <- prep(bow_rec)

train_bow_baked <- bake(bow_prep,
                   new_data = NULL,
                   composition = "matrix")
```

```{r}
valid_bow_baked <- bake(bow_prep, 
                    new_data = data_validate,
                    composition = "matrix")
```

## Перекодирование меток

```{r}
sentiment_train <- data_train |> 
  pull(sentiment)   |> 
  as.factor()  |> 
  as.integer()
```

Функция `to_categorical()` из пакета `{keras}` используется для преобразования вектора классов (представленного в виде целых чисел) в **бинарную матрицу классов** (one-hot encoding). Функция принимает вектор целочисленных меток классов, например, `{0, 1, 2, 3}`, и преобразует его в **one-hot матрицу**, где каждый класс кодируется бинарным вектором. 

Пример:

```
     [,1] [,2] [,3]
[1,]    1    0    0  # Класс 0
[2,]    0    1    0  # Класс 1
[3,]    0    0    1  # Класс 2
[4,]    0    1    0  # Класс 1
[5,]    1    0    0  # Класс 0
```

Здесь:
- Каждая строка соответствует одному образцу.
- Каждый столбец – это конкретный класс.
- 1 стоит в позиции индекса класса, остальное – `0`.

Эта функция используется в нейронных сетях (Keras, TensorFlow), потому что выходной слой **softmax** ожидает one-hot представление меток классов.

```{r}
sentiment_train <- keras3::to_categorical(sentiment_train-1, num_classes = 3)
head(sentiment_train)
```
Теперь проделаем то же самое для валидационного набора. 

```{r}
sentiment_valid <- data_validate  |>  
  pull(sentiment)  |> 
  as.factor()  |> 
  as.integer()

sentiment_valid <- keras3::to_categorical(sentiment_valid-1, num_classes = 3)
```

# Полносвязная нейросеть

```{r}
bow_model <- keras3::keras_model_sequential() |> 
  layer_dense(units = 64, activation = "relu") |> 
  layer_dense(units = 64, activation = "relu") |> 
  layer_dense(units = 3, activation = "softmax")

bow_model
```
```{r}
bow_model  |> 
  compile(
  optimizer = "adam",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

bow_model
```
```{r}
bow_history <- bow_model |> 
  fit(
    x = train_bow_baked,
    y = sentiment_train,
    batch_size = 100,
    epochs = 20,
    validation_data = list(valid_bow_baked, sentiment_valid), 
    verbose = FALSE
  )

bow_history
```
```{r}
plot(bow_history) 
```

```{r}
bow_df <- as.data.frame(bow_history)
bow_history
```

