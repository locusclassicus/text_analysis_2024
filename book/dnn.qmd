# Глубокое обучение

## Основные понятия

В предыдущих главах мы использовали такие алгоритмы, как регуляризованные линейные модели, машины опорных векторов и наивные байесовские модели для предсказания результатов на основе признаков, включая текстовые данные. Модели **глубокого обучения** решают те же задачи и преследуют те же цели, однако используются другие алгоритмы. 

Глубокое обучение -- это особый раздел машинного обучения. Под "глубиной" в глубоком обучении не подразумевают более глубокое понимание, достигаемое этим подходом; идея заключается в многослойном представлении. Количество **слоев**, которые делится модель данных, называют глубиной модели [@chollet2023, 33].


Слои в модели глубокого обучения соединены в сеть, и такие модели называют **нейронными сетями**, хотя по сути они работают не так, как человеческий мозг. Слои могут быть соединены по-разному — такие конфигурации называют **архитектурами** сети. 

В этом уроке мы познакомимся с **полносвязной** (dense) нейронной сетью для работы с текстом. Это одна из самых простых архитектур, и обычно такая модель не показывает наилучших результатов на текстовых данных, но с неё удобно начать, чтобы понять сам процесс построения и оценки глубоких моделей для работы с текстом. Кроме того, этот тип архитектуры может быть своеобразным мостом между методами "мешка слов", которые мы использовали ранее, и более сложными подходами, позволяющими учитывать не только частотность слов, но также их последовательности.

![[Источник.](https://smltar.com/dldnn)](https://smltar.com/diagram-files/dnn-architecture.png)

На рисунке показана архитектура полносвязной прямой нейронной сети (feed-forward). Входные данные поступают в сеть сразу и полностью (в данном случае — полностью) соединены с первым **скрытым слоем**. Слой называется «скрытым», потому что не связан с внешним миром; этим занимаются только входной и выходной слои. Нейроны каждого слоя соединяются лишь со следующим слоем. Количество слоев и узлов в каждом из них может меняться; эти параметры называются **гиперпараметрами** и выбираются исследователем.

Под **обучением** сети подразумевается поиск набора значений **весов** всех слоев в сети, при котором сеть будет правильно отображать образцовые входные данные в соответствующие им результаты. Первоначально весам присваиваются случайные значения, но постепенно они корректируются в нужном направлении. "Нужным" в данном случае считается такое направление, которое минимизирует **функцию потерь**. 

![Источник: @chollet2023](images/chollet1.png)

За корректировку отвечает **оптимизатор** — это алгоритм, который управляет процессом обучения нейронной сети, корректируя веса модели с целью минимизации функции ошибки (или функции потерь). Проще говоря, оптимизатор помогает найти такие значения параметров, при которых сеть даёт наилучшие предсказания. Для этого он реализует алгоритм **обратного распространения ошибки** (backpropagation): для каждого параметра вычисляется вклад, который он вносит в значение потерь [@chollet2023, 93]. 

Этот вклад определяется с помощью **градиентов**. Градиент -- это обобщение понятия производной для функций, принимающих тензоры (многомерные массивы чисел) в качестве входных данных [@chollet2023, 83]. Градиент функции `f` -- это вектор, который указывает направление наискорейшего роста этой функции, при этом модуль градиента равен скорости изменения функции в этом направлении.

Оптимизатор обновляет веса пропорционально этим градиентам (с учетом параметра скорости обучения), что позволяет постепенно приближаться к минимуму функции потерь. **Градиентный спуск** (gradient descent) — это метод оптимизации, который использует вычисленные градиенты для обновления весов сети с целью минимизации функции потерь. Он корректирует веса в направлении, противоположном градиенту (т.е. в сторону уменьшения ошибки).


## Пакеты и виртуальное окружение

```{r message=FALSE}
library(tidyverse)
library(tidymodels)
library(textrecipes)
conflicted::conflict_prefer("filter", winner = "dplyr")
```

Для работы нам понадобится дополнительно установить и загрузить несколько пакетов. 

- Пакет keras для R предоставляет удобный интерфейс для **Keras**, высокоуровневого API для создания нейронных сетей. Keras отвечает за компоненты глубокого обучения высокого уровня: слои, функции потерь, оптимизатор, метрики, обучающий цикл. 

- Keras опирается на **Tensorflow** (доступный в R через одноименный пакет), который отвечает за низкоуровневые манипуляции с тензорами.

- Пакет `{reticulate}` позволяет запускать Python-код прямо из R. Это обеспечивает интеграцию с Keras и Tensorflow: многие современные нейросетевые пакеты в R (в том числе `{keras}` и `{tensorflow}`) — всего лишь "обёртки" над Python-библиотеками. 


```{r message=FALSE, warning=FALSE}
library(keras3)
library(tensorflow)
library(reticulate)
```

Теперь попробуем узнать, какая установлена версия Python на машине. При необходимости обновите. 

```{r eval=FALSE}
py_config()

# python:         /Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/iRJimXLaYLGeT_iEQWqHf/bin/python3
# libpython:      /Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/python/cpython-3.11.12-macos-aarch64-none/lib/libpython3.11.dylib
# pythonhome:     /Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/iRJimXLaYLGeT_iEQWqHf:/Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/iRJimXLaYLGeT_iEQWqHf
# virtualenv:     /Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/iRJimXLaYLGeT_iEQWqHf/bin/activate_this.py
# version:        3.11.12 (main, Apr  9 2025, 03:49:53) [Clang 20.1.0 ]
# numpy:          /Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/iRJimXLaYLGeT_iEQWqHf/lib/python3.11/site-packages/numpy
# numpy_version:  2.1.3
# keras:          /Users/olga/Library/Caches/org.R-project.R/R/reticulate/uv/cache/archive-v0/iRJimXLaYLGeT_iEQWqHf/lib/python3.11/site-packages/keras
# 
# NOTE: Python version was forced by py_require()
```

Убедимся, что Питон работает. Если все ок, вы увидите число `pi`.

```{r}
py_run_string("import math; result = math.pi")
py$result
```

Проверим наличие keras и tensorflow. 

```{r}
py_module_available("keras")
py_module_available("tensorflow")
```

Если хоть один из них отсутствует, устанавливаем `keras` и `tensorflow` в текущее Python-окружение. 

```{r eval=FALSE}
py_install(c("keras", "tensorflow"))
```

Если вы используете эфемерное (временное) виртуальное окружение, которое управляется `{reticulate}` автоматически, то `py_install()` выдаст предупреждение и посоветует использовать `py_require()`, чтобы корректно установить или подключить пакеты без нарушения целостности окружения.

```{r}
py_require(c("keras", "tensorflow"))
```

Это установит последние совместимые версии этих пакетов с помощью pip в вашу текущую виртуальную среду.

:::{.callout-note icon=false}
Пакет `{reticulate}` в новых версиях может создавать временные virtualenv/conda окружения, которые управляются им автоматически — они не привязаны к системному Python и исчезают при завершении сессии (если явно не сохраняются).
:::

Если вы хотите не эфемерную, а постоянную виртуальную среду, можно создать её вручную:

```{r eval=FALSE}
# Только один раз!
virtualenv_create("myenv")

# Активировать для reticulate
use_virtualenv("myenv", required = TRUE)

# Установить нужные модули
py_install(c("keras", "tensorflow"))
```

Тогда `{reticulate}` будет использовать стабильное окружение, которое сохранится между сессиями.


Убедимся, что все работает.

```{r}
py_run_string("
import tensorflow as tf
import keras

print('TensorFlow version:', tf.__version__)
print('Keras version:', keras.__version__)
")
```

Ура, победа 🎈🎉🎊

## Данные: категории новостей


```{r}
library(textdata)
ag_news <- textdata::dataset_ag_news()
ag_news
```

```{r}
ag_news |>
  count(class) |>
  mutate(class = forcats::fct_reorder(class, n)) |>
  ggplot(aes(x = class, y = n, fill = class)) +
  geom_col() +
  theme_minimal()
```

```{r}
ag_news |>
  mutate(text_length = nchar(description)) |> 
  ggplot(aes(text_length, color = class)) +
  geom_density() +
  theme_minimal()

```


## Разделение данных


Функция `initial_validation_split()` создает случайное разделение данных на три части: обучающую (training set), валидационную (validation set) и тестовую (testing set) выборки.  Функции `training()`, `validation()` и `testing()` позволяют извлекать соответствующие подмножества данных после разбиения.

```{r}
set.seed(24052025)
data_split <- ag_news |> 
  mutate(class = as.factor(class)) |> 
  initial_validation_split(strata = class)
data_split
```

```{r}
data_train <- training(data_split)
data_validate <- validation(data_split)
data_test <- testing(data_split)
```



## Препроцессинг: BOW

Мы начнем с простейшей модели типа "мешок слов". Число признаков снижено за счет стемминга, удаления цифр, а также стопслов. Установим максимальное значение признаков на 1000. Обратите внимание, что исходная формула не задаёт зависимой переменной. Это нужно для удобства преобразования в матричный формат. 

```{r}
bow_rec <- recipe( ~ description, data = data_train)  |>  
  step_mutate(description = stringr::str_remove_all(description, "\\d+")) |> 
  step_tokenize(description) |>
  step_stopwords(description) |>
  step_tokenfilter(all_predictors(), 
                   max_tokens = 1000, 
                   min_times = 2) |> 
  step_tfidf(all_predictors()) |> 
  step_zv(all_predictors()) |> 
  step_normalize(all_predictors())

bow_rec
```

Применим рецепт к обучающим данным.  В функции `bake()` аргумент `composition = "matrix"` определяет формат возвращаемого результата. По умолчанию `bake()` возвращает tibble (или data.frame), где каждая строка — это наблюдение, а столбцы — признаки. Но мы планируем отдавать признаки нейросети, а она принимает матрицы на вход. Число элементов матрицы -- 72 млн. 
 
```{r}
bow_rec_prep <- prep(bow_rec) 

train_bow_rec <- bow_rec_prep |> 
  bake(new_data = NULL,
       composition = "matrix")
```

```{r}
valid_bow_rec <- bake(bow_rec_prep, 
                    new_data = data_validate,
                    composition = "matrix")
```

## Перекодирование меток

**One-hot кодирование** меток классов — это способ представления категориальных переменных в виде бинарных векторов.

```{r}
class_train <- data_train |> 
  pull(class)   |> 
  as.factor()  |> 
  as.integer()
```

Функция `to_categorical()` из пакета `{keras}` используется для преобразования вектора классов (представленного в виде целых чисел) в бинарную матрицу классов. Функция принимает вектор целочисленных меток классов, например, `{0, 1, 2, 3}`, и преобразует его в **one-hot матрицу**, где каждый класс кодируется бинарным вектором. 

Пример:

```
     [,1] [,2] [,3]
[1,]    1    0    0  # Класс 0
[2,]    0    1    0  # Класс 1
[3,]    0    0    1  # Класс 2
[4,]    0    1    0  # Класс 1
[5,]    1    0    0  # Класс 0
```

Здесь:

- Каждая строка соответствует одному образцу.
- Каждый столбец – это конкретный класс.
- 1 стоит в позиции индекса класса, остальное – `0`.

Эта функция используется в нейронных сетях, потому что выходной слой **softmax** ожидает one-hot представление меток классов.

```{r}
class_train_onehot <- to_categorical(class_train-1, num_classes = 4)
head(class_train_onehot)
```
Теперь проделаем то же самое для валидационного набора. 

```{r}
class_valid <- data_validate  |>  
  pull(class)  |> 
  as.factor()  |> 
  as.integer()

class_valid_onehot <- to_categorical(class_valid-1, num_classes = 4)
```

```{r}
head(class_valid_onehot)
```

## Спецификация модели BOW

Создаем пустую последовательную (sequential) модель. В последовательной модели слои идут один за другим, по порядку. Добавляем к ней два полносвязных (dense) слоя. Аргументом `units = 64` указываем, что в первом и втором слое будет 64 нейрона. Число нейронов подбирается экспериментально. Наличие большей размерности (многомерное пространство представления) позволяет модели изучать более сложные представления, но делает модель более дорогостоящей в вычислительном отношении и может привести к переобучению [@chollet2023, 149].

Аргумент `activation = "relu"` означает, что скрытые слои используют *функцию активации*  relu (rectified linear unit, блок линейной ректификации). Эта функция преобразует отрицательные значения в ноль. 

> Без функции активации, такой как relu (также называемой фактором нелинейности) полносвязный слой layer_dense будет состоять из двух линейных операций -- скалярного произведения и сложения:
> output <- dot(input, W) + b
> Такой слой может обучаться только на линейных (аффинных) преобразованиях входных данных: пространство гипотез слоя было бы совокупностью всех возможных линейных преобразований входных данных в n-мерное пространство. Такое пространство гипотез слишком ограничено, и наложение нескольких уровней представлений друг на друга не приносило бы никакой выгоды, потому что сколь угодно длинная последовательность линейных преобразований все равно остается линейным преобразованием. -- [@chollet2023, 151]

После этого добавляем выходной слой. Здесь число нейронов соответствует числу предсказываемых классов, а активация softmax  (`activation = "softmax"`) превращает выходы нейронов в вероятности, сумма которых равна 1.

```{r}
bow_model <- keras3::keras_model_sequential() |> 
  layer_dense(units = 32, activation = "relu") |> 
  layer_dense(units = 32, activation = "relu") |> 
  layer_dense(units = 4, activation = "softmax")

bow_model
```

Модель готова к дальнейшему обучению и применению. Осталось выбрать функцию потерь и оптимизатор.

```{r}
bow_model  |> 
  compile(
  optimizer = "adam",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)

bow_model
```
Здесь `compile()` — функция компиляции. Она "собирает" модель для обучения: определяет, как будут считаться ошибки (функция потерь), какой алгоритм оптимизации использовать, и по каким метрикам отслеживать качество.

Оптимизатор Adam (аргумент `optimizer = "adam"`) - один из самых популярных оптимизаторов для градиентного спуска. Adam автоматически подбирает скорость обучения для каждого параметра. Работает быстро и надёжно на большинстве задач — особенно если нет времени или желания подбирать сложные параметры вручную.
  
Перекрестная энтропия (`loss = "categorical_crossentropy"`) -- функция потерь для задач многоклассовой классификации (multi-class classification). Эта функция подходит, когда на выходе модели softmax и целевая переменная — one-hot вектор.  

:::{.callout-note icon=false}
Перекрестная энтропия (crossentropy) -- это термин из области теории информации, обозначающий меру расстояния между распределениями вероятностей или, в данном случае, между фактическими данными и предсказаниями.
:::

      
Также прописываем метрику качества работы модели.


## Обучение BOW-модели

Теперь проведем обучение модели в течение 10 эпох (выполним 10 итераций по всем образцам обучающих данных) пакетами по 512 образцов. 

**Пакет (батч)** - это небольшой набор образцов, которые одновременно обрабатываются моделью.  Количество часто равно степени двойки, чтобы упростить выделение памяти на процессоре. В процессе обучения пакет используется для одного обновления градиентного спуска, применяемого к весам модели.

**Эпоха** (epoch) — это один полный проход (прогон) по всему тренировочному датасету при обучении модели машинного обучения, например, нейронной сети. Например, если у вас есть 1000 картинок, а `batch_size = 100`, то за одну эпоху модель обработает все 1000 картинок по 100 за раз — всего 10 шагов (итераций). Модель обычно обучают несколько (десятков или сотен) эпох, чтобы она постепенно улучшала свои прогнозы.

Также будем следить за потерями и точностью на отложенных образцах. 


```{r}
bow_history <- bow_model |> 
  fit(
    x = train_bow_rec,
    y = class_train_onehot,
    batch_size = 512,
    epochs = 10,
    validation_data = list(valid_bow_rec, class_valid_onehot), 
    verbose = FALSE
  )

bow_history
```


После обучения в переменной `bow_history` сохраняется история процесса обучения: метрики, ошибки, прогресс и т.д. Взглянем на результат.


```{r}
plot(bow_history) + 
  theme_minimal()
```

```{r}
bow_df <- as.data.frame(bow_history)
bow_history
```

