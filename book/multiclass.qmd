---
editor: 
  markdown: 
    wrap: 72
---

# Многоклассовая классификация

Многоклассовая классификация может использоваться для определения
автора, жанра, тематики или эмоциональной тональности текста.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(textrecipes)
library(tidymodels)
library(tidytext)
library(stylo)
```

## Подготовка данных

Исходник: <https://github.com/JoannaBy/RussianNovels> В формате zip
можно забрать
[здесь](https://github.com/locusclassicus/text_analysis_2024/raw/refs/heads/main/files/russian_corpus.zip).

```{r eval=FALSE}
corpus <- load.corpus.and.parse(corpus.dir = "../files/russian_corpus")
```

Разделим тексты на отрывки длиной 2000 слов.

![](./images/tolstoy.jpg){width="50%"}

```{r eval=FALSE}
corpus_samples <- make.samples(corpus, 
                               sample.size = 2000, 
                               sampling = "normal.sampling",
                               sample.overlap = 0,
                               sampling.with.replacement = FALSE)
```

Перед созданием списка слов удалим еры, которые встречаются в некоторых
изданиях ("съ" и т.п.).

```{r eval=FALSE}
corpus_samples_clean <- map(corpus_samples, 
                              function(text) str_remove(text, "ъ$") 
                            )
```

## Отбор переменных

Для построения модели берем 500 наиболее частотных слов (токенов),
наименее связанных с тематикой.

```{r eval=FALSE}
mfw <- make.frequency.list(corpus_samples_clean)[1:500]
sample(mfw, 20)
```

Составим матрицу с частотностями.

```{r eval=FALSE}
corpus_tf <- stylo::make.table.of.frequencies(corpus_samples_clean, mfw) |> 
  as.data.frame.matrix() |> 
  rownames_to_column("id") |> 
  as_tibble()
```

```{r eval=FALSE, echo=FALSE}
save(corpus_tf, file = "../data/corpus_tf.Rdata")
```

```{r echo=FALSE}
load("../data/corpus_tf.Rdata")
```

```{r}
corpus_tf
```

Мы будем определять автора, поэтому разделим первый столбец на два.

```{r warning=FALSE}
corpus_tf <- corpus_tf |> 
  separate(id, into = c("author", "title", NA), sep = "_") 
corpus_tf
```

Посмотрим, сколько произведений для каждого автора в корпусе.

```{r}
corpus_tf |> 
  count(author) |> 
  ggplot(aes(reorder(author, n), n, fill = author)) +
  geom_col(show.legend = FALSE) +
  xlab(NULL) +
  ylab(NULL) +
  scale_fill_viridis_d() + 
  theme_light() +
  coord_flip()
```

```{r}
corpus_tf |> 
  count(author) |> 
  arrange(n)
```

Для ускорения вычислений пока удалим авторов, у которых не так много
текста. Также нам не нужен столбец с названием (кажется, что
предсказывать автора "Войны и мира" по названию -- не очень честно).

```{r}
corpus_tf <- corpus_tf |> 
  add_count(author) |> 
  filter(n > 50) |> 
  select(-n, -title) 
```

## Обучающая и тестовая выборки

```{r}
set.seed(06042025)
data_split <- corpus_tf |> 
  mutate(author = as.factor(author)) |> 
  initial_split(strata = author)

data_train <- training(data_split) 
data_test <- testing(data_split)
```

```{r}
# folds
set.seed(06042025)
folds <- vfold_cv(data_train, strata = author, v = 5)
folds
```

## Препроцессинг

Большую часть препроцессинга мы сделали в `stylo`, поэтому нам нужно
всего несколько шагов.

```{r}
tf_rec <- recipe(author ~ ., data = data_train) |>
  step_zv(all_predictors()) |> 
  step_normalize(all_predictors())

tf_rec
```

Также создадим рецепт, в котором используем главные компоненты в
качестве предикторов. В PCA максимальное число компонент равно минимуму
из

-   числа переменных (признаков) в исходных данных;
-   числа наблюдений минус один.

В нашем случае классов `r data_train$author |> unique() |> length()`.

```{r}
pca_rec <- recipe(author ~ ., data = data_train) |>
  step_zv(all_predictors()) |> 
  step_normalize(all_predictors()) |> 
  step_pca(all_predictors(), num_comp = 14)

pca_rec
```

::: {.callout-note icon="false"}
На очень большом числе признаков `step_pca()` может сильно замедлять
вычисления, в этом случае можно попробовать `step_pca_truncated()` из
пакета
{[embed](https://embed.tidymodels.org/reference/step_pca_truncated.html)}.
Также стоит помнить, что PCA выполняет линейное снижение размерности,
что подходит не для всех данных. Для нелинейного подхода воспользуйтесь
функцией `step_umap()` из того же пакета.
:::

## Результат препроцессинга

```{r}
prep_train_tf <- tf_rec |>
  prep(data_train) 

tidy(prep_train_tf)
```

```{r}
bake_train_tf <- prep_train_tf |> 
  bake(new_data = NULL)

bake_train_tf
```

```{r}
prep_train_pca <- pca_rec |>
  prep(data_train) 

tidy(prep_train_pca)
```

```{r}
bake_train_pca <- prep_train_pca |> 
  bake(new_data = NULL)

bake_train_pca
```

## Первая модель: регрессия с регуляризацией

Когда мы работаем с текстовыми данными и используем большое число
признаков для классификации, важно избегать алгоритмов, которые плохо
работают с высоким числом измерений (например, k-NN). Вместо этого лучше
использовать более эффективные алгоритмы, такие как **линейные модели с
регуляризацией**.

Для задач классификации применяется **логистическая регрессия**, которая
неплохо справляется с разреженными данными благодаря L1-регуляризации
(Lasso) или L2-регуляризации (Ridge). В частности, лассо-регуляризация
позволяет обнулять незначимые признаки, исключая их тем самым из модели.

Поскольку в нашем датасете несколько классов, то мы применим
**многоклассовую логистическую регрессию**.

```{r}
lasso_spec <- multinom_reg(penalty = tune(), mixture = 1) |> 
  set_mode("classification") |> 
  set_engine("glmnet")
```

```{r}
lasso_param <- extract_parameter_set_dials(lasso_spec)
  
lasso_grid <- lasso_param |> 
  grid_regular(levels = 3)

lasso_grid
```

```{r}
lasso_wflow <- workflow() |> 
  add_model(lasso_spec) |> 
  add_recipe(tf_rec)

lasso_wflow
```

Здесь придется немного (или много) подождать. Параллелизация поможет
ускорить вычисления. Сохраняем воркфлоу для сравнения с последующими
моделями.

```{r eval=FALSE}
library(tictoc)
library(future)

plan(multisession, workers = 5)

tic()
set.seed(06042025)
lasso_tune <- lasso_wflow |> 
  tune_grid(
    resamples = folds, 
    grid = lasso_grid,
    metrics = metric_set(accuracy, roc_auc),
    control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
  )

lasso_tune 

toc()
# 12.376 sec elapsed
plan(sequential)
```

```{r eval=FALSE, echo=FALSE}
save(lasso_tune, file = "../data/lasso_tune.Rdata")
```

```{r echo=FALSE}
load("../data/lasso_tune.Rdata")
```

```{r}
autoplot(lasso_tune)
```

Наша модель уже достигла достаточно высокой точности ~~расходимся~~.

```{r}
collect_predictions(lasso_tune) |> 
  roc_curve(truth = author, .pred_Bulgakov:.pred_Vovchok)  |> 
  ggplot(aes(1 - specificity, sensitivity, color = .level)) +
  geom_abline(slope = 1, color = "gray50", lty = 2, alpha = 0.8) +
  geom_path(linewidth = 1.5, alpha = 0.7) +
  labs(color = NULL) +
  coord_fixed() +
  theme_light()
```

Вспомним, что все это значит:

**Sensitivity** (Чувствительность) = **True Positive Rate** (TPR): -
Формула: TP/(TP+FN) - Это доля верно определенных положительных примеров
среди всех положительных примеров - Показывает, насколько хорошо модель
находит нужные объекты из всех существующих - Другие названия: полнота
(recall), истинноположительная доля - Ось Y на ROC-кривой

**1-Specificity** = **False Positive Rate** (FPR): - Формула: FP/(FP+TN)
= 1 - TN/(FP+TN) = 1 - Specificity - Это доля неверно определенных
положительных примеров среди всех отрицательных примеров - Показывает,
насколько часто модель ошибочно причисляет негативные примеры к
позитивным - Другие названия: ложноположительная доля - Ось X на
ROC-кривой

В нашем контексте:

-   sensitivity (для автора А) -- это доля текстов автора А, которые
    правильно определены как тексты автора А,
-   1-specificity (для автора А) -- это доля текстов НЕ автора А,
    которые ошибочно определены как тексты автора А.

```{r}
collect_metrics(lasso_tune) |> 
  filter(.metric == "accuracy")
```

## SVM

```{r}
svm_spec <- svm_linear(cost = tune()) |> 
  set_mode("classification") |> 
  set_engine("LiblineaR")
```

```{r}
svm_param <- extract_parameter_set_dials(svm_spec)

svm_grid <- svm_param |> 
  grid_regular(levels = 3)

svm_grid
```

## Random forest

```{r}
rf_spec <- rand_forest(
  trees = tune()) |>        
  set_mode("classification") |> 
  set_engine("ranger")

rf_spec
```

Для случайного леса создадим решетку вручную.

```{r}
rf_grid <- tibble(trees = c(100, 200, 300))

rf_grid
```

## Workflow_set

```{r}
wflow_set <- workflow_set(  
  preproc = list(tf = tf_rec,
                 pca = pca_rec),  
  models = list(svm = svm_spec,
                rf = rf_spec),  
  cross = TRUE
)


wflow_set
```

```{r}
wflow_set_final <- wflow_set |> 
  option_add(grid = svm_grid, id = "tf_svm") |> 
  option_add(grid = svm_grid, id = "pca_svm") |> 
  option_add(grid = rf_grid, id = "tf_rf") |> 
  option_add(grid = rf_grid, id = "pca_rf")
```

Снова немного подождем. Обратите внимание: обе модели подгоняются 5 раз
с тремя разными гиперпараметрами и двумя рецептами препроцессинга. Это
займет время, так как по сути мы обучаем
``` r 2*5*3*2`` моделей. Чтобы все сработало, должны быть установлены пакеты ```{LiblineaR}`и`{ranger}\`.

```{r eval=FALSE}
plan(multisession, workers = 5)

set.seed(06042025)
tic()
wflow_set_fit <- 
  workflow_map(
    wflow_set_final, 
    verbose = TRUE, 
    metrics = metric_set(accuracy),
    resamples = folds,
    control = control_resamples(save_pred = TRUE),
    fn = "tune_grid"
  )
toc()
plan(sequential)
# i 1 of 4 tuning:     tf_svm
# ✔ 1 of 4 tuning:     tf_svm (9.8s)
# i 2 of 4 tuning:     tf_rf
# ✔ 2 of 4 tuning:     tf_rf (4.5s)
# i 3 of 4 tuning:     pca_svm
# ✔ 3 of 4 tuning:     pca_svm (3.5s)
# i 4 of 4 tuning:     pca_rf
# ✔ 4 of 4 tuning:     pca_rf (4.1s)
# 24.538 sec elapsed
```

```{r echo=FALSE, eval=FALSE}
save(wflow_set_fit, file = "../data/wflow_set_fit.Rdata")
```

```{r echo=FALSE}
load("../data/wflow_set_fit.Rdata")
```

## Объединение воркфлоу

```{r}
wflow_set_final <- wflow_set_fit |> 
  bind_rows(as_workflow_set(lasso_tf = lasso_tune))

wflow_set_final
```

Лучшие результаты показывает SVM. Одна из моделей лассо (с очень высоким
штрафным коэффициентом) находится в самом низу.

```{r warning=FALSE}
autoplot(wflow_set_final, metric = "accuracy") + 
  theme_light() +
  theme(legend.position = "none") +
  geom_text(aes(y = (mean - 2*std_err), label = wflow_id),
            angle = 90, hjust = 1.5) 
```

## Выбор модели и окончательная настройка

```{r warning=FALSE}
rank_results(wflow_set_final, rank_metric = "accuracy")
```

```{r}
autoplot(wflow_set_fit, id = "tf_svm") +
  theme_light()
```

```{r}
best_results <- 
   wflow_set_final |> 
   extract_workflow_set_result("tf_svm") |> 
   select_best(metric = "accuracy")

best_results
```

Обратите внимание: на этом этапе мы "распечатываем" тестовые данные!

```{r eval=FALSE}
svm_test_results <- 
   wflow_set_final |> 
   extract_workflow("tf_svm") |> 
   finalize_workflow(best_results) |> 
   last_fit(split = data_split,
            metrics = metric_set(accuracy, f_meas))

svm_test_results
```

```{r echo=FALSE, eval=FALSE}
save(svm_test_results, file = "../data/svm_test_results.Rdata")
```

```{r echo=FALSE}
load("../data/svm_test_results.Rdata")
```

## Оценка

Оцениваем эффективность на тестовых данных.

```{r}
collect_metrics(svm_test_results)
```

```{r message=FALSE, warning=FALSE}
svm_test_results |> 
  collect_predictions() |>
  conf_mat(truth = author, estimate = .pred_class) |> 
  autoplot(type = "heatmap") +
  scale_fill_gradient(low = "white", high = "#233857") +
  theme(panel.grid.major = element_line(colour = "#233857"),
        axis.text = element_text(color = "#233857"),
        axis.title = element_text(color = "#233857"),
        plot.title = element_text(color = "#233857"),
        axis.text.x = element_text(angle = 90))
  
```

Отличная работа `r emo::ji("award")` `r emo::ji("award")` `r emo::ji("award")`
