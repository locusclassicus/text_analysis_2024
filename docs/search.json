[
  {
    "objectID": "tabular.html",
    "href": "tabular.html",
    "title": "2  Таблицы",
    "section": "",
    "text": "2.1 Матрицы\nМатрица – это вектор, который имеет два дополнительных атрибута: количество строк и количество столбцов. Из этого следует, что матрица, как и вектор, может хранить данные одного типа. Проверим.\nM = matrix(c(1, 2, 3, 4), nrow = 2)\nM # все ок\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nM = matrix(c(1, 2, 3, \"a\"), nrow = 2)\nM # все превратилось в строку! \n\n     [,1] [,2]\n[1,] \"1\"  \"3\" \n[2,] \"2\"  \"a\"\nВ матрице есть ряды и столбцы. Их количество определяет размер (порядок) матрицы. Выше мы создали матрицу 2 x 2. Элементы матрицы, как и элементы вектора, можно извлекать по индексу. Сначала указывается номер ряда (строки), потом номер столбца.\nM = matrix(c(1, 2, 3, 4), nrow = 2)\nM\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\nM[1, ] # первая строка полностью\n\n[1] 1 3\n\nM[,2] # второй столбец полностью\n\n[1] 3 4\n\nM[1,1] # одно значение\n\n[1] 1\nОбратите внимание, как меняется размерность при индексировании.\nM = matrix(c(1, 2, 3, 4), nrow = 2)\ndim(M) # функция для извлечения измерений\n\n[1] 2 2\n\ndim(M[1, ]) \n\nNULL\nПопытка узнать измерения вектора возвращает NULL, потому что, с точки зрения R, векторы не являются матрицами из одного столбца или одной строки и потому не имеют измерений.\nВ этом уроке мы не будем много работать с матрицами, но полезно помнить, что они существуют: матрицы и алгебраические операции с ними задействованы при латентно-семантическом анализе и построении эмбеддингов (см. ниже).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#таблицы-датафреймы",
    "href": "tabular.html#таблицы-датафреймы",
    "title": "2  Таблицы",
    "section": "2.2 Таблицы (датафреймы)",
    "text": "2.2 Таблицы (датафреймы)\nЕсли матрица – это двумерный аналог вектора, то таблица (кадр данных, data frame) – это двумерный аналог списка. Как и список, датафрейм может хранить данные разного типа.\n\n# создание датафрейма\ndf &lt;- data.frame(names = c(\"John\", \"Mary\"), age = c(18, 25), sport = c(\"basketball\", \"tennis\"))\ndf\n\n\n  \n\n\n\nИзвлечение данных тоже напоминает работу со списком.\n\ndf$names # забирает весь столбец\n\n[1] \"John\" \"Mary\"\n\ndf[,\"names\"] # то же самое, другой способ\n\n[1] \"John\" \"Mary\"\n\ndf[1, ] # забирает ряд",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#импорт-табличных-данных",
    "href": "tabular.html#импорт-табличных-данных",
    "title": "2  Таблицы",
    "section": "2.3 Импорт табличных данных",
    "text": "2.3 Импорт табличных данных\nВ этом уроке мы будем работать с датасетом из Репозитория открытых данных по русской литературе и фольклору под названием “Программы по литературе для средней школы с 1919 по 1991 гг.” Этот датасет был использован при подготовке интерактивной карты российского школьного литературного канона (1852-2023). Карта была представлена в 2023 г. Лабораторией проектирования содержания образования ВШЭ. Подробнее о проекте можно посмотреть материал “Системного блока”.\nОсновная функция для скачивания файлов из Сети – download.file(), которой необходимо задать в качестве аргументов url, название сохраняемого файла, иногда также метод.\n\nurl &lt;- \"https://dataverse.pushdom.ru/api/access/datafile/4229\"\n\n# скачивание в папку files в родительской директории\ndownload.file(url, destfile = \"../files/curricula.tsv\") \n\nОсновные функции для чтения табличных данных в базовом R - это read.table() и read.csv(). Файл, который мы скачали, имеет расширение .tsv (tab separated values). Чтобы его прочитать, используем read.table(), указав тип разделителя:\n\ncurricula_df &lt;- read.table(\"../files/curricula.tsv\", sep = \"\\t\", header = TRUE)\n\ncurricula_df\n\n\n  \n\n\n\nФункция read.csv() отличается лишь тем, что автоматически выставляет значения аргументов sep = \",\", header = TRUE.\nФункция class() позволяет убедиться, что перед нами датафрейм.\n\nclass(curricula_df)\n\n[1] \"data.frame\"",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#работа-с-датафреймом",
    "href": "tabular.html#работа-с-датафреймом",
    "title": "2  Таблицы",
    "section": "2.4 Работа с датафреймом",
    "text": "2.4 Работа с датафреймом\n\n# узнать имена столбцов\ncolnames(curricula_df) \n\n[1] \"author\"     \"title\"      \"comment\"    \"curriculum\" \"id\"        \n[6] \"year\"       \"grade\"      \"priority\"  \n\n\n\n# извлечь ряд(ы) по значению\ncurricula_df[curricula_df$year == \"1919\", ]\n\n\n  \n\n\n\n\n# извлечь столбец \ncurricula_df$year |&gt; head()\n\n[1] \"1919\" \"1919\" \"1919\" \"1919\" \"1919\" \"1919\"\n\ncurricula_df[ , \"year\"] |&gt; head()\n\n[1] \"1919\" \"1919\" \"1919\" \"1919\" \"1919\" \"1919\"\n\ncurricula_df[ , 6] |&gt;  head()\n\n[1] \"1919\" \"1919\" \"1919\" \"1919\" \"1919\" \"1919\"\n\n\n\n# узнать тип данных в столбцах\nstr(curricula_df) \n\n'data.frame':   10306 obs. of  8 variables:\n $ author    : chr  \"Андреев Л.Н.\" \"Андреев Л.Н.\" \"Андреев Л.Н.\" \"Бальмонт К.Д.\" ...\n $ title     : chr  \"Жили-были\" \"Иуда\" \"Рассказ о семи повешенных\" \"\" ...\n $ comment   : chr  \"\" \"\" \"\" \"\" ...\n $ curriculum: chr  \"19 ИРЛ 2 ст\" \"19 ИРЛ 2 ст\" \"19 ИРЛ 2 ст\" \"19 ИРЛ 2 ст\" ...\n $ id        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year      : chr  \"1919\" \"1919\" \"1919\" \"1919\" ...\n $ grade     : int  9 9 9 9 9 8 8 8 8 8 ...\n $ priority  : chr  \"\" \"\" \"*\" \"*\" ...\n\n\n\n# преобразовать тип данных в столбцах\ncurricula_df$year &lt;- as.numeric(curricula_df$year)\n\n\n# вывести сводку\nsummary(curricula_df)\n\n    author             title             comment           curriculum       \n Length:10306       Length:10306       Length:10306       Length:10306      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n       id             year          grade          priority        \n Min.   : 1.00   Min.   :1919   Min.   : 5.000   Length:10306      \n 1st Qu.:13.00   1st Qu.:1946   1st Qu.: 8.000   Class :character  \n Median :31.00   Median :1966   Median :10.000   Mode  :character  \n Mean   :28.01   Mean   :1963   Mean   : 9.195                     \n 3rd Qu.:42.00   3rd Qu.:1981   3rd Qu.:10.000                     \n Max.   :50.00   Max.   :1991   Max.   :11.000                     \n                 NA's   :12                                        \n\n\nНебольшое упражнение на кодинг позволит закрепить навыки работы с матрицами и датафреймами.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl() и пройдите урок 7 Matrices and Data Frames.\n\n\nВсе ли вы запомнили?\n\n\n\n\n\n\nВопрос\n\n\n\nДля чего нужна функция cbind()?\n\n\n\n\nдля добавления рядов\n\n\nдля добавления столбцов\n\n\nдля извлечения имен столбцов\n\n\nдля извлечения имен рядов\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nФункция colnames() позволяет как назначать новые имена таблице, так и извлекать существующие.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\nКод для выполнения следующего задания сохраните в виде файла с расширением .R.\n\n\n\n\n\n\nЗадание\n\n\n\nПРАКТИЧЕСКОЕ ЗАДАНИЕ 1: ИСПАНСКИЕ ПИСАТЕЛИ\n\n\n\n# устанавливаем и загружаем нужный пакет\ninstall.packages(\"languageR\")\nlibrary(languageR)\n\n# загружаем датасет\nmeta &lt;- spanishMeta\n\n# допишите ваш код ниже\n# посчитайте средний год публикации романов Камило Хосе Селы\n\n\n# вычислите суммарное число слов в романах Эдуардо Мендосы\n\n\n# извлеките ряды с текстами, опубликованными до 1980 г.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#tibble",
    "href": "tabular.html#tibble",
    "title": "2  Таблицы",
    "section": "2.5 Tibble",
    "text": "2.5 Tibble\nСуществуют два основных “диалекта” R, один из которых опирается главным образом на функции и структуры данных базового R, а другой пользуется синтаксисом tidyverse. Tidyverse – это семейство пакетов (метапакет), разработанных Хадли Уикхемом и др., которое включает в себя в том числе пакеты dplyr, ggplot2 и многие другие.\n\n# загрузить все семейство\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nОсновная структура данных в tidyverse – это tibble, современный вариант датафрейма. Тиббл, как говорят его разработчики, это ленивые и недовольные датафреймы: они делают меньше и жалуются больше. Это позволяет решать проблемы на более ранних этапах, что, как правило, приводит к созданию более чистого и выразительного кода.\nОсновные отличия от обычного датафрейма:\n\nусовершенствованный метод print(), не нужно постоянно вызывать head();\nнет имен рядов;\nдопускает синтаксически “неправильные” имена столбцов;\nпри индексировании не превращается в вектор.\n\nПреобразуем наш датафрейм в тиббл для удобства работы с ним.\n\ncurricula_tbl &lt;- as_tibble(curricula_df)\n\nСравним поведение датафрейма и тиббла.\n\n# индексирование \ncurricula_df[, 1] |&gt; class()\n\n[1] \"character\"\n\ncurricula_tbl[,1]  |&gt; class()\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nПора тренироваться.\n\n\n\n\n\n\nЗадание\n\n\n\nУстановите курс swirl::install_course(\"Getting and Cleaning Data\"). Загрузите библиотеку library(swirl), запустите swirl(), выберите этот курс и пройдите из него урок 1 Manipulating Data with dplyr. При попытке загрузить урок 1 вы можете получить сообщение об ошибке. В таком случае установите версию курса из github, как указано здесь, или загрузите файл вручную, как указано здесь.\n\n\nВремя вопросов! Обычный датафрейм или тиббл?\n\n\n\n\n\n\nВопрос\n\n\n\nПо умолчанию распечатывает только первые 10 рядов в консоль.\n\n\n\n\nдатафрейм\n\n\nтиббл\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nМолчаливо исправляет некорректные названия столбцов.\n\n\n\n\nдатафрейм\n\n\nтиббл\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nНе имеет названий рядов.\n\n\n\n\nдатафрейм\n\n\nтиббл\n\n\n\n\n\nКстати, обратили внимание, как работает оператор &lt;= с символьным вектором?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#dplyr",
    "href": "tabular.html#dplyr",
    "title": "2  Таблицы",
    "section": "2.6 Dplyr",
    "text": "2.6 Dplyr\nВ уроке swirl выше вы уже немного познакомились с “грамматикой манипуляции данных”, лежащей в основе dplyr. Здесь об этом будет сказано подробнее. Эта грамматика предоставляет последовательный набор глаголов, которые помогают решать наиболее распространенные задачи манипулирования данными:\n\nmutate() добавляет новые переменные, которые являются функциями существующих переменных;\nselect() выбирает переменные (столбцы) на основе их имен;\nfilter() выбирает наблюдения (ряды) на основе их значений;\nsummarise() обобщает значения;\narrange() изменяет порядок следования строк.\n\nВсе эти глаголы естественным образом сочетаются с функцией group_by(), которая позволяет выполнять любые операции “по группам”, и с оператором pipe |&gt; из пакета magrittr.\nВ итоге получается более лаконичный и читаемый код. Узнаем, за какие года у нас есть программы по литературе.\n\ncurricula_tbl |&gt; \n  count(curriculum, year) \n\n\n  \n\n\n\nОтберем две программы для 8 класса и выясним, какие авторы в них представлены лучше всего.\n\ncurricula_tbl |&gt; \n  filter(year %in% c(1919, 1922), grade == 8) |&gt; \n  count(author, year) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nТеперь упражнения в swirl. Вам придется редактировать код, который предложит программа, так что сгруппируйтесь.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс Getting and Cleaning Data и пройдите из него урок 2 Grouping and Chaining with dplyr.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nФункция n_distinct() возвращает все уникальные значения.\n\n\n\n\nПравда\n\n\nЛожь",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#опрятные-данные",
    "href": "tabular.html#опрятные-данные",
    "title": "2  Таблицы",
    "section": "2.7 Опрятные данные",
    "text": "2.7 Опрятные данные\n\nTidy datasets are all alike, but every messy dataset is messy in its own way.\n— Hadley Wickham\n\nTidyverse – это не только особый синтаксис, но и отдельная идеология “опрятных данных”. “Сырые” данные, с которыми мы работаем, редко бывают опрятны, и перед анализом их следует “почистить” и преобразовать.\nОсновные принципы опрятных данных:\n\nотдельный столбец для каждой переменной;\nотдельный ряд для каждого наблюдения;\nу каждого значения отдельная ячейка;\nодин датасет – одна таблица.\n\n\n\n\nПринципы опрятных данных. Источник.\n\n\n\nПосмотрите на учебные тибблы из пакета tidyr и подумайте, какое из этих правил нарушено в каждом случае.\n\ndata(\"table2\")\ntable2\n\n\n  \n\n\ndata(\"table3\")\ntable3\n\n\n  \n\n\ndata(\"table4a\")\ntable4a\n\n\n  \n\n\ndata(\"table4b\")\ntable4b\n\n\n  \n\n\n\nВажные функции для преобразования данных из пакета tidyr:\n\nseparate() делит один столбец на новые;\nunite() объединяет столбцы;\npivot_longer() удлиняет таблицу;\npivot_wider() расширяет таблицу;\ndrop_na() и replace_na() указывают, что делать с NA и др.\n\nКроме того, в dplyr есть полезное семейство функций _join, позволяющих объединять данные в различных таблицах. Дальше мы потренируемся с ними работать, но сначала пройдем урок swirl. Это достаточно сложный урок (снова понадобится редактировать скрипт), но он нам дальше здорово поможет.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс Getting and Cleaning Data и пройдите из него урок 3 Tidying Data with tidyr.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nФункция separate() обязательно требует указать разделитель.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nПринципы опрятных данных требуют, чтобы одному наблюдению соответствовал один столбец.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nФункция contains() используется вместе с filter() для выбора рядов.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n Отличная работа! Прежде чем двигаться дальше, приведите в порядок table2, 3, 4a-4b, используя dplyr и tidyr.\n\n\n\n\n\n\nЗадание\n\n\n\nПрактическое задание “Библиотека Gutenberg”\n\n\n\ndevtools::install_github(\"ropensci/gutenbergr\")\nlibrary(gutenbergr)\nlibrary(dplyr)\nlibrary(tidyr)\n\nworks &lt;- gutenberg_works()\n\n# Отберите ряды, в которых gutenberg_author_id равен 65;\n# после этого выберите два столбца: author, title\nmy_data &lt;- works |&gt; \n  # ваш код здесь\n  \n# Загрузите данные об авторах и выберите столбцы: author, deathdate\nauthors &lt;- gutenberg_authors |&gt; \n  # ваш код здесь\n\n# Соедините my_data с данными о смерти автора из authors, \n# так чтобы к my_data добавился новый столбец. \n# После этого используйте функцию separate, \n# чтобы разделить столбец с именем и фамилией на два новых: author, name. \n# Удалите столбец с именем автора, оставив только фамилию.\n# Добавьте новый столбец century, \n# используя функцию mutate и данные из столбца deathdate. \n# Используйте оператор pipe, не сохраняйте промежуточные результаты!\n\nmy_data |&gt; \n  # ваш код здесь",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Компьютерный анализ текста",
    "section": "",
    "text": "Введение",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#об-этом-курсе",
    "href": "index.html#об-этом-курсе",
    "title": "Компьютерный анализ текста",
    "section": "Об этом курсе",
    "text": "Об этом курсе\nЭтот сайт содержит материалы к курсу “Компьютерный анализ текста в R” для магистерской программы НИУ ВШЭ “Цифровые методы в гуманитарных науках”. Предыдущую версию курса можно найти здесь.\nИ тексты, и инструменты для работы с ними подобраны таким образом, чтобы помочь студентам гуманитарных специальностей (филологам, философам, историкам и др.) как можно быстрее, но с полным пониманием дела перейти к применению количественных методов в собственной работе.\nЧтобы лучше понимать, какие из этих методов более всего востребованы в научной работе, преподаватели магистратуры “Цифровые методы в гуманитарных науках” – Б.В. Орехов, А.А. Осмоловская и О.В. Алиева – организовали в 2024 г. серию встреч с ведущими представителями отрасли. Видео этих встреч и литературу к семинарам можно найти на сайте http://criticaldh.ru/.\nТам мы собрали именно теоретические обсуждения и литературу к ним, а в этом курсе предлагаем приступить к практике DH (на языке R). Оба этих аспекта, в нашем представлении и в программе магистратуры тесно связаны: одного программирования не хватит, чтобы стать “цифровым гуманистом”, а теории недостаточно, чтобы судить об успешности тех или иных цифровых проектов. Поэтому этот курс старается стоять на двух ногах и соединять кодинг с теоретической рефлексией. Это почти невыполнимая задача но когда нам это мешало.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#ресурсы",
    "href": "index.html#ресурсы",
    "title": "Компьютерный анализ текста",
    "section": "Ресурсы",
    "text": "Ресурсы\nИ в теоретическом, и в практическом плане курс опирается на огромную работу, уже проделанную преподавателями магистратуры ЦМГН. Важнейшие наши достижения собрал Б.В. Орехов: https://github.com/nevmenandr/awesome-dh-hse. Здесь вы найдете ссылки на видео, научно-популярные и научные публикации и датасеты.\nЕсли вдруг вам не хватит практических заданий по R, то в качестве дополнения к оффлайн-курсу можно рекомендовать онлайн-курс Георгия Мороза “Введение в анализ данных на R для гуманитарных и социальных наук”. К этому курсу прилагается онлайн-ноутбук (https://agricolamz.github.io/daR4hs/) с комментариями и всем кодом, и он полностью открыт. Надо иметь в виду, однако, что онлайн-курс рассчитан всего на 9 недель, в то время как наш – на два семестра, так что его можно использовать лишь как вспомогательный ресурс, но не замену.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#программа",
    "href": "index.html#программа",
    "title": "Компьютерный анализ текста",
    "section": "Программа",
    "text": "Программа\nКурс 2024/2025 г. включает в себя три основных блока и 22 темы (некоторые темы рассчитаны на 2-3 недели, всего 32 недели). Программа носит предварительный характер и может быть чуть изменена.\nЧасть 1. Основы работы в R\n\nЗнакомство с R и RStudio. Начало работы. Объекты, функции, операторы.\nВизуализация данных: базовый R, lattice, ggplot2.\nТрансформация данных. «Опрятные» данные с dplyr и tidyverse.\nУсловия и циклы. Написание собственных функций. Итерации с purrr.\nИмпорт данных. Импорт данных из XML.\nВоспроизводимые исследования. RMarkdown. Quarto.\nРегулярные выражения: базовый R и stringr.\nHTML. Веб-скрапинг.\n\nЧасть 2. Методы анализа текста\n\nТокенизация. Морфологический и синтаксический анализ.\nРаспределения слов и анализ частотностей.\nАнализ эмоциональной тональности (метод словарей).\nТематическое моделирование (LDA).\nЛатентно-семантический анализ. Word2Vec.\nАнализ текста с помощью сетей (графов).\nОписание и анализ графов.\nОбучение без учителя. Пакет Stylo.\n\nЧасть 3. Статистика и машинное обучение\n\nПростая и множественная линейная регрессия.\nАлгоритмы для бинарной и многоклассовой классификации.\n\nДеревья решений и правил. Бэггинг, случайные леса, бустинг.\nПротоколы проверки моделей. Проблема переобучения.\nКонструирование признаков. Методы снижения размерности.\nМетоды “черного ящика”: опорные векторы и нейросети.\nCase-study 1.\nCase-study 2.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#оценивание",
    "href": "index.html#оценивание",
    "title": "Компьютерный анализ текста",
    "section": "Оценивание",
    "text": "Оценивание\nДомашние задания выполняются в GitHub Classroom. Еженедельно выполняются небольшие задания, которые оцениваются по бинарной шкале (1/0), раз в месяц – консолидирующие задания на весь пройденный материал (оценка 0-10). Все необходимые ссылки вы найдете в чате курса в Telegram.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#благодарности",
    "href": "index.html#благодарности",
    "title": "Компьютерный анализ текста",
    "section": "Благодарности",
    "text": "Благодарности\nЗа помощь в разработке курса и подготовке датасетов к нему автор благодарит Георгия Мороза и Бориса Орехова.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#обратная-связь",
    "href": "index.html#обратная-связь",
    "title": "Компьютерный анализ текста",
    "section": "Обратная связь",
    "text": "Обратная связь\nЕсли вы заметили ошибку или опечатку, можно писать на адрес oalieva@hse.ru.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "start.html",
    "href": "start.html",
    "title": "1  Начало работы",
    "section": "",
    "text": "1.1 Установка R и RStudio\nМы будем использовать R, так что для занятий понадобятся:\nМы будем использовать следующую версию R:\nR version 4.3.3 (2024-02-29)\nНекоторые люди не любят устанавливать лишние программы себе на компьютер, несколько вариантов есть и для них:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#установка-r-и-rstudio",
    "href": "start.html#установка-r-и-rstudio",
    "title": "1  Начало работы",
    "section": "",
    "text": "R\n\nна Windows\nна Mac\nна Linux.\n\nRStudio — IDE для R (можно скачать здесь)\n\n\n\n\n\nRStudio cloud — полная функциональность RStudio с некоторыми ограничениями;\nwebR REPL — ограниченная версия компилятора R, которая работает в вашем браузере и не требует никаких установок на компьютер\nJupyter ноутбуки;\nGoogle Colab (нужно в настройках переключить ядро);\nVS Code — другое IDE, которое также позволяет работать с R;\nв принципе, в IDE нет нужды, можно работать из терминала, после установки, нужно всего лишь набрать R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#знакомство-с-rstudio",
    "href": "start.html#знакомство-с-rstudio",
    "title": "1  Начало работы",
    "section": "1.2 Знакомство с RStudio",
    "text": "1.2 Знакомство с RStudio\nRStudio — основная среда разработки (IDE) для R. После установки R и RStudio можно открыть RStudio и перед вами предстанет что-то похожее на изображение ниже:\n\n\n\nRStudio при первом открытии\n\n\nПосле нажатия на двойное окошко чуть левее надписи Environment откроется окно скрипта.\n\n\n\nПодокна RStudio\n\n\nВсе следующие команды можно:\n\nвводить в окне консоли, и тогда для исполнения следует нажимать клавишу Enter.\nвводить в окне скрипта, и тогда для исполнения следует нажимать клавиши Ctrl/Cmd + Enter или на команду Run на панели окна скрипта. Все, что введено в окне скрипта можно редактировать как в любом текстовом редакторе, в том числе сохранять Ctrl/Cmd + S.\n\nДля начала попробуйте получить информацию о сессии, введя в консоли такую команду:\n\nsessionInfo()\n\nsessionInfo() – это функция. О функциях можно думать как о глаголах (“сделай то-то!”). За названием функции всегда следуют круглые скобки, внутри которых могут находиться аргументы функции. Аргументы – это что-то вроде дополнений и обстоятельств. Аргументы могут быть обязательные и необязательные. Чтобы узнать, каких аргументов требует функция, надо вызывать help: ?mean(). В правой нижней панели появится техническая документация. Но также можно воспользоваться функцией args(). Попробуйте набрать в консоли args(round).\n\n\n\n\n\n\nВопрос\n\n\n\nСколько аргументов функции round() имеют значения по умолчанию?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#пакеты",
    "href": "start.html#пакеты",
    "title": "1  Начало работы",
    "section": "1.3 Пакеты",
    "text": "1.3 Пакеты\nПосле установки R вы получите доступ к уже готовым методам статистического анализа и инструментам для визуализации. Если в базовой инсталляции R нет нужного решения – надо поискать в библиотеке пакетов. Пакет – это набор функций и иногда датасетов, созданный пользователями. На 1 июля 2023 г. в репозитории CRAN доступно 19789 пакетов. И это далеко не все: многие пакеты доступны только на GitHub.\n\n\n\n\n\n\nНа заметку\n\n\n\nНекоторые функции, которые вы найдете в пакетах, частично дублируют друг друга – это нормально, как и в естественном языке, “сказать” что-то можно разными способами.\n\n\nПо технической документации и так называемым “виньеткам” можно понять, какой пакет вам нужен. Например, вот так выглядит виньетка пакета RPerseus, при помощи которого можно получить доступ к корпусу греческой и латинской литературы.\nБывают еще “пакеты пакетов”, то есть очень большие семейства функций, своего рода “диалекты” R. Таково семейство tidyverse, объединяемое идеологией “опрятных” данных. Про него мы еще будем говорить.\nПакеты для работы устанавливаются один раз, однако подключать их надо во время каждой сессии. Чтобы установить новый пакет, можно воспользоваться меню Tools &gt; Install Packages. Также можно устанавливать пакеты из консоли. Установим пакет с интерактивными уроками программирования на языке R:\n\ninstall.packages(\"swirl\")\n\nДля подключения используем функцию library(), которой передаем в качестве аргумента название пакета без кавычек:\n\nlibrary(swirl)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#рабочая-директория",
    "href": "start.html#рабочая-директория",
    "title": "1  Начало работы",
    "section": "1.4 Рабочая директория",
    "text": "1.4 Рабочая директория\nПеред началом работы проверьте свою рабочую директорию при помощи getwd(). Для смены можно использовать как абсолютный, так и относительный путь:\n\nsetwd(\"/Users/name/folder\")\n\n# искать в текущей директории\nsetwd(\"./folder\")\n\n# перейти на уровень вверх\nsetwd(\"../\")\n\nТакже для выбора рабочей директории можно использовать меню R Session &gt; Set Working Directory. А теперь – первое задание.\n\n\n\n\n\n\nЗадание\n\n\n\nУстановите курс программирования на R: install_course(\"R Programming\"). После этого привяжите пакет командой library(swirl) и наберите: swirl(). Укажите ваше имя. Пройдите урок 2 Workspace and Files.\n\n\n После выполнения ответьте на несколько вопросов на закрепление материала.\n\n\n\n\n\n\nВопрос\n\n\n\nКакие действия в рабочей директории можно совершать из консоли?\n\n\n\n\nсоздать директорию\n\n\nудалить директорию\n\n\nсоздать файл\n\n\nпереименовать файл\n\n\nкопировать файл\n\n\nудалить файл\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nЧтобы создать вложенную директорию при помощи функции dir.create(), аргументу recursive следует задать значение…\n\n\n\n\nTRUE\nFALSE\n\n\n\n\n\nЕсли все получилось, двигаемся дальше.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#r-как-калькулятор",
    "href": "start.html#r-как-калькулятор",
    "title": "1  Начало работы",
    "section": "1.5 R как калькулятор",
    "text": "1.5 R как калькулятор\nМожно использовать R как калькулятор. Для этого вводим данные рядом с символом приглашения &gt;, который называется prompt.\n\nsqrt(4) # квадратный корень\n\n[1] 2\n\n2^3 # степень\n\n[1] 8\n\nlog10(100) #логарифм\n\n[1] 2\n\n\nЕсли в начале консольной строки стоит +, значит предыдущий код не завершен. Например, вы забыли закрыть скобку функции. Ее можно дописать на следующей строке. Попробуйте набрать sqrt(2 в консоли.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#операторы-присваивания",
    "href": "start.html#операторы-присваивания",
    "title": "1  Начало работы",
    "section": "1.6 Операторы присваивания",
    "text": "1.6 Операторы присваивания\nЧтобы в окружении появился новый объект, надо присвоить результат вычислений какой-нибудь переменной при помощи оператора присваивания &lt;- (Alt + - (Windows) или Option + - (Mac)). Знак = также работает как оператор присваивания, но не во всех контекстах, поэтому им лучше не пользоваться.\n\nx &lt;- 2 + 2 # создаем переменную\ny &lt;- 0.1 # создаем еще одну переменную\nx &lt;- y # переназначаем  \nx + y\n\n[1] 0.2\n\n\nСочетание клавиш для оператора присваивания: Option/Alt + -. Имя переменной, как и имя функции, может содержать прописные и строчные буквы, точку и знак подчеркивания.\nТеперь небольшое упражнение.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(). Укажите ваше имя. Пройдите урок 1 Basic Building Blocks.\n\n\nЕсли все получилось, можно двигаться дальше! Но сначала зафиксируем несколько новых функций из этих первого урока.\n\n\n\n\n\n\nВопрос\n\n\n\nЧто вычисляет функция abs()?\n\n\n\n\nсреднее\n\n\nмодуль\n\n\nквадратный корень\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nСколько значений вернет функция, если разделить c(2, 4, 6) на 2?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nБуква “c” в названии функции c() означает…\n\n\n\n\ncover\n\n\ncollapse\n\n\nconcatenate",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#пайпы-конвееры",
    "href": "start.html#пайпы-конвееры",
    "title": "1  Начало работы",
    "section": "1.7 Пайпы (конвееры)",
    "text": "1.7 Пайпы (конвееры)\nВ нашем коде мы часто будем использовать знаки конвеера (или пайпы): |&gt; (в вашей версии он может выглядить иначе: %&gt;%; переключить оператор можно в Global Options). Они призваны показывать последовательность действий. Сочетание клавиш: Ctrl/Cmd + M.\n\nmean(sqrt(abs(sin(1:100))))\n\n[1] 0.7654264\n\n1:100 |&gt; \n  sin() |&gt; \n  abs() |&gt; \n  sqrt() |&gt; \n  mean()\n\n[1] 0.7654264",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#векторы",
    "href": "start.html#векторы",
    "title": "1  Начало работы",
    "section": "1.8 Векторы",
    "text": "1.8 Векторы\nВектор – это объект, предназначенный для хранения данных. К таким же объектам относятся также матрицы, списки, таблицы данных и др. Заметим, что в языке R нет скаляров (отдельных чисел). Числа считаются векторами из одного элемента.\n\nx &lt;- 2\nclass(x) # числовой вектор\n\n[1] \"numeric\"\n\nlength(x) # длина вектора\n\n[1] 1\n\n\nКак вы уже поняли, функция c() позволяет собрать несколько элементов в единый вектор:\n\nx &lt;- c(3, 5, 7)\nx_mean &lt;- mean(x) \nx_mean\n\n[1] 5\n\n\n Над векторами можно совершать арифметические операции, но будьте внимательны, применяя операции к векторам разной длины: в этом случае более короткий вектор будет переработан, то есть повторен до тех пор, пока его длина не сравняется с длиной вектора большей длины.\n\nx &lt;- 2\ny &lt;- c(10, 20, 30)\ny / x \n\n[1]  5 10 15\n\nx + y \n\n[1] 12 22 32\n\n\nВекторы можно индексировать, то есть забирать из них какие-то элементы:\n\nx &lt;- seq(1, 5, 0.5)\nx[4:5] # индексы начинаются с 1 (в отличие от Python)\n\n[1] 2.5 3.0\n\n\nВектор может хранить данные разных типов:\n\nцелое число (integer);\nчисло с плавающей точкой (numeric, также называются double, то есть число двойной точности);\nстроку (character);\nлогическую переменную (logical);\nкатегориальную переменную, или фактор (factor).\n\n\n# проверить тип данных \nx &lt;- sqrt(2)\nclass(x)\n\n[1] \"numeric\"\n\nis.integer(x)\n\n[1] FALSE\n\nis.numeric(x)\n\n[1] TRUE\n\n\nСоздавать векторы можно не только при помощи c(). Вот еще два способа.\n\nseq(1, 5, 0.5)\n\n[1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\nrep(\"foo\", 5)\n\n[1] \"foo\" \"foo\" \"foo\" \"foo\" \"foo\"\n\n\nНаучиться генерировать векторы поможет небольшое упражнение.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl() и пройдите урок 3 Sequences of Numbers.\n\n\nПроверьте свои знания, прежде чем двигаться дальше.\n\n\n\n\n\n\nВопрос\n\n\n\nКакие числа вернет команда pi:10?\n\n\n\n\nнатуральные\n\n\nцелые\n\n\nрациональные\n\n\nвещественные\n\n\nкомплексные\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nКакие функции могут использоваться для создания символьных векторов?\n\n\n\n\nseq()\n\n\nrep()\n\n\nc()\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nСколько значений вернет команда rep(c(0, 1, 2), times = 10)? Посчитайте в уме, не выполняя код.\n\n\n\n\n\n\n\n\n Факторы внешне похожи на строки, но в отличие от них хранят информацию об уровнях категориальных переменных. Уровень может обозначаться как числом (например, 1 и 0), так и строкой.\n\nt &lt;- factor(c(\"A\", \"B\", \"C\"), levels = c(\"A\", \"B\", \"C\"))\nt\n\n[1] A B C\nLevels: A B C\n\n\nВажно: вектор может хранить данные только одного типа. При попытке объединить в единый вектор данные разных типов они будут принудительно приведены к одному типу:\n\nx &lt;- c(TRUE, 1, 3, FALSE)\nx # логические значения приведены к числовым\n\n[1] 1 1 3 0\n\ny &lt;- c(1, \"a\", 2, \"лукоморье\") \ny # числа превратились в строки\n\n[1] \"1\"         \"a\"         \"2\"         \"лукоморье\"\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl() и пройдите урок 4 Vectors. Это позволит больше узнать про логические и символьные векторы.\n\n\nНесколько вопросов для самопроверки.\n\n\n\n\n\n\nВопрос\n\n\n\nКакие значение вернет команда (3 &gt; 5) & (4 == 4)?\n\n\n\n\nTRUE\nFALSE\nNA\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nКакие значения вернет команда (TRUE == TRUE) | (TRUE == FALSE)?\n\n\n\n\nTRUE\nFALSE\nNA\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nКоманда paste(LETTERS, 1:4, sep = \"-\") вернет…\n\n\n\n\nчисловой вектор длиной 26\n\n\nсимвольный вектор длиной 26\n\n\nчисловой вектор длиной 4\n\n\nсимвольный вектор длиной 4\n\n\nошибку\n\n\n\n\n\n Логические векторы можно получить в результате применения логических операторов (== “равно”, != “не равно”, &lt;= “меньше или равно”) к данным других типов:\n\nx &lt;- c(1:10) # числа от 1 до 10\ny &lt;- x &gt; 5\ny # значения TRUE соответствуют единице, поэтому их можно складывать\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nsum(y)\n\n[1] 5\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗдесь можно запустить swirl() и пройти урок 8 Logic. Это не обязательно, но очень полезно, если хотите разобраться в операторах!\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nПопробуйте посчитать в уме: какое из выражений ниже вернет значение TRUE?\n\n\n\n\n7 == 9\n\n\n!(57 != 8)\n\n\n9 &gt;= 10\n\n\n-6 &gt; -7\n\n\n\n\n\nФункции all() и any() также возвращают логические значения:\n\nx &lt;- 10:20 \nany(x == 15)\n\n[1] TRUE\n\nall(x &gt; 9)\n\n[1] TRUE\n\n\nОтсутствие данных любого типа в R передается двумя способами. NULL означает, что значение не существует. Например, если мы создадим пустой вектор, то при попытке распечатать его получим NULL. А вот длина пустого вектора равна нулю!\n\ny &lt;- c() \ny \n\nNULL\n\nlength(y) \n\n[1] 0\n\n\nNA (not available) указывает на то, что значение существует, но оно неизвестно. Любые операции с NA приводят к появлению новых NA! Сравните:\n\nx &lt;- c(1, NA, 2)\nmean(x)\n\n[1] NA\n\ny &lt;- c(1, NULL, 2)\nmean(y)\n\n[1] 1.5\n\n\nКак проверить, есть ли в данных NA или NULL? Знак == здесь не подойдет.\n\nx &lt;- NA\nx == NA\n\n[1] NA\n\ny &lt;- NULL\ny == NULL\n\nlogical(0)\n\n\nДля этого есть специальные функции.\n\nis.na(x)\n\n[1] TRUE\n\nis.null(y)\n\n[1] TRUE\n\n\n\nWhen some people first get to R, they spend a lot of time trying to get rid of NAs. People probably did the same sort of thing when zero was invented. NA is a wonderful thing to have available to you. It is seldom pleasant when your data have missing values, but life if much better with NA than without.\nBurns (2012)\n\nКак избавиться от NA? В некоторых случаях достаточно аргумента функции.\n\nmean(c(1, NA, 2), na.rm=T) \n\n[1] 1.5\n\n\nЧуть более сложные способы вы узнаете из урока swirl ниже.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl() и пройдите урок 5 Missing Values.\n\n\nГотово? Тогда попробуйте ответить на вопрос ниже, не выполняя вычислений в R.\n\n\n\n\n\n\nВопрос\n\n\n\nДан вектор x &lt;- c(44, NA, 5, NA). Сколько NA вернет команда x == NA?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl() и пройдите урок 6 Subsetting Vectors.\n\n\nПроверьте, все ли вы поняли из этого урока.\n\n\n\n\n\n\nВопрос\n\n\n\nЕсли вектор x содержит числовые значения и некоторое количество NA, то что вернет команда x[is.na(x)]?\n\n\n\n\nвектор длиной 0\n\n\nвектор всех NA\n\n\nлогический вектор\n\n\nвектор без NA\n\n\nошибку\n\n\n\n\n\nЧто надо изменить в этом коде, чтобы получить все, кроме NA?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#списки",
    "href": "start.html#списки",
    "title": "1  Начало работы",
    "section": "1.9 Списки",
    "text": "1.9 Списки\nВ отличие от атомарных векторов, списки, или рекурсивные векторы, могут хранить данные разных типов.\n\nlist = list(a = c(\"a\", \"b\", \"c\"), b = c(1, 2, 3), c = c(T, F, T))\nlist\n\n$a\n[1] \"a\" \"b\" \"c\"\n\n$b\n[1] 1 2 3\n\n$c\n[1]  TRUE FALSE  TRUE\n\n\nМожно получить доступ как к элементам списка целиком, так и к их содержимому.\n\nlist$a # обращение к поименованным элементам \n\n[1] \"a\" \"b\" \"c\"\n\nlist[2] # одинарные квадратные скобки извлекают элемент списка целиком\n\n$b\n[1] 1 2 3\n\nclass(list[2])\n\n[1] \"list\"\n\nlist[[2]] #  элементы второго элемента \n\n[1] 1 2 3\n\nclass(list[[2]])\n\n[1] \"numeric\"\n\nlist$c[1]# первый элемент второго элемента\n\n[1] TRUE\n\n\nОбратите внимание, что list[2] и list[[2]] возвращают объекты разных классов. Нам это еще понадобится при работе с XML.\n\n\n\nИндексирование списка в R. Источник 🧂\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nУстановите библиотеку rcorpora и загрузите список с названиями хлеба и сладкой выпечки.\nlibrary(rcorpora)\nmy_list &lt;-  corpora(\"foods/breads_and_pastries\")\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nУзнайте длину my_list и введите ее в поле ниже.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nДостаньте из my_list элемент pastries и узнайте его длину.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nА теперь извлеките пятый элемент из pastries и введите ниже его название.\n\n\n\n\n\n\n\n\nСо списками покончено. Теперь можно пойти выпить кофе с my_list$pastries[13]. Дальше будет сложнее, но интереснее.\n\n\n\n\nBurns, Patrick. 2012. The R inferno. Lulu.com.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "tabular.html#работа-с-датафреймами",
    "href": "tabular.html#работа-с-датафреймами",
    "title": "2  Таблицы",
    "section": "2.4 Работа с датафреймами",
    "text": "2.4 Работа с датафреймами\n\n# узнать имена столбцов\ncolnames(curricula_df) \n\n[1] \"author\"     \"title\"      \"comment\"    \"curriculum\" \"id\"        \n[6] \"year\"       \"grade\"      \"priority\"  \n\n\n\n# извлечь ряд(ы) по значению\ncurricula_df[curricula_df$year == \"1919\", ]\n\n\n  \n\n\n\n\n# извлечь столбец \ncurricula_df$year |&gt; head()\n\n[1] \"1919\" \"1919\" \"1919\" \"1919\" \"1919\" \"1919\"\n\ncurricula_df[ , \"year\"] |&gt; head()\n\n[1] \"1919\" \"1919\" \"1919\" \"1919\" \"1919\" \"1919\"\n\ncurricula_df[ , 6] |&gt;  head()\n\n[1] \"1919\" \"1919\" \"1919\" \"1919\" \"1919\" \"1919\"\n\n\n\n# узнать тип данных в столбцах\nstr(curricula_df) \n\n'data.frame':   10306 obs. of  8 variables:\n $ author    : chr  \"Андреев Л.Н.\" \"Андреев Л.Н.\" \"Андреев Л.Н.\" \"Бальмонт К.Д.\" ...\n $ title     : chr  \"Жили-были\" \"Иуда\" \"Рассказ о семи повешенных\" \"\" ...\n $ comment   : chr  \"\" \"\" \"\" \"\" ...\n $ curriculum: chr  \"19 ИРЛ 2 ст\" \"19 ИРЛ 2 ст\" \"19 ИРЛ 2 ст\" \"19 ИРЛ 2 ст\" ...\n $ id        : int  1 1 1 1 1 1 1 1 1 1 ...\n $ year      : chr  \"1919\" \"1919\" \"1919\" \"1919\" ...\n $ grade     : int  9 9 9 9 9 8 8 8 8 8 ...\n $ priority  : chr  \"\" \"\" \"*\" \"*\" ...\n\n\n\n# преобразовать тип данных в столбцах\ncurricula_df$year &lt;- as.numeric(curricula_df$year)\n\n\n# вывести сводку\nsummary(curricula_df)\n\n    author             title             comment           curriculum       \n Length:10306       Length:10306       Length:10306       Length:10306      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n       id             year          grade          priority        \n Min.   : 1.00   Min.   :1919   Min.   : 5.000   Length:10306      \n 1st Qu.:13.00   1st Qu.:1946   1st Qu.: 8.000   Class :character  \n Median :31.00   Median :1966   Median :10.000   Mode  :character  \n Mean   :28.01   Mean   :1963   Mean   : 9.195                     \n 3rd Qu.:42.00   3rd Qu.:1981   3rd Qu.:10.000                     \n Max.   :50.00   Max.   :1991   Max.   :11.000                     \n                 NA's   :12                                        \n\n\nНебольшое упражнение на кодинг позволит закрепить навыки работы с матрицами и датафреймами.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl() и пройдите урок 7 Matrices and Data Frames.\n\n\nВсе ли вы запомнили?\n\n\n\n\n\n\nВопрос\n\n\n\nДля чего нужна функция cbind()?\n\n\n\n\nдля добавления рядов\n\n\nдля добавления столбцов\n\n\nдля извлечения имен столбцов\n\n\nдля извлечения имен рядов\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nФункция colnames() позволяет как назначать новые имена таблице, так и извлекать существующие.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПрактическое задание “Испанские писатели”.\n\n\n\n# устанавливаем и загружаем нужный пакет\ninstall.packages(\"languageR\")\nlibrary(languageR)\n\n# загружаем датасет\nmeta &lt;- spanishMeta\n\n# допишите ваш код ниже\n# посчитайте средний год публикации романов Камило Хосе Селы\n\n\n# вычислите суммарное число слов в романах Эдуардо Мендосы\n\n\n# извлеките ряды с текстами, опубликованными до 1980 г.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "tabular.html#обобщение-данных",
    "href": "tabular.html#обобщение-данных",
    "title": "2  Таблицы",
    "section": "2.8 Обобщение данных",
    "text": "2.8 Обобщение данных\nТеперь вернемся к датасету curricula и попробуем частично воспроизвести результаты, полученные авторами проекта “Список чтения”, упомянутого выше.\nУ каких авторов больше всего произведений (во всех программах)?\n\ncurricula_tbl |&gt; \n  group_by(author, title) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nКакие произведения упоминаются в программах чаще всего?\n\ncurricula_tbl |&gt; \n  group_by(author, title) |&gt; \n  count() |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nНа принятые в каких годах программы приходится больше всего произведений? (Объяснение здесь.)\n\ncurricula_tbl |&gt; \n  group_by(year) |&gt; \n  distinct(author, title) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nВ заключение попробуйте сформулировать новые вопросы и ответить на них при помощи этого датасета.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Таблицы</span>"
    ]
  },
  {
    "objectID": "plot.html",
    "href": "plot.html",
    "title": "3  Визуализации",
    "section": "",
    "text": "3.1 Графические системы\nВ R есть несколько графических систем: базовый R, lattice и ggplot2. В этом курсе мы будем работать лишь с ggplot2 как с наиболее современной. Если вам интересны первые две, то вы можете обратиться к версии курса 2023/2024 г. и к интерактивным урокам swirl.\nНастоящая графическая сила R – это пакет ggplot2. В его основе лежит идея “грамматики графических элементов” Лиланда Уилкинсона (Мастицкий 2017) (отсюда “gg” в названии). С одной стороны, вы можете постепенно достраивать график, добавляя элемент за элементом (как в базовом R); с другой – множество параметров подбираются автоматически, как в Lattice.\nО различных видах графиков можно почитать по ссылке. В этом уроке мы научимся строить диаграмму рассеяния (scatter plot), столбиковую диаграмму (bar chart) и линейную диаграмму (line chart).\nВот к чему мы стремимся.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#графические-системы",
    "href": "plot.html#графические-системы",
    "title": "3  Визуализации",
    "section": "",
    "text": "Задание\n\n\n\nЗапустите swirl(); курс R Programming у вас уже установлен. Из него сделайте урок 15 Base Graphics. Также установите курс swirl::install_course(\"Exploratory Data Analysis\"). Из него можно пройти любые уроки: это необязательно, но поможет разобраться в теме.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#датасет-метаданные-романов-xix-xx-вв.",
    "href": "plot.html#датасет-метаданные-романов-xix-xx-вв.",
    "title": "3  Визуализации",
    "section": "3.2 Датасет: метаданные романов XIX-XX вв.",
    "text": "3.2 Датасет: метаданные романов XIX-XX вв.\nЗнакомиться с ggplot2 мы будем на примере датасета из коллекции “NovelTM Datasets for English-Language Fiction, 1700-2009”, подготовленного Тедом Андервудом, Патриком Кимутисом и Джессикой Уайт. Они собрали метаданные о 210,266 томах художественной прозы в HathiTrust Digital Library и составили из них несколько датасетов.\nМы возьмем небольшой датасет, который содержит провернные вручную метаданные, а также сведения о категории художественной прозы для 2,730 произведений, созданных в период 1799-2009 г. (равные выборки для каждого года). Об особенностях сбора и подготовки данных можно прочитать по ссылке. Нужный нам файл (в формате tsv) скопирован в репозиторий курса.\n\nurl &lt;- \"https://github.com/locusclassicus/text_analysis_2024/raw/main/files/manual_title_subset.tsv\"\ndownload.file(url, destfile = \"../files/manual_title_subset.tsv\")\n\nПрежде всего избавимся от лишних столбцов и посмотрим на данные.\n\nlibrary(tidyverse)\nnoveltm &lt;- read_tsv(\"../files/manual_title_subset.tsv\")\n\nnoveltm &lt;- noveltm |&gt; \n  select(author, inferreddate, latestcomp, gender, nationality, shorttitle, category)\n\nnoveltm\n\n\n  \n\n\n\nМы попробуем проверить наблюдение, сделанное Франко Моретти в статье “Корпорация стиля: размышления о 7 тысячах заглавий (британские романы 1740-1850)” (2009 г., рус. перевод в книге “Дальнее чтение”, 2016 г.). Моретти заметил, что на протяжении XVIII-XIX вв. названия становятся короче, причем уменьшается не только среднее, но и стандартное отклонение (т.е. разброс значений). В публикации он предлагает несколько возможных объяснений для этого тренда. В датасете NovelTM есть не только романы (и не только британские), но тем более интересно будет сравнить результат.\nВ наших данных сведения о публикации хранятся в столбце inferreddate, а названия – в столбце shorttitle. Количество слов в названии придется посчитать: для этого можно посчитать количество пробелов и добавить единицу.\n\nnoveltm &lt;- noveltm |&gt; \n  mutate(n_words = str_count(shorttitle, \" \"))\n\nnoveltm",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#слой-за-слоем",
    "href": "plot.html#слой-за-слоем",
    "title": "3  Визуализации",
    "section": "3.3 Слой за слоем",
    "text": "3.3 Слой за слоем\nФункция ggplot() имеет два основных аргумента: data и mapping. Аргумент mapping задает эстетические атрибуты геометрических объектов. Обычно используется в виде mapping = aes(x, y), где aes() означает aesthetics.\nПод “эстетикой” подразумеваются графические атрибуты, такие как размер, форма или цвет. Вы не увидите их на графике, пока не добавите какие-нибудь “геомы” – геометрические объекты (точки, линии, столбики и т.п.). Эти объекты могут слоями накладываться друг на друга (Wickham и Grolemund 2016). Попробуем.\n\nnoveltm |&gt; \n  ggplot(aes(inferreddate, n_words)) + \n  geom_point()\n\n\n\n\n\n\n\n\nУпс. Точек очень много, и они накладываются друг на друга, т.к. число слов – дискретная величина. Поступим так же, как Моретти, который отразил на графике среднее для каждого года. Для этого нам надо снова поколдовать над данными.\n\nnoveltm_summary &lt;- noveltm |&gt;\n  group_by(inferreddate) |&gt;\n  summarise(n = n(),\n            mean_w = mean(n_words, na.rm = TRUE)) |&gt; \n  filter(n &gt; 1)\n\nnoveltm_summary\n\n\n  \n\n\n\nСнова попробуем изобразить. Добавим линию тренда, изменим внешний вид точек и тему оформления, а также уберем подпись оси X.\n\nnoveltm_summary |&gt; \n  ggplot(aes(inferreddate, mean_w)) +\n  geom_point(color = \"steelblue\", alpha = 0.7, size = 2) +\n  geom_smooth(color = \"tomato\") + \n  theme_bw() +\n  xlab(NULL)\n\n\n\n\n\n\n\n\nХорошо прослеживается нисходящая тенденция.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#кодирование-категориальных-переменных",
    "href": "plot.html#кодирование-категориальных-переменных",
    "title": "3  Визуализации",
    "section": "3.4 Кодирование категориальных переменных",
    "text": "3.4 Кодирование категориальных переменных\nВ столбце nationality хранятся данные о происхождении писателя.\n\nnoveltm |&gt; \n  group_by(nationality) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nОтберем только английских и американских авторов и сравним тенденции в этих двух группах.\n\nnoveltm_sel &lt;- noveltm |&gt; \n  filter(nationality %in% c(\"uk\", \"us\")) |&gt; \n  group_by(nationality, inferreddate) |&gt; \n  summarise(n = n(),\n            mean_w = mean(n_words, na.rm = TRUE)) |&gt; \n  filter(n &gt; 1) |&gt; \n  select(-n)\n\nnoveltm_sel\n\n\n  \n\n\n\nТеперь сравним две группы графически, а также добавим заголовок и подзаголовок.\n\nnoveltm_sel |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth() +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL\n  )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#оформление",
    "href": "plot.html#оформление",
    "title": "3  Визуализации",
    "section": "3.5 Оформление",
    "text": "3.5 Оформление\nGgplot2 дает возможность легко поменять цветовую палитру и шрифтовое оформление, а также добавить фон.\nШкалы ColorBrewer scale_color_brewer() и scale_fill_brewer() позволяют использовать специально подобранные палитры хорошо сочетаемых цветов. Посмотреть эти шкалы можно на сайте https://colorbrewer2.org.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс “Exploratory Data Analysis” и пройдите из него урок 7 Working with Colors. Это необязательно, но поможет лучше понять, как устроена работа с цветом в R.\n\n\nОбщее правило для выбора таково.\n\nЕсли дана качественная переменная с упорядоченными уровнями (например, “холодный”, “теплый”, “горячий”) или количественная переменная, и необходимо подчеркнуть разницу между высокими и низкими значениями, то для визуализации подойдет последовательная шкала.\nЕсли дана количественная переменная с осмысленным средним значением, например нулем, 50%, медианой, целевым показателем и т.п., то выбираем расходящуюся шкалу.\nЕсли дана качественная переменная, уровни которой невозможно упорядочить (названия городов, имена авторов и т.п.), ищем качественную шкалу.\n\n.\nУ нас две качественные группы, поэтому выбираем качественную шкалу. На рисунке они посредине (в R есть и другие шкалы, но пока о них не будет). Цвета можно задавать и вручную по названию или коду.\n\n\nnoveltm_sel |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth(se = FALSE) +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL) +\n  scale_color_brewer(palette = \"Dark2\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nДобавим шрифтов.\n\nlibrary(showtext)\nfont_add_google(\"Special Elite\", family = \"special\")\nshowtext_auto()\n\nnoveltm_sel |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth(se = FALSE) +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL) +\n  scale_color_brewer(palette = \"Dark2\") + \n  theme(\n    axis.title = element_text(family = \"special\"),\n    title = element_text(family = \"special\")\n  )\n\n\n\n\n\n\n\n\nФинальный штрих.\n\nlibrary(ggimage)\nurl &lt;- \"https://img.freepik.com/premium-photo/stack-old-books-white-background_427771-2463.jpg?w=1800\"\n\nfont_add_google(\"Special Elite\", family = \"special\")\nshowtext_auto()\n\n\ng &lt;- noveltm_sel |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.5, size = 1.5) +\n  geom_smooth(se = FALSE) +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL) +\n  scale_color_brewer(\"country\", palette = \"Dark2\") + \n  theme(\n    axis.title = element_text(family = \"special\", color = \"sienna\"),\n    title = element_text(family = \"special\", color = \"sienna\"),\n    axis.text = element_text(color = \"sienna\"),\n    axis.ticks = element_blank(),\n    plot.margin = unit(c(0.4, 2, 0.4, 0.4), \"inches\"), # t, r, b, l\n    panel.border = element_rect(color = \"sienna\"),\n    legend.position = c(0.8, 0.8),\n    #legend.box.background =  element_rect(color = \"sienna\")\n  )\n\nggbackground(g, url)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс “Exploratory Data Analysis” и пройдите из него урок 9 GGPlot2 Part2.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nНа одной диаграмме может быть несколько геомов.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nВсе эстетические атрибуты для всех геомов задаются при вызове ggplot().\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nОтметьте все термины “грамматики графических элементов” ggplot2.\n\n\n\n\nданные\n\n\nгеометрические объекты\n\n\nстатистические преобразования\n\n\nшкалы\n\n\nсистемы координат\n\n\nфасеты",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#категоризованный-график",
    "href": "plot.html#категоризованный-график",
    "title": "3  Визуализации",
    "section": "3.8 Категоризованный график",
    "text": "3.8 Категоризованный график\nРазличные группы данных можно выделять не только цветом и формой, но и помещать каждую в свое окошко (facet).\nПока не расслабляемся, впереди еще один урок swirl.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс “Exploratory Data Analysis” и пройдите из него урок 10 GGPlot2 Extras.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nЧтобы построить диаграмму рассеяния, нужно добавить к графическому объекту, созданному функцией ggplot, геометрический объект под названием geom_scatterplot.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nФункция cut() позволяет преобразовать числовой вектор в фактор.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nПолуинтервал (0.2,0.5] включает 0.2 и не включает 0.5.\n\n\n\n\nПравда\nЛожь",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#экспорт-графиков-из-среды-r",
    "href": "plot.html#экспорт-графиков-из-среды-r",
    "title": "3  Визуализации",
    "section": "3.10 Экспорт графиков из среды R",
    "text": "3.10 Экспорт графиков из среды R\nСпособы:\n\nреализованные в R драйверы стандартных графических устройств;\nфункция ggsave()\nменю программы RStudio.\n\n\n# код сохранит pdf в рабочую директорию \npdf(file = \"plot.pdf\")\n \ng \n\ndev.off()\n\nЕще один способ сохранить последний график из пакета ggplot2.\n\nggsave(\n  filename = \"plot.png\",\n  plot = last_plot(),\n  device = \"png\",\n  scale = 1,\n  width = NA,\n  height = 500,\n  units = \"px\",\n  dpi = 300\n)\n\n\n\n\n\n\n\nЗадание\n\n\n\nПРАКТИЧЕСКОЕ ЗАДАНИЕ 2: СТАРОФРАНЦУЗСКАЯ ЛИТЕРАТУРА\n\n\n\n\n# загружаем нужные пакеты\nlibrary(languageR)\nlibrary(ggplot2)\n\n# загружаем датасет\nmeta &lt;- oldFrenchMeta\n\n# допишите ваш код ниже\n# постройте столбиковую диаграмму, \n# показывающую распределение произведений по темам; цветом закодируйте жанр; \n# уберите названия осей; \n# поверните координатную ось; \n# поменяйте тему оформления на черно-белую, \n# а шрифт -- на Palatino; \n# добавьте заголовок \"Plot by [Your Name]\"\n\n\n\n#  экспортируйте график в формате jpg \n# с раширением 300 dpi; \n# в названии файла должна быть \n# ваша фамилия и номер группы\n\n\n\n\n\nUnderwood, Ted. 2019. Distant Horizons: Digital Evidence and Literary Change. University of Chicago Press.\n\n\nWickham, Hadley, и Garrett Grolemund. 2016. R for Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.\n\n\nМастицкий, Сергей. 2017. Визуализация данных с помощью ggplot2. ДМК.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#цветовые-шкалы",
    "href": "plot.html#цветовые-шкалы",
    "title": "3  Визуализации",
    "section": "3.5 Цветовые шкалы",
    "text": "3.5 Цветовые шкалы\nGgplot2 дает возможность легко поменять цветовую палитру и шрифтовое оформление, а также добавить фон.\nФункции scale_color_brewer() и scale_fill_brewer() позволяют использовать специально подобранные палитры хорошо сочетаемых цветов. Посмотреть эти палитры можно на сайте https://colorbrewer2.org.\nОбщее правило для выбора таково.\n\nЕсли дана качественная переменная с упорядоченными уровнями (например, “холодный”, “теплый”, “горячий”) или количественная переменная, и необходимо подчеркнуть разницу между высокими и низкими значениями, то для визуализации подойдет последовательная шкала.\nЕсли дана количественная переменная с осмысленным средним значением, например нулем, 50%, медианой, целевым показателем и т.п., то выбираем расходящуюся шкалу.\nЕсли дана качественная переменная, уровни которой невозможно упорядочить (названия городов, имена авторов и т.п.), ищем качественную шкалу.\n\n\n\n\nИсточник.\n\n\nВот основные (но не единственные!) цветовые шкалы в R. Также цвета можно задавать и вручную – по названию или коду.\n\n\nnoveltm_nation |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth(se = FALSE) +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL) +\n  scale_color_brewer(palette = \"Dark2\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#шрифты",
    "href": "plot.html#шрифты",
    "title": "3  Визуализации",
    "section": "3.6 Шрифты",
    "text": "3.6 Шрифты\nПакет ggplot2 и расширения для него дают возможность использовать пользовательские шрифты.\n\nlibrary(showtext)\nfont_add_google(\"Special Elite\", family = \"special\")\nshowtext_auto()\n\nnoveltm_nation |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth(se = FALSE) +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL) +\n  scale_color_brewer(palette = \"Dark2\") + \n  theme(\n    axis.title = element_text(family = \"special\"),\n    title = element_text(family = \"special\")\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#изображения",
    "href": "plot.html#изображения",
    "title": "3  Визуализации",
    "section": "3.7 Изображения",
    "text": "3.7 Изображения\nИзображения можно добавлять и в качестве фона, и вместо отдельных геомов, например точек. Поправим цвета, чтобы они лучше сочетались с цветом изображения.\n\nlibrary(ggimage)\nurl &lt;- \"./images/book.jpg\"\n\nfont_add_google(\"Special Elite\", family = \"special\")\nshowtext_auto()\n\n\ng &lt;- noveltm_nation |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth(se = FALSE) +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009 \\n \",\n    x = NULL,\n    y = NULL) +\n  scale_color_manual(\"country\", values = c(\"#A03B37\", \"#50684E\")) + \n  theme(\n    axis.title = element_text(family = \"special\", color = \"#8B807C\"),\n    title = element_text(family = \"special\", color = \"#52211E\"),\n    axis.text = element_text(color = \"#52211E\"),\n    axis.ticks = element_blank(),\n    plot.margin = unit(c(0.4, 3, 0.4, 0.4), \"inches\"), # t, r, b, l\n    panel.border = element_rect(color = \"#8B807C\"),\n    legend.position = c(0.8, 0.8)\n  )\n\nggbackground(g, url)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#зависимости",
    "href": "plot.html#зависимости",
    "title": "3  Визуализации",
    "section": "3.3 Зависимости",
    "text": "3.3 Зависимости\nФункция ggplot() имеет два основных аргумента: data и mapping. Аргумент mapping задает эстетические атрибуты геометрических объектов. Обычно используется в виде mapping = aes(x, y), где aes() означает aesthetics.\nПод “эстетикой” подразумеваются графические атрибуты, такие как размер, форма или цвет. Вы не увидите их на графике, пока не добавите какие-нибудь “геомы” – геометрические объекты (точки, линии, столбики и т.п.). Эти объекты могут слоями накладываться друг на друга (Wickham и Grolemund 2016). Диаграмма рассеяния создается при помощи geom_point(). Попробуем настройки по умолчанию.\n\nnoveltm |&gt; \n  ggplot(aes(inferreddate, n_words)) + \n  geom_point()\n\n\n\n\n\n\n\n\nУпс. Точек очень много, и они накладываются друг на друга, т.к. число слов – дискретная величина. Поступим так же, как Моретти, который отразил на графике среднее для каждого года. Для этого нам надо снова поколдовать над данными.\n\nnoveltm_summary &lt;- noveltm |&gt;\n  group_by(inferreddate) |&gt;\n  summarise(n = n(),\n            mean_w = mean(n_words, na.rm = TRUE)) |&gt; \n  filter(n &gt; 1)\n\nnoveltm_summary\n\n\n  \n\n\n\nСнова попробуем изобразить. Добавим линию тренда, изменим внешний вид точек и тему оформления, а также уберем подпись оси X.\n\nnoveltm_summary |&gt; \n  ggplot(aes(inferreddate, mean_w)) +\n  geom_point(color = \"steelblue\", alpha = 0.7, size = 2) +\n  geom_smooth(color = \"tomato\") + \n  theme_bw() +\n  xlab(NULL)\n\n\n\n\n\n\n\n\nХорошо прослеживается нисходящая тенденция, о которой писал Моретти.\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс “Exploratory Data Analysis” и пройдите из него урок 9 GGPlot2 Part2.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nНа одной диаграмме может быть несколько геомов.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nВсе эстетические атрибуты для всех геомов задаются при вызове ggplot().\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nОтметьте все термины “грамматики графических элементов” ggplot2.\n\n\n\n\nданные\n\n\nгеометрические объекты\n\n\nстатистические преобразования\n\n\nшкалы\n\n\nсистемы координат\n\n\nфасеты",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#сравнение-двух-групп",
    "href": "plot.html#сравнение-двух-групп",
    "title": "3  Визуализации",
    "section": "3.4 Сравнение двух групп",
    "text": "3.4 Сравнение двух групп\nВ столбце nationality хранятся данные о происхождении писателя.\n\nnoveltm |&gt; \n  group_by(nationality) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nОтберем только английских и американских авторов и сравним тенденции в этих двух группах.\n\nnoveltm_nation &lt;- noveltm |&gt; \n  filter(nationality %in% c(\"uk\", \"us\")) |&gt; \n  group_by(nationality, inferreddate) |&gt; \n  summarise(n = n(),\n            mean_w = mean(n_words, na.rm = TRUE)) |&gt; \n  filter(n &gt; 1) |&gt; \n  select(-n) |&gt; \n  arrange(-mean_w)\n\nnoveltm_nation\n\n\n  \n\n\n\nКатегориальную переменную (национальность) в нашем случае проще всего закодировать цветом. Также добавим заголовок и подзаголовок.\n\nnoveltm_nation |&gt; \n  ggplot(aes(inferreddate, mean_w, color = nationality)) +\n  geom_point(alpha = 0.7, size = 1.5) +\n  geom_smooth() +\n  theme_bw() +\n  labs(\n    title = \"Title Length in UK and US\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL\n  )\n\n\n\n\n\n\n\n\nДля разведывательного анализа данных вполне достаточно настроек по умолчанию, но для публикации вы, вероятно, захотите вручную поправить шрифтовое и цветовое оформление.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#распределения",
    "href": "plot.html#распределения",
    "title": "3  Визуализации",
    "section": "3.8 Распределения",
    "text": "3.8 Распределения\nДля визуализации распределений качественных переменных подходит стобиковая диаграмма, которая наглядно показывает число наблюдений в каждой группе.\nВ датасете NovelTM представлены следующие категории литературы.\n\nnoveltm |&gt; \n  ggplot(aes(category, fill = category)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nНас будет интересовать категория longfiction, т.к. именно сюда попадает популярный в XIX в. жанр романа. Известно, что примерно до 1840 г. почти половина романистов были женщинами, но к началу XX в. их доля снизилась (Underwood 2019, 133). Отчасти это объясняется тем, что после середины XIX в. профессия писателя становится более престижной, а его социальный статус повышается, что приводит к “джентрификации” романа. Посмотрим, что на этот счет могут сказать данные NovelTM. Переменная gender хранит данные о гендере автора.\n\nnoveltm |&gt; \n  ggplot(aes(gender, fill = gender)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nОтберем лишь одну категорию и два гендера.\n\nnoveltm_lf &lt;- noveltm |&gt; \n  select(inferreddate, gender, category) |&gt; \n  filter(gender != \"u\", category == \"longfiction\") |&gt; \n  select(-category)\n\nnoveltm_lf\n\n\n  \n\n\n\nМожно предположить, что соотношение мужчин и женщин в разные десятилетия менялось. Чтобы это выяснить, нам надо преобразовать данные, указав для каждого года соответствующую декаду, и посчитать число мужчин и женщин в каждой декаде.\n\nnoveltm_decade &lt;- noveltm_lf |&gt; \n  mutate(decade = (inferreddate %/% 10) * 10) \n\nnoveltm_decade\n\n\n  \n\n\n\nЭтого уже достаточно для визуализации, но она будет не очень наглядная.\n\nnoveltm_decade |&gt; \n  ggplot(aes(decade, fill = gender)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nУзнаем, сколько всего наблюдений в каждом десятилетии. В 1790-х всего одно наблюдение, его удаляем.\n\ntotal &lt;- noveltm_decade |&gt; \n  group_by(decade) |&gt; \n  summarise(total = n()) |&gt; \n  filter(total &gt; 1)\n\ntotal\n\n\n  \n\n\n\n\nsummary &lt;- noveltm_decade |&gt; \n  group_by(decade, gender) |&gt; \n  summarise(counts = n()) |&gt; \n  filter(counts &gt; 1)\n\n`summarise()` has grouped output by 'decade'. You can override using the\n`.groups` argument.\n\nsummary\n\n\n  \n\n\n\nТеперь объединим две таблицы и посчитаем долю мужчин и женщин.\n\nnoveltm_share &lt;- summary |&gt; \n  left_join(total) |&gt; \n  mutate(share = counts / total) |&gt; \n  select(-counts, -total)\n\nJoining with `by = join_by(decade)`\n\nnoveltm_share\n\n\n  \n\n\n\nМожно визуализировать.\n\nnoveltm_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = gender)) +\n  geom_line(show.legend = FALSE)\n\n\n\n\n\n\n\n\nГрафик, кажется, подтверждает, что доля женщин в литературе снижалась примерно до середины XX в. Однако при разделении данных на группы можно заметить другую тенденцию.\n\nnoveltm_nation &lt;- noveltm |&gt; \n  filter(category == \"longfiction\") |&gt; \n  select(inferreddate, gender, nationality) |&gt; \n  mutate(nationality = case_when(!nationality %in% c(\"uk\", \"us\") ~ \"other\",\n                                 .default = nationality)) |&gt; \n  filter(gender != \"u\") |&gt; \n  mutate(decade = (inferreddate %/% 10) * 10) \n\nnoveltm_nation\n\n\n  \n\n\ntotal_nation &lt;- noveltm_nation |&gt; \n  group_by(decade) |&gt; \n  summarise(total = n()) |&gt; \n  filter(total &gt; 1)\n\nsummary_nation &lt;- noveltm_nation |&gt; \n  group_by(decade, nationality, gender) |&gt; \n  summarise(counts = n()) |&gt; \n  filter(counts &gt; 1)\n\nsummary_nation\n\n\n  \n\n\nnoveltm_nation_share &lt;- summary_nation |&gt; \n  left_join(total) |&gt; \n  mutate(share = counts / total) |&gt; \n  select(-counts, -total)\n\nnoveltm_nation_share\n\n\n  \n\n\n\n\nnoveltm_nation_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = nationality)) +\n  geom_line()\n\n\n\n\n\n\n\n\nДобавим название и немного поменяем оформление.\n\ng &lt;- noveltm_nation_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = nationality)) +\n  geom_line(size = 2, alpha = 0.7) + \n  theme_minimal() + \n  labs(\n    title = \"Female Writers' Share\",\n    subtitle = \"NovelTM Data 1800-2009 \\n \",\n    x = NULL,\n    y = NULL) +\n  theme(text=element_text(size=14, family=\"serif\")) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ng\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс “Exploratory Data Analysis” и пройдите из него урок 10 GGPlot2 Extras.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nЧтобы построить диаграмму рассеяния, нужно добавить к графическому объекту, созданному функцией ggplot, геометрический объект под названием geom_scatterplot.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nФункция cut() позволяет преобразовать числовой вектор в фактор.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nПолуинтервал (0.2,0.5] включает 0.2 и не включает 0.5.\n\n\n\n\nПравда\nЛожь",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#парадокс-симпсона",
    "href": "plot.html#парадокс-симпсона",
    "title": "3  Визуализации",
    "section": "3.9 Парадокс Симпсона",
    "text": "3.9 Парадокс Симпсона\nГрафик, кажется, подтверждает, что доля женщин в литературе снижалась примерно до середины XX в. Однако при разделении данных на группы можно заметить другую тенденцию. Это явление известно как “парадокс Симпсона”.\n\nnoveltm_nation &lt;- noveltm |&gt; \n  select(inferreddate, gender, nationality) |&gt; \n  mutate(nationality = case_when(!nationality %in% c(\"uk\", \"us\") ~ \"other\",\n                                 .default = nationality)) |&gt; \n  filter(gender != \"u\") |&gt; \n  mutate(decade = (inferreddate %/% 10) * 10) \n\nnoveltm_nation\n\n\n  \n\n\ntotal_nation &lt;- noveltm_nation |&gt; \n  group_by(decade) |&gt; \n  summarise(total = n()) |&gt; \n  filter(total &gt; 1)\n\nsummary_nation &lt;- noveltm_nation |&gt; \n  group_by(decade, nationality, gender) |&gt; \n  summarise(counts = n()) |&gt; \n  filter(counts &gt; 1)\n\n`summarise()` has grouped output by 'decade', 'nationality'. You can override\nusing the `.groups` argument.\n\nnoveltm_nation_share &lt;- summary_nation |&gt; \n  left_join(total) |&gt; \n  mutate(share = counts / total) |&gt; \n  select(-counts, -total)\n\nJoining with `by = join_by(decade)`\n\nnoveltm_nation_share\n\n\n  \n\n\nnoveltm_nation_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = nationality)) +\n  geom_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗапустите swirl(), выберите курс “Exploratory Data Analysis” и пройдите из него урок 10 GGPlot2 Extras.\n\n\nПравда или ложь?\n\n\n\n\n\n\nВопрос\n\n\n\nЧтобы построить диаграмму рассеяния, нужно добавить к графическому объекту, созданному функцией ggplot, геометрический объект под названием geom_scatterplot.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nФункция cut() позволяет преобразовать числовой вектор в фактор.\n\n\n\n\nПравда\nЛожь\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nПолуинтервал (0.2,0.5] включает 0.2 и не включает 0.5.\n\n\n\n\nПравда\nЛожь",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#диаграмма-рассеяния",
    "href": "plot.html#диаграмма-рассеяния",
    "title": "3  Визуализации",
    "section": "3.3 Диаграмма рассеяния",
    "text": "3.3 Диаграмма рассеяния\nФункция ggplot() имеет два основных аргумента: data и mapping. Аргумент mapping задает эстетические атрибуты геометрических объектов. Обычно используется в виде mapping = aes(x, y), где aes() означает aesthetics.\nПод “эстетикой” подразумеваются графические атрибуты, такие как размер, форма или цвет. Вы не увидите их на графике, пока не добавите какие-нибудь “геомы” – геометрические объекты (точки, линии, столбики и т.п.). Эти объекты могут слоями накладываться друг на друга (Wickham и Grolemund 2016).\nДиаграмма рассеяния, которая подходит для отражения связи между двумя переменными, делается при помощи geom_point(). Попробуем настройки по умолчанию.\n\nnoveltm |&gt; \n  ggplot(aes(inferreddate, n_words)) + \n  geom_point()\n\n\n\n\n\n\n\n\nУпс. Точек очень много, и они накладываются друг на друга, так как число слов – дискретная величина. Поступим так же, как Моретти, который отразил на графике среднее для каждого года. Для этого нам надо снова поколдовать над данными.\n\nnoveltm_summary &lt;- noveltm |&gt;\n  group_by(inferreddate) |&gt;\n  summarise(n = n(),\n            mean_w = mean(n_words, na.rm = TRUE)) |&gt; \n  filter(n &gt; 1)\n\nnoveltm_summary\n\n\n  \n\n\n\nСнова построим диаграмму рассеяния. Добавим линию тренда, изменим внешний вид точек и тему оформления, а также уберем подпись оси X.\n\nnoveltm_summary |&gt; \n  ggplot(aes(inferreddate, mean_w)) +\n  geom_point(color = \"steelblue\", alpha = 0.7, size = 2) +\n  geom_smooth(color = \"tomato\") + \n  theme_bw() +\n  xlab(NULL)\n\n\n\n\n\n\n\n\nНисходящая тенденция, о которой писал Моретти, хорошо прослеживается. Но, возможно, она характерна не для всех стран?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#столбиковая-диаграмма",
    "href": "plot.html#столбиковая-диаграмма",
    "title": "3  Визуализации",
    "section": "3.8 Столбиковая диаграмма",
    "text": "3.8 Столбиковая диаграмма\nДля визуализации распределений качественных переменных подходит стобиковая диаграмма, которая наглядно показывает число наблюдений в каждой группе. В датасете NovelTM представлены следующие категории литературы.\n\nnoveltm |&gt; \n  ggplot(aes(category, fill = category)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nНас будет интересовать категория longfiction, т.к. именно сюда попадает популярный в XIX в. жанр романа. Известно, что примерно до 1840 г. почти половина романистов были женщинами, но к началу XX в. их доля снизилась (Underwood 2019, 133). Отчасти это объясняется тем, что после середины XIX в. профессия писателя становится более престижной, а его социальный статус повышается, что приводит к “джентрификации” романа. Посмотрим, что на этот счет могут сказать данные NovelTM. Переменная gender хранит данные о гендере автора.\n\nnoveltm |&gt; \n  ggplot(aes(gender, fill = gender)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nОтберем лишь одну категорию и два гендера.\n\nnoveltm_lf &lt;- noveltm |&gt; \n  select(inferreddate, gender, category) |&gt; \n  filter(gender != \"u\", category == \"longfiction\") |&gt; \n  select(-category)\n\nnoveltm_lf\n\n\n  \n\n\n\nМожно предположить, что соотношение мужчин и женщин в разные десятилетия менялось. Чтобы это выяснить, нам надо преобразовать данные, указав для каждого года соответствующую декаду, и посчитать число мужчин и женщин в каждой декаде.\n\nnoveltm_decade &lt;- noveltm_lf |&gt; \n  mutate(decade = (inferreddate %/% 10) * 10) \n\nnoveltm_decade\n\n\n  \n\n\n\nЭтого уже достаточно для визуализации, но она будет не очень наглядная.\n\nnoveltm_decade |&gt; \n  ggplot(aes(decade, fill = gender)) +\n  geom_bar(position = \"dodge\")\n\n\n\n\n\n\n\n\nУзнаем, сколько всего наблюдений в каждом десятилетии. В 1790-х всего одно наблюдение, его удаляем.\n\ntotal &lt;- noveltm_decade |&gt; \n  group_by(decade) |&gt; \n  summarise(total = n()) |&gt; \n  filter(total &gt; 1)\n\ntotal\n\n\n  \n\n\n\n\nsummary &lt;- noveltm_decade |&gt; \n  group_by(decade, gender) |&gt; \n  summarise(counts = n()) |&gt; \n  filter(counts &gt; 1)\n\nsummary\n\n\n  \n\n\n\nТеперь объединим две таблицы и посчитаем долю мужчин и женщин.\n\nnoveltm_share &lt;- summary |&gt; \n  left_join(total) |&gt; \n  mutate(share = counts / total) |&gt; \n  select(-counts, -total)\n\nJoining with `by = join_by(decade)`\n\nnoveltm_share\n\n\n  \n\n\n\n\nnoveltm_share |&gt; \n  ggplot(aes(decade, share, fill = gender)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nПопробуем развернуть диаграмму - так ее будет легче читать.\n\nnoveltm_share |&gt; \n  ggplot(aes(decade, share, fill = gender)) +\n  geom_bar(stat = \"identity\") + \n  coord_flip() + \n  xlab(NULL) + \n  ylab(NULL)\n\n\n\n\n\n\n\n\nПоскольку нас интересует доля женщин, логично поменять группы местами. Также поменяем порядок, в котором идут года (от меньшего к большему).\n\nnoveltm_share |&gt; \n  ggplot(aes(as.factor(decade), share, fill = gender)) +\n  geom_bar(stat = \"identity\", position = position_fill(reverse = TRUE)) + \n  scale_x_discrete(limits = rev) +\n  coord_flip() + \n  ylab(NULL) + \n  xlab(NULL) + \n  theme_minimal()\n\n\n\n\n\n\n\n\nУбавим цвет в мужской части диаграммы и добавим заголовки.\n\nnoveltm_share |&gt; \n  ggplot(aes(as.factor(decade), share, fill = gender)) +\n  geom_bar(stat = \"identity\", \n           position = position_fill(reverse = TRUE),\n           color = \"grey\",\n           show.legend = FALSE) + \n  scale_x_discrete(limits = rev) +\n  scale_fill_manual(values = c(\"lightcoral\", \"white\")) +\n  coord_flip() + \n  ylab(NULL) + \n  xlab(NULL) + \n  theme_minimal() +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Women Share per Decade\",\n    subtitle = \"NovelTM Data 1800-2009\"\n  ) + \n  theme(text=element_text(size=12, family=\"serif\")) \n\n\n\n\n\n\n\n\nСтоит подвинуть заголовок, убрать просветы между столбцами и добавить подписи.\n\nlabel_data &lt;- noveltm_share |&gt; \n  filter(gender == \"f\") |&gt; \n  mutate(share = round(share, 2))\n\nnoveltm_share |&gt; \n  ggplot(aes(as.factor(decade), share, fill = gender)) +\n  geom_bar(stat = \"identity\", \n           position = position_fill(reverse = TRUE),\n           color = \"darkred\",\n           show.legend = FALSE,\n           width = 1) + \n  scale_x_discrete(limits = rev) +\n  scale_fill_manual(values = c(\"#f5b2b2\", \"white\")) +\n  coord_flip() + \n  ylab(NULL) + \n  xlab(NULL) + \n  theme_minimal() +\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"Women Share per Decade\",\n    subtitle = \"NovelTM Data 1800-2009\"\n  ) + \n  geom_text(data = label_data, aes(label = share), \n            hjust = 1.2, \n            color = \"darkred\",\n            family = \"serif\") +\n  theme(text=element_text(size=12, family=\"serif\", color = \"darkred\"),\n        plot.title.position = \"plot\",\n        axis.text = element_text(color = \"darkred\"),\n        )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "plot.html#линейная-диаграмма",
    "href": "plot.html#линейная-диаграмма",
    "title": "3  Визуализации",
    "section": "3.9 Линейная диаграмма",
    "text": "3.9 Линейная диаграмма\nДанные о доли женщин-писателей можно представить и в виде линии: в нашем случае это не лишено смысла, поскольку ось x – это временная шкала.\n\nnoveltm_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = gender)) +\n  geom_line(show.legend = FALSE)\n\n\n\n\n\n\n\n\nПо умолчанию ось y усекается, и создается впечатление, что доля женщин ок. 1900 падает чуть ли не до нуля. Поправим вручную границы оси.\n\nnoveltm_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = gender)) +\n  geom_line(show.legend = FALSE) +\n  expand_limits(y = 0)\n\n\n\n\n\n\n\n\nГрафик, кажется, подтверждает, что доля женщин в литературе снижалась примерно до середины XX в. Однако при разделении данных на группы можно заметить другую тенденцию.\n\nnoveltm_nation &lt;- noveltm |&gt; \n  filter(category == \"longfiction\") |&gt; \n  select(inferreddate, gender, nationality) |&gt; \n  mutate(nationality = case_when(!nationality %in% c(\"uk\", \"us\") ~ \"other\",\n                                 .default = nationality)) |&gt; \n  filter(gender != \"u\") |&gt; \n  mutate(decade = (inferreddate %/% 10) * 10)\n\nnoveltm_nation\n\n\n  \n\n\ntotal_nation &lt;- noveltm_nation |&gt; \n  group_by(decade) |&gt; \n  summarise(total = n()) |&gt; \n  filter(total &gt; 1)\n\nsummary_nation &lt;- noveltm_nation |&gt; \n  group_by(decade, nationality, gender) |&gt; \n  summarise(counts = n()) |&gt; \n  filter(counts &gt; 1)\n\nsummary_nation\n\n\n  \n\n\nnoveltm_nation_share &lt;- summary_nation |&gt; \n  left_join(total) |&gt; \n  mutate(share = counts / total) |&gt; \n  select(-counts, -total)\n\nnoveltm_nation_share\n\n\n  \n\n\n\n\nnoveltm_nation_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = nationality)) +\n  geom_line() \n\n\n\n\n\n\n\n\nДобавим название и немного поменяем оформление.\n\nnoveltm_nation_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = nationality)) +\n  geom_line(linewidth = 2, alpha = 0.7) + \n  theme_minimal() + \n  labs(\n    title = \"Female Writers' Share\",\n    subtitle = \"NovelTM Data 1800-2009 \\n \",\n    x = NULL,\n    y = NULL) +\n  theme(text=element_text(size=14, family=\"serif\")) + \n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nМожно добавить темную рамку и переместить легенду.\n\ng &lt;- noveltm_nation_share |&gt; \n  filter(gender == \"f\") |&gt; \n  ggplot(aes(decade, share, color = nationality)) +\n  geom_line(linewidth = 2, alpha = 0.7) + \n  theme_light() + \n  labs(\n    title = \"Female Writers' Share\",\n    subtitle = \"NovelTM Data 1800-2009\",\n    x = NULL,\n    y = NULL) +\n  theme(text=element_text(size=14, family=\"serif\"),\n        axis.text = element_text(color = \"white\"),\n        legend.position = c(0.5, 0.84), \n        legend.direction = \"horizontal\",\n        legend.title = element_blank(),\n        legend.text = element_text(color = \"#440151FF\"),\n        legend.background = element_blank(),\n        plot.title = element_text(hjust=0.5, color = \"white\"),\n        plot.subtitle = element_text(hjust=0.5, color = \"white\"),\n        plot.background = element_rect(fill = \"#440151FF\"),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.major.y = element_line(linewidth = 0.5)) + \n  scale_color_viridis_d()\n\ng",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Визуализации</span>"
    ]
  },
  {
    "objectID": "iterate.html",
    "href": "iterate.html",
    "title": "4  Циклы, условия, функции",
    "section": "",
    "text": "4.1 Циклы и их аналоги\nХорошая новость: многие функции в R уже векторизованы, и если необходимо применить функцию к каждому элементу вектора, в большинстве случаев достаточно просто вызвать функцию. Это называется векторизация.\nНапример, у нас есть символьный вектор, и мы хотим узнать количество символов в каждом слове.\nhomer &lt;- c(\"в\", \"мысли\", \"ему\", \"то\", \"вложила\", \"богиня\", \"державная\", \"гера\")\nДля каждого компонента вектора необходимо выполнить одну итерацию цикла, в нашем случае – применить функцию nchar(). В некоторых языках программирования это делается как-то так:\nfor(i in homer) print(nchar(i))\n\n[1] 1\n[1] 5\n[1] 3\n[1] 2\n[1] 7\n[1] 6\n[1] 9\n[1] 4\nМы написали цикл for, который считает количество букв для каждого слова в векторе. Как видно, все сработало. Но в R это избыточно, потому что nchar() уже векторизована:\nnchar(homer)\n\n[1] 1 5 3 2 7 6 9 4\nЭто относится не только ко многим встроенным функциям R, но и к даже к операторам. x + 4 в действительности представляет собой +(x, 4):\nx &lt;- c(1.2, 2.51, 3.8)\n\n`+`(x, 4) \n\n[1] 5.20 6.51 7.80\nКлючевую роль здесь играет переработка данных, о которой мы говорили в первом уроке: короткий вектор повторяется до тех пор, пока его длина не сравняется с длиной более длинного вектора. Как-то так:\n\\[ \\left(\n    \\begin{array}{c}\n      1.2 \\\\\n      2.51 \\\\\n      3.8\n    \\end{array}\n  \\right) + \\left(\n    \\begin{array}{c}\n      4 \\\\\n      4 \\\\\n      4\n    \\end{array}\n  \\right) \\]\nЛишний цикл может замедлить вычисления. Проверим. Дан вектор x &lt;- c(3, 5, 7, 13). Необходимо возвести в квадрат каждое число, а из результата вычесть 100. Выполним двумя способами.\nlibrary(tictoc)\nx &lt;- c(2, 3, 5, 7, 11, 13)\n\n# способ первый\ntic()\nfor (i in x) print(i^2 - 100)\n\n[1] -96\n[1] -91\n[1] -75\n[1] -51\n[1] 21\n[1] 69\n\ntoc()\n\n0.001 sec elapsed\n\n# способ второй \ntic()\nx^2 - 100\n\n[1] -96 -91 -75 -51  21  69\n\ntoc()\n\n0.001 sec elapsed\nДля работы со списками циклы тоже чаще всего избыточны. Снова воспользуемся списком печенек из коллекции rcorpora.\nlibrary(rcorpora)\nmy_list &lt;-  corpora(\"foods/breads_and_pastries\")\npaste(\"Длина списка:\", length(my_list))\n\n[1] \"Длина списка: 3\"\n\nnames(my_list)\n\n[1] \"description\" \"breads\"      \"pastries\"\nКак узнать длину каждого вложенного в список вектора? Попробуем цикл (снова заметим время):\ntic()\nfor (i in 1:length(my_list)) print(length(my_list[[i]]))\n\n[1] 1\n[1] 35\n[1] 20\n\ntoc()\n\n0.002 sec elapsed\nНо в базовом R для таких случаев существуют функционалы lapply() и sapply(). Они принимают на входе список и функцию и применяют функцию к каждому элементу списка. Получается быстрее:\ntic()\nlapply(my_list, length)\n\n$description\n[1] 1\n\n$breads\n[1] 35\n\n$pastries\n[1] 20\n\ntoc()\n\n0.001 sec elapsed\nФункция sapply() упростит результат до вектора (s означает simplify):\ntic()\nsapply(my_list, length)\n\ndescription      breads    pastries \n          1          35          20 \n\ntoc()\n\n0.001 sec elapsed\nЕсли в виде списка хранится корпус, то так можно сделать, например, случайную выборку. Заметьте, как переданы аргументы функции sample().\nlapply(my_list[2:3], sample, 5, replace = TRUE)\n\n$breads\n[1] \"casalinga\"    \"tortilla\"     \"pumpernickel\" \"fruit bread\"  \"flatbread\"   \n\n$pastries\n[1] \"croissant\"     \"mille-feuille\" \"morning bun\"   \"rugelach\"     \n[5] \"croissant\"\nМожет быть, с датафреймами будут полезны циклы? Например, так.\ndf &lt;- data.frame(author=c(\"Joe\",\"Jane\"), year=c(1801,1901), reprints=c(TRUE,FALSE))\ndf\ntic()\nfor (i in seq_along(df)) {\n print(class(df[,i]))\n}\n\n[1] \"character\"\n[1] \"numeric\"\n[1] \"logical\"\n\ntoc()\n\n0.002 sec elapsed\nНо и здесь можно ускориться. Второй аргумент apply означает, что мы работаем со столбцами (1 - строки).\ntic()\napply(df, 2, class)\n\n     author        year    reprints \n\"character\" \"character\" \"character\" \n\ntoc()\n\n0.002 sec elapsed\nЕсть еще vapply(), tapply() и mapply(), но и про них мы не будем много говорить, потому что все их с успехом заменяет семейство map_() из пакета purrr в tidyverse.\nТем не менее, перед освоением семейства map_() стоит потренироваться работать с обычными циклами, особенно если вам не приходилось иметь с ними дела (например, на Python). Несмотря на все недостатки, цикл for интуитивно понятен и часто проще начинать именно с него. Поэтому, прежде чем двинуться дальше, сделаем несколько упражнений из (Wickham и Grolemund 2016, 316).\n# стоит заглянуть в документацию к функции\nout &lt;- \"\"\nfor (x in letters) {\n  out &lt;- stringr::str_c(out, x)\n}\n\n# ответ - всего пять символов...\nx &lt;- sample(100)\nsd &lt;- 0\nfor (i in seq_along(x)) {\n  sd &lt;- sd + (x[i] - mean(x)) ^ 2\n}\nsd &lt;- sqrt(sd / (length(x) - 1))\n\n# надо понять, что тут происходит \nx &lt;- runif(100)\nout &lt;- vector(\"numeric\", length(x))\nout[1] &lt;- x[1]\nfor (i in 2:length(x)) {\n  out[i] &lt;- out[i - 1] + x[i]\n}",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "iterate.html#циклы-и-их-аналоги",
    "href": "iterate.html#циклы-и-их-аналоги",
    "title": "4  Циклы, условия, функции",
    "section": "",
    "text": "На заметку\n\n\n\nВ циклах часто используется буква i. Но никакой особой магии в ней нет, имя переменной можно изменить.\n\n\n\n\n\n\n\n\n\n\n\nОдин из главных принципов программирования на R гласит, что следует обходиться без циклов, а если это невозможно, то циклы должны быть простыми.\n— Нормат Мэтлофф\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПройдите урок 10 lapply and sapply и урок 11 vapply and tapply из курса R Programming в swirl.\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\n\nПосчитайте среднее для всех столбцов в mtcars.\nОпределите тип данных во всех столбцах nycflights13::flights.\nПосчитайте число уникальных значений в каждом столбце iris.\nСгенерируйте 10 случайных чисел из нормального распределения - это делает функция rnorm() - со средним -10, 0, 10.\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПопробуйте избавиться от цикла 😜.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "iterate.html#условия",
    "href": "iterate.html#условия",
    "title": "4  Циклы, условия, функции",
    "section": "4.2 Условия",
    "text": "4.2 Условия\nИногда необходимо ограничить выполнение функции неким условием. Короткие условия можно писать в одну строку без фигурных скобок.\n\ny &lt;-  \"Эйяфьятлайокудль\"\n\nif(nchar(y) &gt; 10) print(\"много букв\")\n\n[1] \"много букв\"\n\n\nБолее сложные и множественные условия требуют фигурных скобок. Можно сравнить это с условным периодом: протасис (всегда либо TRUE, либо FALSE) в круглых скобках, аподосис в фигурных.\n\nif (nchar(y) &gt; 10) {\n  print(\"много букв\")\n} else if (nchar(y) &lt; 5) {\n  print(\"мало букв\")\n} else {\n  print(\"норм букв\")\n}\n\n[1] \"много букв\"\n\n\nТакже в R можно использовать специальную функцию:\n\nifelse(nchar(y) &gt; 10, \"много букв\", \"мало букв\")\n\n[1] \"много букв\"\n\n\nПрописывая условие, не забывайте, что применение булева оператора к вектору возвращает логический вектор:\n\nx &lt;- c(1:10)\nx &gt;= 5\n\n [1] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n\n\nТакое условие вернет ошибку.\n\nif (x &gt;= 5) print(\"все сломалось\")\n\nError in if (x &gt;= 5) print(\"все сломалось\"): the condition has length &gt; 1\n\n\nМожно скорректировать код так:\n\nif (any(x &gt;= 5)) print(\"все сработало\")\n\n[1] \"все сработало\"\n\n\nПо той же причине внутри условия не надо использовать логические операторы | (“или”) или & (“и”), потому что они векторизованы:\n\nx &lt; 3 | x &gt; 7\n\n [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "iterate.html#функции",
    "href": "iterate.html#функции",
    "title": "4  Циклы, условия, функции",
    "section": "4.3 Функции",
    "text": "4.3 Функции\nФункция и код – не одно и то же. Чтобы стать функцией, кусок кода должен получить имя. Но зачем давать имя коду, который и так работает?\nВот три причины, которые приводит Хадли Уикхем:\n\nу функции есть выразительное имя, которое облегчает понимание кода;\nпри изменении требований необходимо обновлять код только в одном месте, а не во многих;\nменьше вероятность случайных ошибок при копировании (например, обновление имени переменной в одном месте, но не в другом)\n\n\nWriting good functions is a lifetime journey.\n— Hadley Wickham\n\nМашине все равно, как вы назовете функцию, но тем, кто будет читать код, не все равно. Имена должны быть информативы (поэтому функция f() – плохая идея). Также не стоит переписывать уже существующие в R имена!\nДалее следует определить формальные аргументы и, при желании, значения по умолчанию. Тело функции пишется в фигурных скобках. В конце кода функции располагается команда return(); если ее нет, то функция возвращает последнее вычисленное значение (см. здесь о том, когда что предпочесть).\nНаписание функций – навык, который можно бесконечно совершенствовать. Начать проще всего с обычного кода. Убедившись, что он работает как надо, вы можете упаковать его в функцию.\nНапример, нам нужна функция, которая ищет совпадения в двух векторах и возвращает совпавшие элементы. Сначала решим задачу для двух векторов.\n\nline1 &lt;- c(\"гнев\", \"богиня\", \"воспой\")\nline2 &lt;- c(\"в\", \"мысли\", \"ему\", \"то\", \"вложила\", \"богиня\", \"державная\", \"гера\")\nidx &lt;- which(line2 %in% line1) # 2\nline2[idx]\n\n[1] \"богиня\"\n\n\nТеперь заменяем фактические переменные на формальные.\n\ncommon_words &lt;- function(x, y){\n  idx &lt;- which(x %in% y)\n  x[idx]\n}\n\nИ применяем к новым данным.\n\nline3 &lt;- c(\"лишь\", \"явилась\", \"заря\", \"розоперстая\", \"вестница\", \"утра\")\nline4 &lt;- c(\"вестница\", \"утра\", \"заря\", \"на\", \"великий\", \"олимп\", \"восходила\")\ncommon_words(line4, line3)\n\n[1] \"вестница\" \"утра\"     \"заря\"    \n\n\n\n\n\n\n\n\nЗадание\n\n\n\nЗагрузите библиотеку swirl, выберите курс R Programming и пройдите из него урок 9 Functions.\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nДля просмотра исходного кода любой функции необходимо…\n\n\n\n\n\n\nиспользовать специальную функцию для просмотра кода\n\n\nнабрать имя функции без аргументов и без скобок\n\n\nединственный способ — найти код функции в репозитории на GitHub\n\n\nвызвать help к функции\n\n\n\n\n\n\n\nНапишем функцию, которая будет центрировать данные, то есть вычитать среднее из каждого значения (забудем на время, что это уже делает базовая scale()):\n\ncenter &lt;- function(x){ \n  n = x - mean(x)\n  return(n) \n}\n\nx &lt;- c(5, 10, 15)\ncenter(x) \n\n[1] -5  0  5\n\n\nВнутри нашей функции есть переменная n, которую не видно в глобальном окружении. Это локальная переменная. Область ее видимости – тело функции. Когда функция возвращает управление, переменная исчезает. Обратное неверно: глобальные переменные доступны в теле функции.\nФункция может принимать произвольное число аргументов. Доработаем наш код:\n\ncenter &lt;- function(x, na.rm = F){\n  if(na.rm) { x &lt;- x[!is.na(x)]} # добавим условие\n  x - mean(x) # на этот раз без return()\n}\n\nx &lt;- c(5, 10, NA)\ncenter(x)\n\n[1] NA NA NA\n\n\nЧто произошло? Почему следующий код выдает другой результат?\n\ncenter(x, na.rm = T)\n\n[1] -2.5  2.5\n\n\nВычисления в R ленивы, то есть они откладываются до тех пор, пока не понадобится результат. Если вы зададите аргумент, который не нужен в теле функции, ошибки не будет.\n\ncenter &lt;- function(x, na.rm = F, what_is_your_name){\n  if(na.rm) { x &lt;- x[!is.na(x)]} # добавим условие\n  x - mean(x) # на этот раз без return()\n}\n\ncenter(x, na.rm = T)\n\n[1] -2.5  2.5\n\ncenter(x, na.rm = T, what_is_your_name = \"Locusclassicus\")\n\n[1] -2.5  2.5\n\n\nЧасто имеет смысл добавить условие остановки или сообщение, которое будет распечатано в консоль при выполнении.\n\ncenter &lt;- function(x){\n  if (length(x) == 1) {stop(\"Отстань, старушка, я в печали.\")}\n  x - mean(x) # на этот раз без return()\n}\n\nx &lt;- 10\ncenter(x) # вернет ошибку\n\n\n\n\n\n\n\nЗадание\n\n\n\nНапишите функцию awesome_plot, которая будет принимать в качестве аргументов два вектора, трансформировать их в тиббл и строить диаграмму рассеяния при помощи ggplot(). Задайте цвет и прозрачность точек, а в подзаголовке выведите коэффициент корреляции.\n\n\n\n\n\n\n\n\nЗадание\n\n\n\n\nНапишите код, который распечатает стихи детской песни “Alice the Camel”.\nПревратите детскую потешку “Ted in the Bed” в функцию. Обобщите до любого числа спящих.\nЗапишите в виде функции текст песни “99 Bottles of Beer on the Wall”. Обобщите до любого числа любых напитков на любой поверхности.\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nНапишите функцию, которая будет говорить “доброе утро”, “добрый день” или “добрый вечер” в зависимости от времени суток. Используйте lubridate::now() в качестве значения аргумента по умолчанию.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "iterate.html#purrr",
    "href": "iterate.html#purrr",
    "title": "4  Циклы, условия, функции",
    "section": "4.4 Purrr",
    "text": "4.4 Purrr\nПо-настоящему мощный инструмент для итераций – это пакет purrr из семейства tidyverse. Разработчики предупреждают, что потребуется время, чтобы овладеть этим инструментом (Wickham и Grolemund 2016).\n\nYou should never feel bad about using a loop instead of a map function. The map functions are a step up a tower of abstraction, and it can take a long time to get your head around how they work.\n— Hadley Wickham & Garrett Grolemund\n\nВ семействе функций map_ из этого пакета всего 23 вариации. Вот основные из них:\n\nmap()\nmap_lgl()\nmap_int()\nmap_dbl()\nmap_chr()\n\nВсе они принимают на входе данные и функцию (или формулу), которую следует к ним применить, и возвращают результат в том виде, который указан после подчеркивания. Просто map() вернет список, а map_int() – целочисленный вектор, и т.д.\nВоспользуемся возможностями purrr, чтобы исследовать датасет starwars из пакета dplyr. Для начала узнаем число отсутствующих значений в каждом столбце. Косая черта (\\) указывает на то, что мы используем анонимную функцию\n\nlibrary(tidyverse)\nstarwars &lt;- starwars\nmap_int(starwars, \\(x) sum(is.na(x)))\n\n      name     height       mass hair_color skin_color  eye_color birth_year \n         0          6         28          5          0          0         44 \n       sex     gender  homeworld    species      films   vehicles  starships \n         4          4         10          4          0          0          0 \n\n\nОбратите внимание, что map_int, как и map_dbl возвращает именованный вектор. Чтобы избавиться от имен, можно использовать unname():\n\nmap_chr(starwars, class) |&gt; \n  unname()\n\n [1] \"character\" \"integer\"   \"numeric\"   \"character\" \"character\" \"character\"\n [7] \"numeric\"   \"character\" \"character\" \"character\" \"character\" \"list\"     \n[13] \"list\"      \"list\"     \n\n\n\nИспользуйте map_dbl и n_distinct, чтобы узнать число уникальных наблюдений в каждом столбце.\n\nЕсли функция принимает дополнительные аргументы, их можно задать после названия функции. В таком случае для каждого вызова функции будет использовано это значение аргумента. В примере ниже это аргумент na.rm.\n\nstarwars |&gt; \n  select(mass, height) |&gt; \n  map(mean, na.rm = TRUE)\n\n$mass\n[1] 97.31186\n\n$height\n[1] 174.6049\n\n\nПри вызове map_df есть дополнительная возможность сохранить названия столбцов, используя аргумент .id:\n\nstarwars |&gt; \n  map_df(~data.frame(unique_values = n_distinct(.x),\n                     col_class = class(.x)),\n         .id = \"variable\"\n         )\n\n\n  \n\n\n\nФункции map можно передать пользовательскую функцию. Для примера создадим функцию describe_vec(), которая возвращает строку с длиной и классом вектора, и применим ее к хлебо-булочному списку из примеров выше.\n\n# пользовательская функция\ndescribe_vec &lt;- function(vec){\n  l = paste(\"Длина вектора: \", length(vec))\n  c = paste(\"Класс вектора: \", class(vec))\n  result = paste(l, c, sep = \" | \")\n  return(result)\n}\n\nmap_chr(my_list, describe_vec) |&gt; \n  unname()\n\n[1] \"Длина вектора:  1 | Класс вектора:  character\" \n[2] \"Длина вектора:  35 | Класс вектора:  character\"\n[3] \"Длина вектора:  20 | Класс вектора:  character\"\n\n\nКроме того, мы можем передать map анонимную функцию (вместо function можно поставить \\):\n\nmap_chr(my_list, \n        function(x) paste(\"Длина вектора: \", length(x))\n        )\n\n         description               breads             pastries \n \"Длина вектора:  1\" \"Длина вектора:  35\" \"Длина вектора:  20\" \n\n\nЕсли необходимо несколько раз вызывать одну и ту же функцию с двумя аргументами, используется функция map2(). Аргументы, которые меняются при каждом вызове, пишутся до функции; аргументы, которые остаются неизменны, – после.\n\nmean = list(5, 10, -3)\nsd = list(1, 5, 50)\nmap2(mean, sd, rnorm, n = 5)\n\n[[1]]\n[1] 5.606236 6.674324 7.120550 4.269691 5.646766\n\n[[2]]\n[1] 18.812590 18.821804 12.961582  8.766922 12.555786\n\n[[3]]\n[1]  28.12704  50.88303 -99.55774  19.01899  49.18838\n\n\n\n\n\n\n_Как работает map2()_\n\n\n\nЭто можно обобщить следующим образом (источник):\n\nМожно было бы предположить, что должны быть и map3(), map4() и т.д., но во всех случаеях, когда у функции больше двух аргументов, используется pmap().\n\n\n\n\n\n\nЗадание\n\n\n\nУстановите курс swirl::install_course(\"Advanced R Programming\") и пройдите из него урок 3 Functional Programming with purrr.\n\n\nНесколько вопросов для самопроверки.\n\n\n\n\n\n\nВопрос\n\n\n\nФункции-предикаты (predicate functions) возвращают TRUE или FALSE. Выберите из списка все функции-предикаты.\n\n\n\n\nevery()\n\n\nsome()\n\n\nnone()\n\n\nhas_element()\n\n\nis.factor()\n\n\nkeep()\n\n\ndiscard()\n\n\nis.numeric()\n\n\ndetect()\n\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nКакие из функций ниже принимают в качестве аргумента функции-предикаты?\n\n\n\n\nevery()\n\n\nsome()\n\n\nnone()\n\n\nhas_element()\n\n\nis.factor()\n\n\nkeep()\n\n\ndiscard()\n\n\nis.numeric()\n\n\ndetect()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "iterate.html#чтение-файлов-с-purrr",
    "href": "iterate.html#чтение-файлов-с-purrr",
    "title": "4  Циклы, условия, функции",
    "section": "4.5 Чтение файлов с purrr",
    "text": "4.5 Чтение файлов с purrr\nВы уже поняли, что благодаря циклам можно прочитать сразу несколько файлов. Та же задача решается и при помощи map. Мы потренируемся на датасете, который в 2023 г. был доступен на сайте Британской библиотеки (https://www.bl.uk/), но потом оттуда исчез. Однако у нас сохранилась копия.\nДатасет представляет собой набор файлов .csv, содержащих метаданные о ресурсах, связанных с Гарри Поттером, из коллекций Британской библиотеки. Первоначально он был выпущен к 20-летию публикации книги «Гарри Поттер и философский камень» 26 июня 2017 года и с тех пор ежегодно обновлялся. Всего в датасете пять файлов, каждый из которых содержит разное представление данных.\nСкачаем архив.\n\nmy_url &lt;- \"https://github.com/locusclassicus/text_analysis_2024/raw/main/files/HP.zip\"\ndownload.file(url = my_url, destfile = \"HP.zip\")\n\nПосле этого переходим в директорию с архивом и распаковываем его.\n\nunzip(\"HP.zip\")\n\n\n\n\n\n\n\nЗадание\n\n\n\nПрактическое задание “Гарри Поттер”\n\n\n\n# сохраните список всех файлов с расширением .csv, \n# используя подходящую функцию из base R\n\n# ваш код здесь\n# my_files &lt;- \n\n# напишите цикл, который:\n# 1) прочитает все файлы из my_files, используя для этого функцию read_csv() из пакета readr\n# (аргумент show_col_types установите на FALSE);\n# 2) для каждого датасета выяснит количество рядов _без_ NA в столбце BNB Number;\n# 3) разделит число таких рядов на общее число рядов;\n# 4) вернет таблицу c четырьми столбцами: \n# - название файла (id), \n# - число рядов (total), \n# - число рядов без NA (complete), \n# - доля полных рядов (ratio)\n\nmy_df &lt;- data.frame(id = my_files, \n                    total = rep(0, length(my_files)),\n                    complete = rep(0, length(my_files)),\n                    ratio = rep(0, length(my_files)))\n\nfor (i in 1:length(my_files)) {\n  # ваш код здесь\n}\n\nУзнаем имена файлов в директории и прочитаем их все одним вызовом функции.\n\n# чтение файлов \nlibrary(readr)\n\nfiles &lt;- list.files(\"../files/HP\", pattern = \".csv\", full.names = TRUE)\n\nHP &lt;- map(files, read_csv, col_types = cols())\n\nОбъект HP – это список. В нем пять элементов, так как на входе у нас было пять файлов. Для удобства назначим имена элементам списка. Пока можно не вникать, что здесь происходит – регулярные выражения мы рассмотрим в одном из следующих уроков.\n\nlibrary(stringr) \nnames(HP) &lt;- str_extract(files, \"\\\\w+(?=.csv)\")\nnames(HP)\n\n[1] \"classification\" \"names\"          \"records\"        \"titles\"        \n[5] \"topics\"        \n\n\nНачнем с простого: при помощи map можно извлечь столбцы (по имени) или ряды (по условию) из всех пяти таблиц. Прежде чем выполнить код ниже, подумайте, как будет выглядеть результат.\n\n# извлечь столбцы\nmap(HP, select, `BNB number`)\n\n# извлечь ряды\nmap(HP, filter, !(is.na(`BNB number`)))\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nИзвлеките все уникальные названия (столбец Title) из всех пяти таблиц в HP. Используйте функцию distinct.\n\n\n\nЧто, если мы не знаем заранее, какие столбцы есть во всех пяти таблицах, и хотим это выяснить? Для этого подойдет функция reduce() из того же purrr. Она принимает на входе вектор (или список) и функцию и применяет функцию последовательно к каждой паре значений.\n\n\n\nИсточник.\n\n\n\nВоспользуемся этим, чтобы найти общие для всех таблиц имена столбцов.\n\nmap(HP, colnames) |&gt; \n  reduce(intersect)\n\n [1] \"Dewey classification\"       \"BL record ID\"              \n [3] \"Type of resource\"           \"Content type\"              \n [5] \"Material type\"              \"BNB number\"                \n [7] \"ISBN\"                       \"ISSN\"                      \n [9] \"Name\"                       \"Dates associated with name\"\n[11] \"Type of name\"               \"Role\"                      \n[13] \"Title\"                      \"Series title\"              \n[15] \"Number within series\"       \"Country of publication\"    \n[17] \"Place of publication\"       \"Publisher\"                 \n[19] \"Date of publication\"        \"Edition\"                   \n[21] \"Physical description\"       \"BL shelfmark\"              \n[23] \"Genre\"                      \"Languages\"                 \n[25] \"Notes\"                     \n\n\nЕще одна неочевидная возможность функции reduce - объединение нескольких таблиц в одну одним вызовом. Например, так:\n\nHP_joined &lt;- HP |&gt; \n  reduce(left_join)\n\nТеперь можно почистить данные и построить несколько разведывательных графиков.\n\nlibrary(ggplot2)\nlibrary(tidyr)\ndata_sum &lt;- HP_joined |&gt; \n  separate(`Date of publication`, into = c(\"year\", NA)) |&gt; \n  separate(`Country of publication`, into = c(\"country\", NA), sep = \";\") |&gt;\n  mutate(country = str_squish(country)) |&gt; \n  mutate(country = \n           case_when(country == \"England\" ~ \"United Kingdom\",\n                     country == \"Scotland\" ~ \"United Kingdom\",\n                     TRUE ~ country)) |&gt; \n  group_by(year, country) |&gt; \n  summarise(n = n()) |&gt; \n  filter(!is.na(year)) |&gt; \n  filter(!is.na(country)) \n  \n\n# график\ndata_sum |&gt; \n  ggplot(aes(year, n, fill = country)) + \n  geom_col() + \n  xlab(NULL) +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nВ качестве небольшого бонуса к этому уроку построим облако слов. Вектор слов возьмем из столбца Topic.\n\nlibrary(tidyr)\ndata_topics &lt;- HP_joined |&gt; \n  filter(!is.na(Topics)) |&gt; \n  separate(Topics, into = c(\"topic\", NA)) |&gt; \n  mutate(topic = tolower(topic)) |&gt; \n  group_by(topic) |&gt; \n  summarise(n = n()) |&gt; \n  filter(!topic %in% c(\"harry\", \"rowling\", \"potter\", \"children\", \"literary\"))\n\n\npal &lt;- c(\"#f1c40f\", \"#34495e\", \n         \"#8e44ad\", \"#3498db\",\n         \"#2ecc71\")\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\npar(mar = c(1, 1, 1, 1))\nwordcloud(data_topics$topic, \n          data_topics$n,\n          min.freq = 3,\n          #max.words = 50, \n          scale = c(3, 0.8),\n          colors = pal, \n          random.color = T, \n          rot.per = .2,\n          vfont=c(\"script\",\"plain\")\n          )\n\n\n\n\n\n\n\n\nИнтерактивное облако слов можно построить с использованием пакета wordcloud2. Сделаем облако в форме шляпы волшебника!\n\n# devtools::install_github(\"lchiffon/wordcloud2\")\nlibrary(wordcloud2)\n\n\nwordcloud2(data_topics, \n           figPath = \"./images/hat.png\",\n           size = 1.5,\n           color=\"random-light\", \n           fontWeight = \"normal\",\n           backgroundColor=\"black\"\n           )\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПрактическое задание “Алиса в стране чудес”\n\n\n\n\n# постройте облако слов для \"Алисы в стране чудес\"\n\nlibrary(languageR)\nlibrary(dplyr)\nlibrary(tidytext)\n\n# вектор с \"Алисой\"\nalice &lt;- tolower(alice)\n\n# частотности для слов\nfreq &lt;- as_tibble(table(alice)) |&gt; \n  rename(word = alice)\n\n# удалить стоп-слова\nfreq_tidy &lt;- freq |&gt; \n  anti_join(stop_words) \n# возможно, вы захотите произвести и другие преобразования\n\n# облако можно строить в любой библиотеке\n\n\n\n\n\nWickham, Hadley, и Garrett Grolemund. 2016. R for Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Литература",
    "section": "",
    "text": "Burns, Patrick. 2012. The R\ninferno. Lulu.com.\n\n\nUnderwood, Ted. 2019. Distant Horizons: Digital\nEvidence and Literary Change. University of Chicago Press.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R\nfor Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.\n\n\nМастицкий, Сергей. 2017. Визуализация Данных с Помощью Ggplot2.\nДМК.",
    "crumbs": [
      "Литература"
    ]
  },
  {
    "objectID": "iterate.html#гарри-поттер-цикл-vs.-map_",
    "href": "iterate.html#гарри-поттер-цикл-vs.-map_",
    "title": "4  Циклы, условия, функции",
    "section": "4.5 Гарри Поттер: цикл vs. map_()",
    "text": "4.5 Гарри Поттер: цикл vs. map_()\nКак вы уже поняли, одни и те же задачи можно решать при помощи циклов и при помощи map_. Мы потренируемся на датасете, который в 2023 г. был доступен на сайте Британской библиотеки (https://www.bl.uk/), но потом оттуда исчез (но у нас сохранилась копия).\nДатасет представляет собой набор файлов .csv, содержащих метаданные о ресурсах, связанных с Гарри Поттером, из коллекций Британской библиотеки. Первоначально он был выпущен к 20-летию публикации книги «Гарри Поттер и философский камень» 26 июня 2017 года и с тех пор ежегодно обновлялся. Всего в датасете пять файлов, каждый из которых содержит разное представление данных.\nСкачаем архив.\n\nmy_url &lt;- \"https://github.com/locusclassicus/text_analysis_2024/raw/main/files/HP.zip\"\ndownload.file(url = my_url, destfile = \"../files/HP.zip\")\n\nПосле этого переходим в директорию с архивом и распаковываем его.\n\nunzip(\"../files/HP.zip\")\n\nСохраним список всех файлов с расширением .csv, используя подходящую функцию из base R.\n\nmy_files &lt;- list.files(\"../files/HP\", pattern = \".csv\", full.names = TRUE)\nmy_files\n\n[1] \"../files/HP/classification.csv\" \"../files/HP/names.csv\"         \n[3] \"../files/HP/records.csv\"        \"../files/HP/titles.csv\"        \n[5] \"../files/HP/topics.csv\"        \n\n\n\n4.5.1 Цикл\nТеперь напишем цикл, который\n\nпрочитает все файлы из my_files, используя для этого функцию read_csv() из пакета readr;\nдля каждого датасета выяснит количество рядов без NA в столбце BNB Number;\nразделит число таких рядов на общее число рядов; (@)) вернет таблицу c четырьми столбцами:\n\n\nназвание файла (id),\nчисло рядов (total),\nчисло рядов без NA (complete),\nдоля полных рядов (ratio).\n\nСначала создаем таблицу, в которую будем складывать результат.\n\nmy_files_short &lt;- list.files(\"../files/HP\", pattern = \".csv\")\n\nmy_df &lt;- data.frame(id = my_files_short, \n                    total = rep(0, length(my_files)),\n                    complete = rep(0, length(my_files)),\n                    ratio = rep(0, length(my_files)))\n\nmy_df\n\n\n  \n\n\n\nТеперь тело цикла:\n\nfor (i in 1:length(my_files)) {\n\n  # читаем очередной файл из my_files\n  current_file &lt;- my_files[i]\n  current_df &lt;- readr::read_csv(current_file, show_col_types = FALSE) \n\n  # выявляем общее число рядов и число рядов без NA в BNB number\n  # из-за пробела в названии столбца BNB number нужно использовать\n  # с бэктиками ``, а не с \"такими\" или 'такими' кавычками \n  current_total &lt;- nrow(current_df)\n  current_complete &lt;- sum(!is.na(current_df$`BNB number`))\n    \n\n  # помещаем значения в нужное место в заранее созданном my_df вместо нулей\n  my_df$total[i] &lt;- current_total  \n  my_df$complete[i] &lt;- current_complete\n  my_df$ratio[i] &lt;- current_complete / current_total\n}\n\nСмотрим на результат.\n\nmy_df\n\n\n  \n\n\n\n\n\n4.5.2 map_()\nТеперь исследуем датасет при помощи функционалов. Прочитаем все файлы одним вызовом функции.\n\n# чтение файлов \nHP &lt;- map(my_files, read_csv, col_types = cols())\n\nОбъект HP – это список. В нем пять элементов, так как на входе у нас было пять файлов. Для удобства назначим имена элементам списка.\n\nnames(HP) &lt;- my_files_short\n\n\nНачнем с простого: при помощи map можно извлечь столбцы (по имени) или ряды (по условию) из всех пяти таблиц. Прежде чем выполнить код ниже, подумайте, как будет выглядеть результат.\n\n# извлечь столбцы\nmap(HP, select, `BNB number`)\n\n# извлечь ряды\nmap(HP, filter, !(is.na(`BNB number`)))\n\n\n\n\n\n\n\nЗадание\n\n\n\nИзвлеките все уникальные названия (столбец Title) из всех пяти таблиц в HP. Используйте функцию distinct.\n\n\nЧто, если мы не знаем заранее, какие столбцы есть во всех пяти таблицах, и хотим это выяснить? Для этого подойдет функция reduce() из того же purrr. Она принимает на входе вектор (или список) и функцию и применяет функцию последовательно к каждой паре значений.\n\n\n\nИсточник.\n\n\n\nВоспользуемся этим, чтобы найти общие для всех таблиц имена столбцов.\n\nmap(HP, colnames) |&gt; \n  reduce(intersect)\n\n [1] \"Dewey classification\"       \"BL record ID\"              \n [3] \"Type of resource\"           \"Content type\"              \n [5] \"Material type\"              \"BNB number\"                \n [7] \"ISBN\"                       \"ISSN\"                      \n [9] \"Name\"                       \"Dates associated with name\"\n[11] \"Type of name\"               \"Role\"                      \n[13] \"Title\"                      \"Series title\"              \n[15] \"Number within series\"       \"Country of publication\"    \n[17] \"Place of publication\"       \"Publisher\"                 \n[19] \"Date of publication\"        \"Edition\"                   \n[21] \"Physical description\"       \"BL shelfmark\"              \n[23] \"Genre\"                      \"Languages\"                 \n[25] \"Notes\"                     \n\n\nЕще одна неочевидная возможность функции reduce - объединение нескольких таблиц в одну одним вызовом. Например, так:\n\nHP_joined &lt;- HP |&gt; \n  reduce(left_join)\n\nHP_joined\n\n\n  \n\n\n\n\n\n4.5.3 EDA\nТеперь можно почистить данные и построить несколько разведывательных графиков.\n\nlibrary(ggplot2)\nlibrary(tidyr)\n\ndata_sum &lt;- HP_joined |&gt; \n  separate(`Date of publication`, into = c(\"year\", NA)) |&gt; \n  separate(`Country of publication`, into = c(\"country\", NA), sep = \";\") |&gt;\n  mutate(country = str_squish(country)) |&gt; \n  mutate(country = \n           case_when(country == \"England\" ~ \"United Kingdom\",\n                     country == \"Scotland\" ~ \"United Kingdom\",\n                     TRUE ~ country)) |&gt; \n  filter(!is.na(year)) |&gt; \n  filter(!is.na(country)) |&gt; \n  group_by(year, country) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(-n)\n  \n\ndata_sum\n\n\n  \n\n\n\n\ndata_sum |&gt; \n  ggplot(aes(year, n, fill = country)) + \n  geom_col() + \n  xlab(NULL) +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nВ качестве небольшого бонуса к этому уроку построим облако слов. Вектор слов возьмем из столбца Topic.\n\ndata_topics &lt;- HP_joined |&gt; \n  filter(!is.na(Topics)) |&gt; \n  separate(Topics, into = c(\"topic\", NA)) |&gt; \n  mutate(topic = tolower(topic)) |&gt; \n  group_by(topic) |&gt; \n  summarise(n = n()) |&gt; \n  filter(!topic %in% c(\"harry\", \"rowling\", \"potter\", \"children\", \"literary\"))\n\n\npal &lt;- c(\"#f1c40f\", \"#34495e\", \n         \"#8e44ad\", \"#3498db\",\n         \"#2ecc71\")\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\npar(mar = c(1, 1, 1, 1))\nwordcloud(data_topics$topic, \n          data_topics$n,\n          min.freq = 3,\n          #max.words = 50, \n          scale = c(3, 0.8),\n          colors = pal, \n          random.color = T, \n          rot.per = .2,\n          vfont=c(\"script\",\"plain\")\n          )\n\n\n\n\n\n\n\n\nИнтерактивное облако слов можно построить с использованием пакета wordcloud2. Сделаем облако в форме шляпы волшебника!\n\n# devtools::install_github(\"lchiffon/wordcloud2\")\nlibrary(wordcloud2)\n\n\nwordcloud2(data_topics, \n           figPath = \"./book/images/Wizard-Hat.png\",\n           size = 1.5,\n           backgroundColor=\"black\",\n           color=\"random-light\", \n           fontWeight = \"normal\",\n)\n\n\nТеперь попробуйте сами.\n\n\n\n\n\n\nЗадание\n\n\n\nПрактическое задание “Алиса в стране чудес”\n\n\n\n# постройте облако слов для \"Алисы в стране чудес\"\n\nlibrary(languageR)\nlibrary(dplyr)\nlibrary(tidytext)\n\n# вектор с \"Алисой\"\nalice &lt;- tolower(alice)\n\n# частотности для слов\nfreq &lt;- as_tibble(table(alice)) |&gt; \n  rename(word = alice)\n\n# удалить стоп-слова\nfreq_tidy &lt;- freq |&gt; \n  anti_join(stop_words) \n# возможно, вы захотите произвести и другие преобразования\n\n# облако можно строить в любой библиотеке\n\n\n\n\n\nWickham, Hadley, и Garrett Grolemund. 2016. R for Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Циклы, условия, функции</span>"
    ]
  },
  {
    "objectID": "import.html",
    "href": "import.html",
    "title": "5  Импорт",
    "section": "",
    "text": "5.1 JSON\nФормат JSON (JavaScript Object Notation) предназначен для представления структурированных данных. JSON имеет шесть основных типов данных. Четыре из них - скаляры:\nСтроки, числа и булевы значения в JSON очень похожи на символьные, числовые и логические векторы в R. Основное отличие заключается в том, что скаляры JSON могут представлять только одно значение. Для представления нескольких значений необходимо использовать один из двух оставшихся типов: массивы и объекты.\nИ массивы, и объекты похожи на списки в R, разница заключается в том, именованы они или нет. Массив подобен безымянному списку и записывается через []. Например, [1, 2, 3] - это массив, содержащий 3 числа, а [null, 1, \"string\", false] - массив, содержащий ноль, число, строку и булево значение.\nОбъект подобен именованному списку и записывается через {}. Имена (ключи в терминологии JSON) являются строками, поэтому должны быть заключены в кавычки. Например, {“x”: 1, “y”: 2} - это объект, который сопоставляет x с 1, а y – с 2.\nЗагрузим небольшой файл TBBT.json, хранящий данные о сериале “Теория большого взрыва” (источник). Скачать лучше из репозитория курса ссылка.\nlibrary(jsonlite)\n\npath &lt;- \"../files/TBBT.json\"\ntbbt &lt;- fromJSON(txt =  path,\n                 simplifyVector = T)\nФункция fromJSON() вернула нам список, в предпросмотре он выглядит так.\nВыборочно преобразуем список в тиббл:\nlibrary(tidyverse)\n\ncast_tbl &lt;- tbbt$casting |&gt; \n  transpose() |&gt; \n  map(as.character) |&gt; \n  as_tibble()\n\ncast_tbl\nПроделаем то же самое для списка эпизодов, но немного другим способом.\nepisodes_tbl &lt;- tibble(\n  episode_id = map_chr(tbbt$episode_list, pluck, \"episode_id\"),\n  title = map_chr(tbbt$episode_list, pluck, \"title\"))\n\nepisodes_tbl",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Импорт</span>"
    ]
  },
  {
    "objectID": "import.html#json",
    "href": "import.html#json",
    "title": "5  Импорт",
    "section": "",
    "text": "cамый простой тип - null (нуль), который играет ту же роль, что и NA в R. Он представляет собой отсутствие данных;\ncтрока (string) похожа на строку в R, но в ней всегда должны использоваться двойные кавычки;\nчисло аналогично числам в R, при этом поддерживается целочисленная (например, 123), десятичная (например, 123.45) или научная (например, 1,23e3) нотация. JSON не поддерживает Inf, -Inf или NaN;\nлогическое значение аналогично TRUE и FALSE в R, но использует строчные буквы true и false.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nСамостоятельно создайте тиббл, в котором будет храниться количество серий для каждого сезона.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Импорт</span>"
    ]
  },
  {
    "objectID": "import.html#xml",
    "href": "import.html#xml",
    "title": "5  Импорт",
    "section": "5.2 XML",
    "text": "5.2 XML\nXML (от англ. eXtensible Markup Language) — расширяемый язык разметки. Слово “расширяемый” означает, что список тегов не зафиксирован раз и навсегда: пользователи могут вводить свои собственные теги и создавать так называемые настраиваемые языки разметки (Холзнер 2004, 29). Один из таких настраиваемых языков – это TEI (Text Encoding Initiative), о котором будет сказано дальше.\nНазначение языков разметки заключается в описании структурированных документов. Структура документа представляется в виде набора вложенных в друг друга элементов (дерева XML). У элементов есть открывающие и закрывающие теги.\nВсе составляющие части документа обобщаются в пролог и корневой элемент. Корневой элемент — обязательная часть документа, в которую вложены все остальные элементы. Пролог может включать объявления, инструкции обработки, комментарии.\nВ правильно сформированном XML открывающий и закрывающий тег вложенного элемента всегда находятся внутри одного родительского элемента.\nСоздадим простой XML из строки. Сначала идет инструкция по обработке XML (со знаком вопроса), за ней следует объявление типа документа (с восклицательным знаком) и открывающий тег корневого элемента. В этот корневой элемент вложены все остальные элементы.\n\nstring_xml &lt;- '&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;!DOCTYPE recipe&gt;\n&lt;recipe name=\"хлеб\" preptime=\"5min\" cooktime=\"180min\"&gt;\n   &lt;title&gt;\n      Простой хлеб\n   &lt;/title&gt;\n   &lt;composition&gt;\n      &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n      &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n      &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n   &lt;/composition&gt;\n   &lt;instructions&gt;\n     &lt;step&gt;\n        Смешать все ингредиенты и тщательно замесить. \n     &lt;/step&gt;\n     &lt;step&gt;\n        Закрыть тканью и оставить на один час в тёплом помещении. \n     &lt;/step&gt;\n     &lt;step&gt;\n        Замесить ещё раз, положить на противень и поставить в духовку.\n     &lt;/step&gt;\n   &lt;/instructions&gt;\n&lt;/recipe&gt;'\n\nДля работы с xml понадобится установить одноименную библиотеку. Функция xmlTreeParse() создаст R-структуру, представляющую дерево XML.\n\nlibrary(XML)\ndoc &lt;- xmlTreeParse(string_xml)\nclass(doc)\n\n[1] \"XMLDocument\"         \"XMLAbstractDocument\"\n\n\nФункция xmlRoot позволяет извлечь корневой элемент вместе со всеми детьми.\n\nrootnode &lt;- xmlRoot(doc)\nrootnode\n\n&lt;recipe name=\"хлеб\" preptime=\"5min\" cooktime=\"180min\"&gt;\n &lt;title&gt;Простой хлеб&lt;/title&gt;\n &lt;composition&gt;\n  &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n  &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n  &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n &lt;/composition&gt;\n &lt;instructions&gt;\n  &lt;step&gt;Смешать все ингредиенты и тщательно замесить.&lt;/step&gt;\n  &lt;step&gt;Закрыть тканью и оставить на один час в тёплом помещении.&lt;/step&gt;\n  &lt;step&gt;Замесить ещё раз, положить на противень и поставить в духовку.&lt;/step&gt;\n &lt;/instructions&gt;\n&lt;/recipe&gt;\n\n\nЕсли документ большой, бывает удобнее не распечатывать все дерево, а вывести имена дочерних элементов.\n\nnames(xmlChildren(rootnode))\n\n[1] \"title\"        \"composition\"  \"instructions\"\n\n\nРазмер узла – это число вложенных в него “детей”. Его можно узнать, применив к узлу функцию xmlSize() – или подсчитав число “детей”.\n\nxmlSize(rootnode) == length(xmlChildren(rootnode))\n\n[1] TRUE\n\n\nРаботать с xml можно как с обычным списком, то есть индексировать узлы по имени или по номеру элемента при помощи квадратных скобок. Так мы достаем узел по имени:\n\nrootnode[[\"composition\"]]\n\n&lt;composition&gt;\n &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n&lt;/composition&gt;\n\n\nА так – по индексу:\n\nrootnode[[2]]\n\n&lt;composition&gt;\n &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n&lt;/composition&gt;\n\n\nКак и с обычными списками, мы можем использовать последовательности квадратных скобок:\n\ningr_node &lt;- rootnode[[2]][[\"ingredient\"]]\ningr_node\n\n&lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n\n\nНо обычно нам нужен не элемент как таковой, а его содержание (значение). Чтобы добраться до него, используем функцию xmlValue():\n\nxmlValue(ingr_node)\n\n[1] \"Мука\"\n\n\nМожно уточнить атрибуты узла при помощи xmlAttrs():\n\nxmlAttrs(ingr_node)\n\n  amount     unit \n     \"3\" \"стакан\" \n\n\nЧтобы извлечь значение атрибута, используем функцию xmlGetAttr(). Первым аргументом функции передаем xml-узел, вторым – имя атрибута.\n\nxmlGetAttr(ingr_node, \"unit\")\n\n[1] \"стакан\"\n\n\nКак насчет того, чтобы применить функцию к набору узлов – например, ко всем инредиентам? Вспоминаем функции для работы со списками – sapply() из базового R или map() из пакета purrr:\n\ningr_nodes &lt;- xmlChildren(rootnode[[2]])\n\nsapply(ingr_nodes, xmlValue)\n\n   ingredient    ingredient    ingredient \n       \"Мука\"      \"Дрожжи\" \"Тёплая вода\" \n\n\n\nsapply(ingr_nodes, xmlGetAttr, \"unit\")\n\ningredient ingredient ingredient \n  \"стакан\"    \"грамм\"   \"стакан\" \n\n\nДобраться до узлов определенного уровня можно также при помощи синтаксиса XPath. XPath – это язык запросов к элементам XML-документа. С его помощью можно описать “путь” до нужного узла: абсолютный (начиная с корневого элемента) или относительный. В пакете XML синтаксис XPath поддерживает функция getNodeSet().\n\n# абсолютный путь\ningr_nodes &lt;- getNodeSet(rootnode, \"/recipe//composition//ingredient\")\n\ningr_nodes\n\n[[1]]\n&lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n\n[[2]]\n&lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n\n[[3]]\n&lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n\n\n# относительный путь\ningr_nodes &lt;- getNodeSet(rootnode, \"//composition//ingredient\")\n\ningr_nodes\n\n[[1]]\n&lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n\n[[2]]\n&lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n\n[[3]]\n&lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n\n\n\n\n\n\n\n\nНа заметку\n\n\n\nВ большинстве случаев функция getNodeSet() требует задать пространство имен (namespace), но в нашем случае оно не определено, поэтому пока передаем только дерево и путь до узла. С пространством имен встретимся чуть позже!\n\n\n\nСинтаксис XPath позволяет отбирать узлы с определенными атрибутами. Допустим, нам нужны только те узлы, где значение атрибута unit = “стакан”:\n\ngetNodeSet(rootnode, \"//composition//ingredient[@unit='стакан']\")\n\n[[1]]\n&lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n\n[[2]]\n&lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n\nПри работе с xml в большинстве случаев наша задача – извлечь значения определеннных узлов или их атрибутов и сохранить их в прямоугольном формате.\nВ нашем простом примере это можно сделать несколькими способами. Первый: просто связать воедино несколько векторов.\n\ntitle &lt;- xmlValue(rootnode[[\"title\"]])\ningredients &lt;- map_chr(xmlChildren(rootnode[[\"composition\"]]), xmlValue)\nunit &lt;- map_chr(xmlChildren(rootnode[[\"composition\"]]), xmlGetAttr, \"unit\")\namount &lt;- map_chr(xmlChildren(rootnode[[\"composition\"]]), xmlGetAttr, \"amount\")\n\n\ntibble(title, ingredients, unit, amount)\n\n\n  \n\n\n\nВ некоторых случаях бывает удобно также воспользоваться функциями из пакета xml2 в сочетании с функциями семейства unnest_ из tidyr.\n\nlibrary(xml2)\n\ndoc &lt;- as_list(read_xml(string_xml))\n\n# попробуем достать атрибуты\ndoc |&gt; \n  as_tibble() |&gt; \n  unnest_longer(recipe) |&gt; \n  filter(recipe_id == \"ingredient\") |&gt; \n  mutate(unit = map_chr(recipe, attr, \"unit\")) |&gt; \n  mutate(amount = map_chr(recipe, attr, \"amount\")) |&gt; \n  select(-recipe_id) |&gt; \n  unnest_longer(recipe)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Импорт</span>"
    ]
  },
  {
    "objectID": "import.html#tei",
    "href": "import.html#tei",
    "title": "5  Импорт",
    "section": "5.3 TEI",
    "text": "5.3 TEI\nБольшая часть размеченных литературных корпусов хранится именно в формате XML. Это очень удобно, и вот почему: документы в формате XML, как и документы в формате HTML, содержат данные, заключенные в теги, но если в формате HTML теги определяют оформление данных, то в формате XML теги нередко определяют структуру и смысл данных. С их помощью мы можем достать из документа именно то, что нам интересно: определенную главу, речи конкретных персонажей, слова на иностранных языках и т.п.\nДобавлять и удалять разметку может любой пользователь в редакторе XML кода или даже в простом текстовом редакторе. При этом в качестве универсального языка разметки в гуманитарных дисциплинах используется язык TEI (Скоринкин 2016). Корневой элемент в документах TEI называется TEI, внутри него располагается элемент teiHeader с метаинформацией о документе и элемент text. Последний содержит текст документа с элементами, определяющими его структурное членение.\n&lt;TEI&gt;\n  &lt;teiHeader&gt;&lt;/teiHeader&gt;\n  &lt;text&gt;&lt;/text&gt;\n&lt;/TEI&gt;\nПример оформления документа можно посмотреть по ссылке.\nУ teiHeader есть четыре главных дочерних элемента:\n\nfileDesc (описание документа c библиографической информацией)\nencodingDesc (описание способа кодирование первоисточника)\nprofileDesc (“досье” на текст, например отправитель и получатель для писем, жанр, используемые языки, обстоятельства создания, место написания и т.п.)\nrevisionDesc (история изменений документа)\n\nВ самом тексте язык TEI дает возможность представлять разные варианты (авторские, редакторские, корректорские и др.) Основным средством параллельного представления является элемент choice. Например, в тексте Лукреция вы можете увидеть такое:\nsic calor atque &lt;choice&gt;&lt;reg&gt;aer&lt;/reg&gt;&lt;orig&gt;aër&lt;/orig&gt;&lt;/choice&gt; et venti caeca potestas\nЗдесь reg указывает на нормализованное написание, а orig – на оригинальное.\nВ качестве примера загрузим датасет “Пушкинского дома”, подготовленный Д.А. Скоринкиным: “Персонажи «Войны и мира» Л. Н. Толстого: вхождения в тексте, прямая речь и семантические роли”.\n\nfilename = \"../files/War_and_Peace.xml\"\ndoc &lt;- xmlTreeParse(filename, useInternalNodes = T)\nrootnode &lt;- xmlRoot(doc)\n\nТеперь можно внимательнее взглянуть на структуру xml. Корневой элемент расходится на две ветви. Полностью они нам пока не нужны, узнаем только имена:\n\nnames(xmlChildren(rootnode)) \n\n[1] \"teiHeader\" \"text\"     \n\n\nОчевидно, что что-то для нас интересное будет спрятано в ветке text, глядим на нее:\n\nnames(xmlChildren(rootnode[[\"text\"]])) \n\n[1] \"div\" \"div\" \"div\" \"div\" \"div\"\n\n\nИтак, текст делится на какие-то пять частей. Функция xmlGetAttr() позволяет узнать значение атрибута type: как выясняется, это четыре тома и эпилог.\n\n# это список\ndivs &lt;-  rootnode[[\"text\"]][\"div\"]\n\nsapply(divs, xmlGetAttr, \"type\")\n\n       div        div        div        div        div \n  \"volume\"   \"volume\"   \"volume\"   \"volume\" \"epilogue\" \n\n\nКак мы уже знаем, добраться до определенного узла можно не только путем индексирования, но и – гораздо удобнее – при помощи синтаксиса XPath. Для этого просто указываем путь до узла. Попробуем спуститься на два уровня ниже: там тоже будет тег div, но с другим атрибутом. Как легко убедиться, теперь это главы, всего их 358.\n\ndivs &lt;- getNodeSet(doc, \"/tei:TEI//tei:text//tei:div//tei:div//tei:div\",\n                     namespaces = c(tei = \"http://www.tei-c.org/ns/1.0\")) \n\nlength(divs)\n\n[1] 358\n\nunique(sapply(divs, xmlGetAttr, \"type\"))\n\n[1] \"chapter\"\n\n\nОбратите внимание, что в данном случае надо прямо прописать пространство имен (namespaces). Это можно посмотреть в самом xml, а можно воспользоваться специальной функцией:\n\nxmlNamespace(rootnode)\n\n[1] \"http://www.tei-c.org/ns/1.0\"\nattr(,\"class\")\n[1] \"XMLNamespace\"\n\n\nЗабрать конкретную главу можно путем индексации, но лучше – по значению соответствующего атрибута.\n\nidx &lt;- which(map(divs, xmlGetAttr, \"xml:id\") == \"chapter1part1Volume1\")\nch1 &lt;- divs[[idx]]\n\nЧтобы извлечь текст, понадобится функция xmlValue.\n\nchapter_1 &lt;- xmlValue(ch1)\n\nРаспечатывать весь текст первой главы не будем (это очень длинный вектор); разобъем текст на параграфы и выведем первый и последний:\n\nlibrary(stringr)\nchapter_lines &lt;- str_split(chapter_1, pattern = \"\\n\")\n\nchapter_lines[[1]][[5]]\n\n[1] \"        — Eh bien, mon prince. Gênes et Lueques ne sont plus que des apanages, des поместья, de la famille Buonaparte. Non, je vous préviens que si vous ne me dites pas que nous avons la guerre, si vous vous permettez encore de pallier toutes les infamies, toutes les atrocités de cet Antichrist (ma parole, j'y crois) — je ne vous connais plus, vous n'êtes plus mon ami, vous n'êtes plus мой верный раб, comme vous dites. Ну, здравствуйте, здравствуйте. Je vois que je vous fais peur, садитесь и рассказывайте.\"\n\nchapter_lines[[1]][[838]]\n\n[1] \"       Ce sera dans votre famille que je ferai mon apprentissage de vieille fille.\"\n\n\nПервая и последняя реплика по-французски: все правильно!\n\n\n\n\n\n\nЗадание\n\n\n\nСкачайте по ссылке “Горе от ума” Грибоедова и преобразуйте xml в прямоугольный формат таким образом, чтобы для каждой реплики был указан акт, сцена и действующее лицо.\n\n\nПодбробнее о структуре XML документов и способах работы с ними вы можете прочитать в книгах: (Nolan и Lang 2014) и (Холзнер 2004).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Импорт</span>"
    ]
  },
  {
    "objectID": "import.html#бонус-gutenbergr",
    "href": "import.html#бонус-gutenbergr",
    "title": "5  Импорт",
    "section": "5.4 Бонус: GutenbergR",
    "text": "5.4 Бонус: GutenbergR\nПакет GutenbergR поможет достать тексты из библиотеки Gutenberg, но будьте осторожны: распознаны они не всегда хорошо и порой содержат много разного шума, например примечания редактора, номера страниц и т.п. В билингвах источник и перевод могут идти вперемешку. И если в XML подобные элементы будут окружены соответствующими тегами, которые позволят их легко отбросить при анализе, то Gutenberg дает вам сырой текст. Часто его надо хорошенько чистить при помощи регулярных выражений или даже вручную.\nРаботать с метаданными GutenbergR вы уже научились, теперь можете пользоваться пакетом и для скачивания текстов. Сначала узнаем id нужных текстов^ [https://cran.r-project.org/web/packages/gutenbergr/vignettes/intro.html]\n\nlibrary(gutenbergr)\n\ncaesar &lt;- gutenberg_works(author == \"Caesar, Julius\", languages = \"la\") \n\ncaesar \n\n\n  \n\n\n\nЧтобы извлечь отдельный текст (тексты):\n\nde_bello_gallico &lt;- gutenberg_download(218, meta_fields = \"title\", mirror = \"ftp://mirrors.xmission.com/gutenberg/\")\nde_bello_gallico\n\n\n  \n\n\n\n\n\n\n\n\n\nНа заметку\n\n\n\nСуществует несколько зеркал библиотеки Gutenberg, и, если при выполнении функции gutenberg_download() возникает ошибка “could not download a book at http://aleph.gutenberg.org/”, то следует использовать аргумент mirror. Список зеркал доступен по ссылке: https://www.gutenberg.org/MIRRORS.ALL\n\n\n\n\n\n\nNolan, D., и D. T. Lang. 2014. XML and Web Technologies for Data Science with R. Springer.\n\n\nСкоринкин, Даниил. 2016. «Электронное представление текста с помощью стандарта разметки TEI», 90–108.\n\n\nХолзнер, Стивен. 2004. Энциклопедия XML. Питер.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Импорт</span>"
    ]
  },
  {
    "objectID": "share.html",
    "href": "share.html",
    "title": "6  Публикация",
    "section": "",
    "text": "6.1 О воспроизводимости\nПолученный в результате количественных исследований результат должен быть проверяем и воспроизводим. Это значит, что в большинстве случаев недостаточно просто рассказать, что вы проделали. Теоретически читатель должен иметь возможность проделать тот же путь, что и автор: вопроизвести его результаты, но в обратном направлении.\nДля этого должны выполняться три основных требования:\nУже на этапе планирования исследования очень важно продумать, как вы будете его документировать. Важно помнить, что код пишется не только для машин, но и для людей, поэтому стоит документировать не только то, что вы делали, но и почему. R дает для этого множество возможностей, главная из которых – это Markdown.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#о-воспроизводимости",
    "href": "share.html#о-воспроизводимости",
    "title": "6  Публикация",
    "section": "",
    "text": "На заметку\n\n\n\nВоспроизводимость (reproducibility) – это не то же, что повторяемость (replicability). Ученый, который повторяет исследование, проводит его заново на новых данных. Воспроизведение – гораздо более скромная задача, не требующая таких ресурсов, как повторение (Winter 2020, 47).\n\n\n\n\nдоступность данных и метаданных;\nдоступность компьютерного кода;\nдоступность программного обеспечения.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#markdown",
    "href": "share.html#markdown",
    "title": "6  Публикация",
    "section": "6.2 Markdown",
    "text": "6.2 Markdown\nMarkdown – это облегчённый язык разметки. Он позволяет создавать документы разного формата – не только HTML (веб-страницы), но и PDF и Word. Markdown дает возможность создания полностью воспроизводимых документов, сочетающих код и поясняющий текст. Этот язык используется для создания сайтов, статей, книг, презентаций, отчетов, дашбордов и т.п. Этот курс написан с использованием Markdown.\nЧтобы начать работать с документами .rmd, нужен пакет rmarkdown; в RStudio он уже предустановлен. Создание нового документа .rmd происходит из меню.\nПо умолчанию документ .rmd снабжен шапкой yaml. Она не обязательна. Здесь содержатся данные об авторе, времени создания, формате, сведения о файле с библиографией и т.п.\n---\ntitle: \"Demo\"\nauthor: \"My name\"\ndate: \"2024-08-17\"\noutput: html_document\n---\nТакже в документе .rmd скорее всего будет простой текст и блоки кода. Чтобы “сшить” html (pdf, doc), достаточно нажать кнопку knit либо запустить в консоли код: rmarkdown::render(\"Demo.Rmd\"). После этого в рабочей директории появится новый файл (html, pdf, или doc), которым можно поделиться с коллегами, грантодателями или друзьями.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#quarto",
    "href": "share.html#quarto",
    "title": "6  Публикация",
    "section": "6.3 Quarto",
    "text": "6.3 Quarto\nРаботать с маркдауном мы будем, используя издательскую систему Quarto с открытым исходным кодом. Она позволяет создавать и публиковать статьи, презентации, информационные панели, веб-сайты, блоги и книги в HTML, PDF, MS Word, ePub и других форматах. В общем, обычный Markdown тоже позволяет все это делать, но чуть сложнее. Quarto объединяет различные пакеты из экосистемы R Markdown воедино и значительно упрощает работу с ними.\n\n\n\n\n\n\nЗадание\n\n\n\nСоздайте новый .qmd документ. Потренируйтесь запускать код и сшивать документ в .html, .pdf, .docx.\n\n\nДля .pdf может понадобиться установка LaTeX.\n\n# install.packages(\"tinytex\")\ntinytex::install_tinytex()\n# to uninstall TinyTeX, run\n# tinytex::uninstall_tinytex()\n\nМожно указать сразу несколько форматов для файла, как показано здесь, и “сшить” их одновременно:\n\nquarto::quarto_render(\n  \"untitled.qmd\", \n  output_format = c(\"pdf\", \"html\", \"docx\")\n)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#шапка-yaml",
    "href": "share.html#шапка-yaml",
    "title": "6  Публикация",
    "section": "6.4 Шапка YAML",
    "text": "6.4 Шапка YAML\nОсновные параметры документа хранятся в YAML-шапке. К ним относятся format, title, subtitle, date, date-format, author, abstract, lang, toc, number-sections и другие.\nПопробуйте изменить шапку своего .qmd-документа и заново его сшить. Сравните с предыдущей версией.\n---\ntitle: \"Заголовок\"\nsubtitle: \"Подзаголовок\"\nformat: html\nauthor: locusclassicus\ndate: today\ndate-format: D.MM.YYYY\nabstract: Значенье бублика нам непонятно.\nlang: ru\ntoc: true\nnumber-sections: true\n---\n\nПоле execute позволяет задать параметры всех фрагментов кода в документе, например:\n---\nexecute:\n  echo: false\n  fig-width: 9\n---\n  \nНо для отдельных кусков кода эти настройки можно поменять:\n```\n#| echo: true\n\nsqrt(16)\n```\nПараметр df-print позволяет выбрать один из возможных способов отображения датафреймов:\n\ndefault — стандартный, как в консоли;\ntibble — стандартный, как в консоли, но в формате tibble;\nkable — минималистичный вариант, подходит для всех видов документов;\npaged — интерактивная таблица, подходит для html страниц.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#синтаксис-markdown",
    "href": "share.html#синтаксис-markdown",
    "title": "6  Публикация",
    "section": "6.5 Синтаксис Markdown",
    "text": "6.5 Синтаксис Markdown\n\n6.5.1 Заголовки\nЗаголовки разного уровня задаются при помощи решетки:\n# Заголовок первого уровня\n## Заголовок второго уровня\n### Заголовок третьего уровня\n#### Заголовок четвёртого уровня\nПример заголовка третьего уровня:\n\n\n6.5.2 Форматирование\n*курсив*  \n_курсив_\n\n**полужирный**  \n__полужирный__\n\n***полужирный курсив***  \n___полужирный курсив___\n\n~~зачеркнутый~~\n\n&lt;mark&gt;выделение&lt;/mark&gt;\nПример:\nкурсив\nполужирный\nуж и не знаю как выделить\nзачеркнутый\nвыделение\n\n\n6.5.3 Списки\nНумерованный список\n1. Пункт первый\n2. Пункт второй\n3. Пункт третий\nПример:\n\nПункт первый\nПункт второй\nПункт третий\n\nМаркированный список\n- Пункт первый\n- Пункт второй\n- Пункт третий\nПример:\n\nПункт первый\nПункт второй\nПункт третий\n\nТакже Markdown позволяет делать вложенные списки:\n1. Пункт первый\n    - Подпункт первый\n    - Подпункт второй\n2. Пункт второй\nПример:\n\nПункт первый\n\nПодпункт первый\nПодпункт второй\n\nПункт второй\n\nСамое удобное, что элементы списка не обязательно нумеровать:\n(@) Пункт первый.\n(@) Пункт не знаю какой.\n\nПункт первый.\nПункт не знаю какой.\n\n\n\n6.5.4 Ссылки\n[Текст ссылки](http://antibarbari.ru/)\nПример:\nТекст ссылки\n\n\n6.5.5 Изображения\n![Текст описания](http://antibarbari.ru/wp-content/uploads/2023/03/corderius-656x300.png)\nПример:\n\n\n\nМоя картинка\n\n\nДва нюанса:\n\nможно давать ссылки на локальные файлы (то есть такие файлы, которые хранятся на компьютере), но имейте в виду, что такой код не будет работать у другого пользователя;\nизображения можно вставлять, пользуясь непосредственно разметкой html.\n\n&lt;img src=\"images/my_image.jpg\" width=40%&gt;\n\n\n6.5.6 Блоки кода\nМожно вставлять непосредственно в текст; для этого код выделяют одинарным обратным апострофом (грависом). Но чаще код дают отдельным блоком. Эти блоки можно именовать; тогда в случае ошибки будет сразу понятно, где она случилась.\n```{}\nsome code here\n```\nВ фигурных скобках надо указать язык, например {r}, только в этом случае код будет подсвечиваться и выполняться.\nТам же в фигурных скобках можно задать следующие параметры:\n\neval = FALSE код будет показан, но не будет выполняться;\ninclude = FALSE код будет выполнен, но ни код, ни результат не будут показаны;\necho = FALSE код будет выполнен, но не показан, результаты при этом видны;\nmessage = FALSE или warning = FALSE прячет сообщения или предупреждения;\nresults = 'hide' не распечатывает результат, а fig.show = 'hide' прячет графики;\nerror = TRUE “сшивание” продолжается, даже если этот блок вернул ошибку.\n\n\n\n6.5.7 Цитаты\n&gt; Omnia praeclara rara.\nПример:\n\nOmnia praeclara rara.\n\nЦитата с подписью может быть оформлена так:\n&gt; Omnia praeclara rara.\n&gt;\n&gt; --- Cicero\nПример:\n\nOmnia praeclara rara.\n— Cicero\n\n\n\n6.5.8 Разделители\nЧтобы создать горизонтальную линию, можно использовать ---, *** или ___.\nПример:\n\n\n\n6.5.9 Таблицы\nТаблицы можно задать вручную при помощи дефисов - и вертикальных линий |; идеальная точность при этом не нужна. Перед таблицей обязательно оставляйте пустую строку, иначе волшебство не сработает.\n\n| Фрукты   | Калории  |\n| -----  | ---- |\n| Яблоко   | 52  |\n| Апельсин | 47  |\nПример:\n\n\n\nФрукты\nКалории\n\n\n\n\nЯблоко\n52\n\n\nАпельсин\n47\n\n\n\nПо умолчанию Markdown распечатывает таблицы так, как они бы выглядели в консоли.\n\ndata(\"iris\")\nhead(iris)\n\n\n  \n\n\n\nДля дополнительного форматирования можно использовать функцию knitr::kable():\n\nknitr::kable(iris[1:6, ], caption = \"Таблица knitr\")\n\n\nТаблица knitr\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nИнтерактивную таблицу можно создать так:\n\nDT::datatable(iris[1:6,])\n\n\n\n\n\n\n\n6.5.10 Чек-листы\n- [x] Таблицы\n- [ ] Графики\nПример:\n\nТаблицы\nГрафики\n\n\n\n6.5.11 Внутренние ссылки\nУдобны для навигации по документу. К названию любого раздела можно добавить {#id}.\n[Вернуться к чек-листам](#id)\nПример:\nВернуться к чек-листам\n\n\n6.5.12 Графики\nMarkdown позволяет встраивать любые графики.\n\nlibrary(ggplot2)\nggplot(aes(x = Sepal.Length, y = Petal.Length, col = Species), data = iris) +\n  geom_point(show.legend = F)\n\n\n\n\n\n\n\n\nДля интерактивных графиков понадобится пакет plotly:\n\nlibrary(plotly)\nplot_ly(data=iris, x = ~Sepal.Length, y = ~Petal.Length, color = ~Species)\n\n\n\n\n\nПодробное руководство по созданию интерактивных графиков можно найти на сайте https://plotly.com/r/.\n\n\n6.5.13 Математические формулы\nПишутся с использованием синтаксиса LaTeX, о котором можно прочитать подробнее здесь.\nФормулы заключаются в одинарный $, если пишутся в строку, и в двойной $$, если отдельным блоком.\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\nВот так это выглядит в тексте: \\(\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\\).\nА вот так – блоком:\n\\[\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\\]\n\n\n6.5.14 Смайлы\nУдобнее вставлять через визуальный редактор (“шестеренка” &gt; Use Visual Editor), но можно и без него:\n\n# devtools::install_github(\"hadley/emo\")\nlibrary(emo)\nemo::ji(\"apple\")\n\n🍎 \n\n\nКод можно записать в строку, тогда смайл появится в тексте: 💀.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#библиография",
    "href": "share.html#библиография",
    "title": "6  Публикация",
    "section": "6.6 Библиография",
    "text": "6.6 Библиография\nMarkdown позволяет добавлять библиографию в формате BibTeX. BibTeX — программное обеспечение для создания форматированных списков библиографии; обычно используется совместно с LaTeX’ом. Многие сайты, например GoogleScholar, позволяют экспортировать библиографические записи в формате BibTeX. При необходимости запись можно исправить вручную.\nКаждая запись имеет следующую форму.\n@book{winter2020,\n  author = {Bodo Winter},\n  title = \"{Statistics for Linguists: An Introduction Using R}\",\n  year = {2020},\n  publisher = {Routledge}\n}\nЗдесь book — тип записи («книга»), winter2020 — метка-идентификатор записи, дальше список полей со значениями.\nОдна запись описывает ровно одну публикацию статью, книгу, диссертацию, и т. д. Подробнее о типах записей можно посмотреть вот здесь.\nПодобные записи хранятся в текстовом файле с расширением .bib. Чтобы привязать библиографию, нужно указать имя файла в шапке yaml.\n---\nbibliography: bibliography.bib\n---\nДальше, чтобы добавить ссылку, достаточно ввести ключ публикации после @ (в квадратных скобках, чтобы публикация отражалась в круглых): [@wickham2016].\nПример:\n(Wickham и Grolemund 2016).\nМожно интегрировать BibTex с Zotero или другим менеджером библиографии. Для этого придется установить специальное расширение.\nЧтобы изменить стиль цитирования, необходимо добавить в шапку yaml название csl-файла (CSL - Citation Style Language), например:\n---\noutput: html_document\nbibliography: references.bib\ncsl: archiv-fur-geschichte-der-philosophie.csl\n---\nНайти необходимый csl-файл можно, например, в репозитории стилей Zotero.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#публикация-html",
    "href": "share.html#публикация-html",
    "title": "6  Публикация",
    "section": "6.7 Публикация html",
    "text": "6.7 Публикация html\nДля публикации на RPubs понадобится установить пакеты packrat, rsconnect.\n\n\n\n\nWickham, Hadley, и Garrett Grolemund. 2016. R for Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.\n\n\nWinter, Bodo. 2020. Statistics for Linguists: An Introduction Using R. Routledge.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "share.html#footnotes",
    "href": "share.html#footnotes",
    "title": "6  Публикация",
    "section": "",
    "text": "https://rmarkdown.rstudio.com/↩︎\nhttps://docs.posit.co/how-to-guides/rsc/publish-rmd/↩︎\nhttps://www.markdownguide.org/basic-syntax/↩︎\nhttps://r4ds.had.co.nz/r-markdown.html#chunk-name↩︎\nhttps://github.com/hadley/emo↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Публикация</span>"
    ]
  },
  {
    "objectID": "regex.html",
    "href": "regex.html",
    "title": "7  Регулярные выражения",
    "section": "",
    "text": "7.1 Regex в базовом R\nВ базовом R за работу со строками отвечают, среди прочего, такие функции, как grep() и grepl(). При этом grepl() возвращает TRUE, если шаблон найден в соответствующей символьной строке, а grep() возвращает вектор индексов символьных строк, содержащих паттерн.\nОбеим функциям необходим аргумент pattern и аргумент x, где pattern - регулярное выражение, по которому производится поиск, а аргумент x - вектор символов, по которым следует искать совпадения.\nФункция gsub() позволяет производить замену и требует также аргумента replacement.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#литералы-и-классы",
    "href": "regex.html#литералы-и-классы",
    "title": "7  Регулярные выражения",
    "section": "7.2 Литералы и классы",
    "text": "7.2 Литералы и классы\nБуквальные символы – это то, что вы ожидаете увидеть (или не увидеть – для управляющих и пробельных символов); можно сказать, что это символы, которые ничего не “имеют в виду”. Их можно объединять в классы при помощи квадратных скобок, например, так: [abc].\n\nvec &lt;- c(\"a\", \"d\", \"c\")\ngrepl(\"[abc]\", vec)\n\n[1]  TRUE FALSE  TRUE\n\ngrep(\"[abc]\", vec)\n\n[1] 1 3\n\n\nДля некоторых классов есть специальные обозначения.\n\n\n\n\n\n\n\n\nКласс\nЭквивалент\nЗначение\n\n\n\n\n[:upper:]\n[A-Z]\nСимволы верхнего регистра\n\n\n[:lower:]\n[a-z]\nСимволы нижнего регистра\n\n\n[:alpha:]\n[[:upper:][:lower:]]\nБуквы\n\n\n[:digit:]\n[0-9], т. е. \\d\nЦифры\n\n\n[:alnum:]\n[[:alpha:][:digit:]]\nБуквы и цифры\n\n\n[:word:]\n[[:alnum:]_], т. е. \\w\nСимволы, образующие «слово»\n\n\n[:punct:]\n[-!“#$%&’()*+,./:;&lt;=&gt;?@[\\]_`{|}~]\nЗнаки пунктуации\n\n\n[:blank:]\n[\\s\\t]\nПробел и табуляция\n\n\n[:space:]\n[[:blank:]\\v\\r\\n\\f], т. е. \\s\nПробельные символы\n\n\n[:cntrl:]\n\nУправляющие символы (перевод строки, табуляция и т.п.)\n\n\n[:graph:]\n\nПечатные символы\n\n\n[:print:]\n\nПечатные символы с пробелом\n\n\n\nЭти классы тоже можно задавать в качестве паттерна.\n\nvec &lt;- c(\"жираф\", \"верблюд1\", \"0зебра\")\ngsub( \"[[:digit:]]\",  \"\", vec)\n\n[1] \"жираф\"   \"верблюд\" \"зебра\"  \n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nВ пакете stringr есть небольшой датасет words. Найдите все слова с последовательностью символов wh. Сколько слов содержат два гласных после w?\n\n\n\nВ качестве классов можно рассматривать и следующие обозначения:\n\n\n\n\n\n\n\n\nПредставление\nЭквивалент\nЗначение\n\n\n\n\n\\d\n[0-9]\nЦифра\n\n\n\\D\n[^\\\\d]\nЛюбой символ, кроме цифры\n\n\n\\w\n[A-Za-zА-Яа-я0-9_]\nСимволы, образующие «слово» (буквы, цифры и символ подчёркивания)\n\n\n\\W\n[^\\\\w]\nСимволы, не образующие «слово»\n\n\n\\s\n[ \\t\\v\\r\\n\\f]\nПробельный символ\n\n\n\\S\n[^\\\\s]\nНепробельный символ\n\n\n\n\ngsub( \"\\\\d\",  \"\", vec) # вторая косая черта \"экранирует\" первую\n\n[1] \"жираф\"   \"верблюд\" \"зебра\"  \n\n\nВнутри квадратных скобор знак ^ означает отрицание:\n\ngsub( \"[^[:digit:]]\",  \"\", vec) \n\n[1] \"\"  \"1\" \"0\"\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nНайдите все слова в words, в которых за w следует согласный. Замените всю пунктуацию в строке “tomorrow?and-tomorrow_and!tomorrow” на пробелы.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#якоря",
    "href": "regex.html#якоря",
    "title": "7  Регулярные выражения",
    "section": "7.3 Якоря",
    "text": "7.3 Якоря\nЯкоря позволяют искать последовательности символов в начале или в конце строки. Знак ^ (вне квадратных скобок!) означает начало строки, а знак $ – конец. Мнемоническое правило: First you get the power (^) and then you get the money ($).\n\nvec &lt;- c(\"The spring is a lovely time\", \n         \"Fall is a time of peace\")\ngrepl(\"time$\", vec)\n\n[1]  TRUE FALSE\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nНайдите все слова в words, которые заканчиваются на x. Найдите все слова, которые начинаются на b или на g.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#метасимволы",
    "href": "regex.html#метасимволы",
    "title": "7  Регулярные выражения",
    "section": "7.4 Метасимволы",
    "text": "7.4 Метасимволы\nВсе метасимволы представлены в таблице ниже.\n\n\n\nОписание\nСимвол\n\n\n\n\nоткрывающая квадратная скобка\n[\n\n\nзакрывающая квадратная скобка\n]\n\n\nобратная косая черта\n\\\n\n\nкарет\n^\n\n\nзнак доллара\n$\n\n\nточка\n.\n\n\nвертикальная черта\n|\n\n\nзнак вопроса\n?\n\n\nастериск\n*\n\n\nплюс\n+\n\n\nоткрывающая фигурная скобка\n{\n\n\nзакрывающая фигурная скобка\n}\n\n\nоткрывающая круглая скобка\n(\n\n\nзакрывающая круглая скобка\n)\n\n\n\nКвадратные скобки используются для создания классов, карет и знак доллара – это якоря, но карет внутри квадратных скобок может также быть отрицанием. Точка – это любой знак.\n\nvec &lt;- c(\"жираф\", \"верблюд1\", \"0зебра\")\ngrep(\".б\", vec) \n\n[1] 2 3\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nНайдите все слова в words, в которых есть любые два символа между b и k.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#экранирование",
    "href": "regex.html#экранирование",
    "title": "7  Регулярные выражения",
    "section": "7.5 Экранирование",
    "text": "7.5 Экранирование\nЕсли необходимо найти буквальную точку, буквальный знак вопроса и т.п., то используется экранирование: перед знаком ставится косая черта. Но так как сама косая черта – это метасимвол, но нужно две косые черты, первая из которых экранирует вторую.\n\nvec &lt;- c(\"жираф?\", \"верблюд.\", \"зебра\")\ngrep(\"\\\\?\", vec) \n\n[1] 1\n\ngrepl(\"\\\\.\", vec)\n\n[1] FALSE  TRUE FALSE\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nУзнайте, все ли предложения в sentences (входит в stringr) кончаются на точку.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#квантификация",
    "href": "regex.html#квантификация",
    "title": "7  Регулярные выражения",
    "section": "7.6 Квантификация",
    "text": "7.6 Квантификация\nКвантификатор после символа, символьного класса или группы определяет, сколько раз предшествующее выражение может встречаться. Квантификатор может относиться более чем к одному символу в регулярном выражении, только если это символьный класс или группа.\n\n\n\nПредставление\nЧисло повторений\nЭквивалент\n\n\n\n\n?\nНоль или одно\n{0,1}\n\n\n*\nНоль или более\n{0,}\n\n\n+\nОдно или более\n{1,}\n\n\n\nПример:\n\nvec &lt;- c(\"color\", \"colour\", \"colouur\")\ngrepl(\"ou?r\", vec) # ноль или одно \n\n[1]  TRUE  TRUE FALSE\n\ngrepl(\"ou+r\", vec) # одно или больше\n\n[1] FALSE  TRUE  TRUE\n\ngrepl(\"ou*r\", vec) # ноль или больше\n\n[1] TRUE TRUE TRUE\n\n\nТочное число повторений (интервал) можно задать в фигурных скобках:\n\n\n\nПредставление\nЧисло повторений\n\n\n\n\n{n}\nРовно n раз\n\n\n{m,n}\nОт m до n включительно\n\n\n{m,}\nНе менее m\n\n\n{,n}\nНе более n\n\n\n\n\nvec &lt;- c(\"color\", \"colour\", \"colouur\", \"colouuuur\")\ngrepl(\"ou{1}r\", vec)\n\n[1] FALSE  TRUE FALSE FALSE\n\ngrepl(\"ou{1,2}r\", vec)\n\n[1] FALSE  TRUE  TRUE FALSE\n\ngrepl(\"ou{,2}r\", vec) # это включает и ноль!\n\n[1]  TRUE  TRUE  TRUE FALSE\n\n\nЧасто используется последовательность .* для обозначения любого количества любых символов между двумя частями регулярного выражения.\n\n\n\n\n\n\nЗадание\n\n\n\nУзнайте, в каких предложениях в sentences за пробелом следует ровно три согласных.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#жадная-и-ленивая-квантификация",
    "href": "regex.html#жадная-и-ленивая-квантификация",
    "title": "7  Регулярные выражения",
    "section": "7.7 Жадная и ленивая квантификация",
    "text": "7.7 Жадная и ленивая квантификация\nВ регулярных выражениях квантификаторам соответствует максимально длинная строка из возможных (квантификаторы являются жадными, англ. greedy). Это может оказаться значительной проблемой. Например, часто ожидают, что выражение &lt;.*&gt; найдёт в тексте теги HTML. Однако если в тексте есть более одного HTML-тега, то этому выражению соответствует целиком строка, содержащая множество тегов.\n\nvec &lt;- c(\"&lt;p&gt;&lt;b&gt;Википедия&lt;/b&gt; — свободная энциклопедия, в которой &lt;i&gt;каждый&lt;/i&gt; может изменить или дополнить любую статью.&lt;/p&gt;\")\ngsub(\"&lt;.*&gt;\", \"\", vec) # все исчезло!\n\n[1] \"\"\n\n\nЧтобы этого избежать, надо поставить после квантификатора знак вопроса. Это сделает его ленивым.\n\n\n\nregex\nзначение\n\n\n\n\n??\n0 или 1, лучше 0\n\n\n*?\n0 или больше, как можно меньше\n\n\n+?\n1 или больше, как можно меньше\n\n\n{n,m}?\nот n до m, как можно меньше\n\n\n\nПример:\n\ngsub(\"&lt;.*?&gt;\", \"\", vec) # все получилось!\n\n[1] \"Википедия — свободная энциклопедия, в которой каждый может изменить или дополнить любую статью.\"\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nДана строка “tomorrow (and) tomorrow (and) tomorrow”. Необходимо удалить первые скобки с их содержанием.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#regex-в-stringr-основы",
    "href": "regex.html#regex-в-stringr-основы",
    "title": "7  Регулярные выражения",
    "section": "7.8 Regex в stringr: основы",
    "text": "7.8 Regex в stringr: основы\nПакет stringr не является частью tidyverse, хотя и разделяет его принципы1. Его надо загружать отдельно:\n\nlibrary(stringr)\n\nЭто очень удобный инструмент для работы со строками. Вот так можно узнать длину строки или объединить ее с другими строками:\n\nvec &lt;- c(\"жираф\", \"верблюд\")\nstr_length(vec)\n\n[1] 5 7\n\nstr_c(\"красивый_\", vec)\n\n[1] \"красивый_жираф\"   \"красивый_верблюд\"\n\n\nЭлементы вектора можно объединить в одну строку:\n\nstr_c(vec, collapse = \", \") # теперь у них общие кавычки\n\n[1] \"жираф, верблюд\"\n\n\nС помощью str_sub() и str_sub_all() можно выбрать часть строки2.\n\nvec &lt;- c(\"жираф\", \"верблюд\")\nstr_sub(vec, 1, 3)\n\n[1] \"жир\" \"вер\"\n\nstr_sub(vec, 1, -2)\n\n[1] \"жира\"   \"верблю\"\n\n\nФункции ниже меняют начертание с прописного на строчное или наоборот:\n\nVEC &lt;- str_to_upper(vec)\nVEC\n\n[1] \"ЖИРАФ\"   \"ВЕРБЛЮД\"\n\nstr_to_lower(VEC)\n\n[1] \"жираф\"   \"верблюд\"\n\nstr_to_title(vec)\n\n[1] \"Жираф\"   \"Верблюд\"\n\n\nОдна из полезнейших функций в этом пакете – str_view(); она помогает увидеть, что поймало регулярное выражение – до того, как вы внесете какие-то изменения в строку.\n\nstr_view(c(\"abc\", \"a.c\", \"bef\"), \"a\\\\.c\")\n\n[2] │ &lt;a.c&gt;\n\n\nНапример, с помощью этой функции можно убедиться, что вертикальная черта выступает как логический оператор “или”:\n\nstr_view(c(\"grey\", \"gray\"), \"gr(e|a)y\")\n\n[1] │ &lt;grey&gt;\n[2] │ &lt;gray&gt;\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nСоздайте тиббл с двумя столбцами: letters и numbers (1:26). Преобразуйте, чтобы в третьем столбце появился результат соединения первых двух через подчеркивание, например a_1. Отфильтруйте, чтобы остались только ряды, где есть цифра 3 или буква x.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#str_detect-и-str_count",
    "href": "regex.html#str_detect-и-str_count",
    "title": "7  Регулярные выражения",
    "section": "7.9 str_detect() и str_count()",
    "text": "7.9 str_detect() и str_count()\nАналогом grepl() в stringr является функция str_detect()\n\nlibrary(rcorpora)\ndata(\"fruit\")\nhead(fruit)\n\n[1] \"apple\"       \"apricot\"     \"avocado\"     \"banana\"      \"bell pepper\"\n[6] \"bilberry\"   \n\nstr_detect(head(fruit), \"[aeiou]$\")\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE FALSE\n\n# какая доля слов заканчивается на гласный?\nmean(str_detect(fruit, \"[aeiou]$\"))\n\n[1] 0.35\n\n# сколько всего слов заканчивается на гласный?\nsum(str_detect(fruit, \"[aeiou]$\"))\n\n[1] 28\n\n\nОтрицание можно задать двумя способами:\n\ndata(\"words\")\n\nno_vowels1 &lt;- !str_detect(words, \"[aeiou]\") # слова без гласных\n\nno_vowels2 &lt;- str_detect(words, \"^[^aeiou]+$\") # слова без гласных\n\nsum(no_vowels1 != no_vowels2)\n\n[1] 0\n\n\nЛогический вектор можно использовать для индексирования:\n\nwords[!str_detect(words, \"[aeiou]\")]\n\n[1] \"by\"  \"dry\" \"fly\" \"mrs\" \"try\" \"why\"\n\n\nЭту функцию можно применять вместе с функцией filter() из пакета dplyr:\n\nlibrary(dplyr)\ngods &lt;- corpora(which = \"mythology/greek_gods\")\n\ndf &lt;- tibble(god = as.character(gods$greek_gods), \n             i = seq_along(god)\n             )\n\ndf |&gt; \n  filter(str_detect(god, \"s$\"))\n\n\n  \n\n\n\nВариацией этой функции является str_count():\n\nstr_count(as.character(gods$greek_gods), \"[Aa]\")\n\n [1] 1 1 1 1 2 0 0 1 1 1 0 1 0 0 1 2 1 0 0 0 0 1 2 1 0 2 3 2 1 0 0\n\n\nЭту функцию удобно использовать вместе с mutate() из dplyr:\n\ndf |&gt; \n  mutate(\n    vowels = str_count(god, \"[AEIOYaeiou]\"),\n    consonants = str_count(god, \"[^AEIOYaeiou]\")\n  )\n\n\n  \n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПреобразуйте sentences из пакета stringr в тиббл; в новом столбце сохраните количество пробелов в каждом предложении.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#str_extract-str_subset-и-str_match",
    "href": "regex.html#str_extract-str_subset-и-str_match",
    "title": "7  Регулярные выражения",
    "section": "7.10 str_extract(), str_subset() и str_match()",
    "text": "7.10 str_extract(), str_subset() и str_match()\nФункция str_extract() извлекает совпадения3.\nСначала зададим паттерн для поиска.\n\ncolours &lt;- c(\" red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\")\ncolour_match &lt;- str_c(colours, collapse = \"|\")\ncolour_match\n\n[1] \" red|orange|yellow|green|blue|purple\"\n\n\nИ применим к предложениями. Используем str_extract_all(), т.к. str_extract() возвращает только первое вхождение.\n\nhas_colour &lt;- str_subset(sentences, colour_match)\nmatches &lt;- str_extract_all(has_colour, colour_match)\nhead(unlist(matches))\n\n[1] \"blue\"   \"blue\"   \"blue\"   \"yellow\" \"green\"  \" red\"  \n\n\nКруглые скобки используются для группировки. Например, мы можем задать шаблон для поиска существительного или прилагательного с артиклем.\n\nnoun &lt;- \"(a|the) ([^ ]+)\" # как минимум один непробельный символ после пробела\n\nhas_noun &lt;- sentences |&gt;\n  str_subset(noun) |&gt;\n  head(10)\nhas_noun\n\n [1] \"The birch canoe slid on the smooth planks.\"       \n [2] \"Glue the sheet to the dark blue background.\"      \n [3] \"It's easy to tell the depth of a well.\"           \n [4] \"These days a chicken leg is a rare dish.\"         \n [5] \"The box was thrown beside the parked truck.\"      \n [6] \"The boy was there when the sun rose.\"             \n [7] \"The source of the huge river is the clear spring.\"\n [8] \"Kick the ball straight and follow through.\"       \n [9] \"Help the woman get back to her feet.\"             \n[10] \"A pot of tea helps to pass the evening.\"          \n\n\nДальше можно воспользоваться уже известной функцией str_extract() или применить str_match. Результат будет немного отличаться: вторая функция вернет матрицу, в которой хранится не только сочетание слов, но и каждый компонент отдельно.\n\nhas_noun |&gt; \n  str_extract(noun)\n\n [1] \"the smooth\" \"the sheet\"  \"the depth\"  \"a chicken\"  \"the parked\"\n [6] \"the sun\"    \"the huge\"   \"the ball\"   \"the woman\"  \"a helps\"   \n\nhas_noun |&gt; \n  str_match(noun)\n\n      [,1]         [,2]  [,3]     \n [1,] \"the smooth\" \"the\" \"smooth\" \n [2,] \"the sheet\"  \"the\" \"sheet\"  \n [3,] \"the depth\"  \"the\" \"depth\"  \n [4,] \"a chicken\"  \"a\"   \"chicken\"\n [5,] \"the parked\" \"the\" \"parked\" \n [6,] \"the sun\"    \"the\" \"sun\"    \n [7,] \"the huge\"   \"the\" \"huge\"   \n [8,] \"the ball\"   \"the\" \"ball\"   \n [9,] \"the woman\"  \"the\" \"woman\"  \n[10,] \"a helps\"    \"a\"   \"helps\"  \n\n\nФункция tidyr::extract работает похожим образом, но требует дать имена для каждого элемента группы. Этим удобно пользоваться, если ваши данные хранятся в виде тиббла.\n\ntibble(sentence = sentences) |&gt; \n  tidyr::extract(\n    sentence, c(\"article\", \"noun\"), \"(a|the) ([^ ]+)\", \n    remove = FALSE\n  )\n\n\n  \n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nНайдите в sentences все предложения, где есть to, и выберите следующее за этим слово. Переведите в нижний регистр. Узнайте, сколько всего уникальных сочетаний.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#str_replace",
    "href": "regex.html#str_replace",
    "title": "7  Регулярные выражения",
    "section": "7.11 str_replace",
    "text": "7.11 str_replace\nФункции str_replace() и str_replace_all() позволяют заменять совпадения на новые символы.\n\nx &lt;- c(\"apple\", \"pear\", \"banana\")\nstr_replace(x, \"[aeiou]\", \"-\")\n\n[1] \"-pple\"  \"p-ar\"   \"b-nana\"\n\nstr_replace_all(x, \"[aeiou]\", \"-\")\n\n[1] \"-ppl-\"  \"p--r\"   \"b-n-n-\"\n\n\nЭтим можно воспользоваться, если вы хотите, например, удалить из текста все греческие символы. Для стандартного греческого алфавита хватит [Α-Ωα-ω], но для древнегреческого этого, например, не хватит. Попробуем на отрывке из письма Цицерона Аттику, которое содержит греческий текст.\n\ncicero &lt;- \"nihil hāc sōlitūdine iūcundius, nisi paulum interpellāsset Amyntae fīlius. ὢ ἀπεραντολογίας ἀηδοῦς! \"\n\nstr_replace_all(cicero, \"[Α-Ωα-ω]\", \"\")\n\n[1] \"nihil hāc sōlitūdine iūcundius, nisi paulum interpellāsset Amyntae fīlius. ὢ ἀί ἀῦ! \"\n\n\nὢ ἀί ἀῦ! Не все у нас получилось гладко. Попробуем иначе:\n\nstr_replace_all(cicero, \"[\\u0370-\\u03FF]\", \"\")\n\n[1] \"nihil hāc sōlitūdine iūcundius, nisi paulum interpellāsset Amyntae fīlius. ὢ ἀ ἀῦ! \"\n\n\nУдалилась (буквально была заменена на пустое место) та диакритика, которая есть в новогреческом (ί). Но остались еще буквы со сложной диакритикой, которой современные греки не пользуются.\n\nno_greek &lt;- str_replace_all(cicero, \"[[\\u0370-\\u03FF][\\U1F00-\\U1FFF]]\", \"\")\nno_greek\n\n[1] \"nihil hāc sōlitūdine iūcundius, nisi paulum interpellāsset Amyntae fīlius.   ! \"\n\n\n! Мы молодцы. Избавились от этого непонятного греческого.\nНа самом деле, конечно, str_replace хорош тем, что он позволяет производить осмысленные замены. Например, мы можем в оставшемся латинском текст заменить гласные с макроном (черточка, означающая долготу) на обычные гласные.\n\nstr_replace_all(no_greek, c(\"ā\" = \"a\", \"ū\" = \"u\", \"ī\" = \"i\", \"ō\" = \"o\"))\n\n[1] \"nihil hac solitudine iucundius, nisi paulum interpellasset Amyntae filius.   ! \"\n\n\nКрасота. О более сложных заменах с перемещением групп можно посмотреть видео здесь и здесь. Это помогает даже в таком скорбном деле, как переоформление библиографии.\n\n\n\n\n\n\nЗадание\n\n\n\nДана библиографическая запись:\nAst, Friedrich. 1816. Platon’s Leben und Schriften. Leipzig, Weidmann.\nИспользуя регулярные выражения, замените полное имя на инициал. Запятую перед инициалом удалите. Уберите название издательства. Год поставьте в круглые скобки.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#str_split",
    "href": "regex.html#str_split",
    "title": "7  Регулярные выражения",
    "section": "7.12 str_split",
    "text": "7.12 str_split\nФункция str_split() помогает разбить текст на предложения, слова или просто на бессмысленные наборы символов. Это важный этап подготовки текста для анализа, и проводится он нередко именно с применением регулярных выражений.\n\nsentences |&gt;\n  head(2) |&gt; \n  str_split(\" \")\n\n[[1]]\n[1] \"The\"     \"birch\"   \"canoe\"   \"slid\"    \"on\"      \"the\"     \"smooth\" \n[8] \"planks.\"\n\n[[2]]\n[1] \"Glue\"        \"the\"         \"sheet\"       \"to\"          \"the\"        \n[6] \"dark\"        \"blue\"        \"background.\"\n\n\nНо можно обойтись и без регулярных выражений.\n\nx &lt;- \"This is a sentence.  This is another sentence.\"\nstr_view_all(x, boundary(\"word\"))\n\n[1] │ &lt;This&gt; &lt;is&gt; &lt;a&gt; &lt;sentence&gt;.  &lt;This&gt; &lt;is&gt; &lt;another&gt; &lt;sentence&gt;.\n\nstr_view_all(x, boundary(\"sentence\"))\n\n[1] │ &lt;This is a sentence.  &gt;&lt;This is another sentence.&gt;\n\n\nОчень удобно, но убедитесь, что в вашем языке границы слов и предложения выглядят как у людей. С древнегреческим эта штука не справится (как делить на предложения греческие и латинские тексты, я рассказывала здесь):\n\napology &lt;- c(\"νῦν δ' ἐπειδὴ ἀνθρώπω ἐστόν, τίνα αὐτοῖν ἐν νῷ ἔχεις ἐπιστάτην λαβεῖν; τίς τῆς τοιαύτης ἀρετῆς, τῆς ἀνθρωπίνης τε καὶ πολιτικῆς, ἐπιστήμων ἐστίν; οἶμαι γάρ σε ἐσκέφθαι διὰ τὴν τῶν ὑέων κτῆσιν. ἔστιν τις,” ἔφην ἐγώ, “ἢ οὔ;” “Πάνυ γε,” ἦ δ' ὅς. “Τίς,” ἦν δ' ἐγώ, “καὶ ποδαπός, καὶ πόσου διδάσκει;\")\n\nstr_view_all(apology, boundary(\"sentence\"))\n\n[1] │ &lt;νῦν δ' ἐπειδὴ ἀνθρώπω ἐστόν, τίνα αὐτοῖν ἐν νῷ ἔχεις ἐπιστάτην λαβεῖν; τίς τῆς τοιαύτης ἀρετῆς, τῆς ἀνθρωπίνης τε καὶ πολιτικῆς, ἐπιστήμων ἐστίν; οἶμαι γάρ σε ἐσκέφθαι διὰ τὴν τῶν ὑέων κτῆσιν. ἔστιν τις,” ἔφην ἐγώ, “ἢ οὔ;” “Πάνυ γε,” ἦ δ' ὅς. &gt;&lt;“Τίς,” ἦν δ' ἐγώ, “καὶ ποδαπός, καὶ πόσου διδάσκει;&gt;\n\n\nПолный крах 💩",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "regex.html#footnotes",
    "href": "regex.html#footnotes",
    "title": "7  Регулярные выражения",
    "section": "",
    "text": "https://r4ds.had.co.nz/strings.html↩︎\nhttps://stringr.tidyverse.org/reference/str_sub.html↩︎\nhttps://r4ds.had.co.nz/strings.html#extract-matches↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Регулярные выражения</span>"
    ]
  },
  {
    "objectID": "scrape.html",
    "href": "scrape.html",
    "title": "8  Веб-скрапинг",
    "section": "",
    "text": "8.1 Структура html\nДокументы html (HyperText Markup Language) имеют ирархическую структуру, состоящую из элементов. В каждом элементе есть открывающий тег (&lt;tag&gt;), опциональные атрибуты (id='first') и закрывающий тег (&lt;/tag&gt;). Все, что находится между открывающим и закрывающим тегом, называется содержанием элемента.\nВажнейшие теги, о которых стоит знать:\nЧтобы увидеть структуру веб-страницы, надо нажать правую кнопку мыши и выбрать View Source (это работает и для тех html, которые хранятся у вас на компьютере).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#структура-html",
    "href": "scrape.html#структура-html",
    "title": "8  Веб-скрапинг",
    "section": "",
    "text": "&lt;html&gt; (есть всегда), с двумя детьми (дочерними элементами): &lt;head&gt; и &lt;body&gt;;\nэлементы, отвечающие за структуру: &lt;h1&gt; (заголовок), &lt;section&gt;, &lt;p&gt; (параграф), &lt;ol&gt; (упорядоченный список);\nэлементы, отвечающие за оформление: &lt;b&gt; (bold), &lt;i&gt; (italics), &lt;a&gt; (ссылка).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#каскадные-таблицы-стилей",
    "href": "scrape.html#каскадные-таблицы-стилей",
    "title": "8  Веб-скрапинг",
    "section": "8.2 Каскадные таблицы стилей",
    "text": "8.2 Каскадные таблицы стилей\nУ тегов могут быть именованные атрибуты; важнейшие из них – это id и class, которые в сочетании с CSS контролируют внешний вид страницы.\n\n\n\n\n\n\nНа заметку\n\n\n\nCSS (англ. Cascading Style Sheets «каскадные таблицы стилей») — формальный язык декорирования и описания внешнего вида документа (веб-страницы), написанного с использованием языка разметки (чаще всего HTML или XHTML).\n\n\nПример css-правила (такие инфобоксы использованы в предыдущей версии курса):\n\n.infobox {\n  padding: 1em 1em 1em 4em;\n  background: aliceblue 5px center/3em no-repeat;\n  color: black;\n}\n\n\nПроще говоря, это инструкция, что делать с тем или иным элементом. Каждое правило CSS имеет две основные части — селектор и блок объявлений. Селектор, расположенный в левой части правила до знака {, определяет, на какие части документа (возможно, специально обозначенные) распространяется правило. Блок объявлений располагается в правой части правила. Он помещается в фигурные скобки, и, в свою очередь, состоит из одного или более объявлений, разделённых знаком «;».\nСелекторы CSS полезны для скрапинга, потому что они помогают вычленить необходимые элементы. Это работает так:\n\np выберет все элементы &lt;p&gt;\n.title выберет элементы с классом “title”\n#title выберет все элементы с атрибутом id=‘title’\n\nВажно: если изменится структура страницы, откуда вы скрапили информацию, то и код придется переписывать.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#чтение-html",
    "href": "scrape.html#чтение-html",
    "title": "8  Веб-скрапинг",
    "section": "8.3 Чтение html",
    "text": "8.3 Чтение html\nЧтобы прочесть файл html, используем одноименную функцию.\n\nlibrary(rvest)\nantibarbari_files &lt;- list.files(\"../files/antibarbari_2024-08-18\", pattern = \"html\", full.names = TRUE)\n\nИспользуем пакет purrr, чтобы прочитать сразу три файла из архива.\n\nlibrary(tidyverse)\nantibarbari_archive &lt;- map(antibarbari_files, read_html)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#сбор-данных",
    "href": "scrape.html#сбор-данных",
    "title": "8  Веб-скрапинг",
    "section": "8.4 Сбор данных",
    "text": "8.4 Сбор данных\nНа следующем этапе важно понять, какие именно элементы нужны. Рассмотрим на примере одного сообщения. Для примера я сохраню этот элемент как небольшой отдельный html; rvest позволяет это сделать (но внутри двойных кавычек должны быть только одинарные):\n\nexample_html &lt;-  minimal_html(\"\n&lt;div class='message default clearfix' id='message83'&gt;\n      &lt;div class='pull_left userpic_wrap'&gt;\n       &lt;div class='userpic userpic2' style='width: 42px; height: 42px'&gt;\n        &lt;div class='initials' style='line-height: 42px'&gt;\nA\n        &lt;/div&gt;\n       &lt;/div&gt;\n      &lt;/div&gt;\n      &lt;div class='body'&gt;\n       &lt;div class='pull_right date details' title='19.05.2022 11:18:07 UTC+03:00'&gt;\n11:18\n       &lt;/div&gt;\n       &lt;div class='from_name'&gt;\nAntibarbari HSE \n       &lt;/div&gt;\n       &lt;div class='text'&gt;\nЭтот пост открывает серию переложений из «Дайджеста платоновских идиом» Джеймса Ридделла (1823–1866), английского филолога-классика, чей научный путь был связан с Оксфордским университетом. По приглашению Бенджамина Джоветта он должен был подготовить к изданию «Апологию», «Критон», «Федон» и «Пир». Однако из этих четырех текстов вышла лишь «Апология» с предисловием и приложением в виде «Дайджеста» (ссылка) — уже после смерти автора. &lt;br&gt;&lt;br&gt;«Дайджест» содержит 326 параграфов, посвященных грамматическим, синтаксическим и риторическим особенностям языка Платона. Знакомство с этим теоретическим материалом позволяет лучше почувствовать уникальный стиль философа и добиться большей точности при переводе. Ссылки на «Дайджест» могут быть уместны и в учебных комментариях к диалогам Платона. Предлагаемая здесь первая часть «Дайджеста» содержит «идиомы имен» и «идиомы артикля» (§§ 1–39).&lt;br&gt;&lt;a href='http://antibarbari.ru/2022/05/19/digest_1/'&gt;http://antibarbari.ru/2022/05/19/digest_1/&lt;/a&gt;\n       &lt;/div&gt;\n       &lt;div class='signature details'&gt;\nOlga Alieva\n       &lt;/div&gt;\n      &lt;/div&gt;\n     &lt;/div&gt;\n\")\n\nИз всего этого мне может быть интересно id сообщения (&lt;div class=‘message default clearfix’ id=‘message83’&gt;), текст сообщения (&lt;div class=‘text’&gt;), дата публикации (&lt;div class=‘pull_right date details’ title=‘19.05.2022 11:18:07 UTC+03:00’&gt;), а также, если указан, автор сообщения (&lt;div class=‘signature details’&gt;). Извлекаем текст (для этого рекомендуется использовать функцию html_text2()):\n\nexample_html |&gt;\n  html_element(\".text\") |&gt; \n  html_text2()\n\n[1] \"Этот пост открывает серию переложений из «Дайджеста платоновских идиом» Джеймса Ридделла (1823–1866), английского филолога-классика, чей научный путь был связан с Оксфордским университетом. По приглашению Бенджамина Джоветта он должен был подготовить к изданию «Апологию», «Критон», «Федон» и «Пир». Однако из этих четырех текстов вышла лишь «Апология» с предисловием и приложением в виде «Дайджеста» (ссылка) — уже после смерти автора.\\n\\n«Дайджест» содержит 326 параграфов, посвященных грамматическим, синтаксическим и риторическим особенностям языка Платона. Знакомство с этим теоретическим материалом позволяет лучше почувствовать уникальный стиль философа и добиться большей точности при переводе. Ссылки на «Дайджест» могут быть уместны и в учебных комментариях к диалогам Платона. Предлагаемая здесь первая часть «Дайджеста» содержит «идиомы имен» и «идиомы артикля» (§§ 1–39).\\nhttp://antibarbari.ru/2022/05/19/digest_1/\"\n\n\nВ классе signature details есть пробел, достаточно на его месте поставить точку:\n\nexample_html |&gt;\n  html_element(\".signature.details\") |&gt; \n  html_text2()\n\n[1] \"Olga Alieva\"\n\n\nВажно помнить, что html_element всегда возвращает один элемент. Если их больше, надо использовать html_elements.\nОсталось добыть дату и message id:\n\nexample_html |&gt; \n  html_element(\".pull_right.date.details\") |&gt; \n  html_attr(\"title\")\n\n[1] \"19.05.2022 11:18:07 UTC+03:00\"\n\n\n\nexample_html |&gt;\n  html_element(\"div\") |&gt; \n  html_attr(\"id\")\n\n[1] \"message83\"\n\n\nТеперь мы можем сохранить все нужные нам данные в таблицу.\n\ntibble(id = example_html |&gt; \n         html_element(\"div\") |&gt; \n         html_attr(\"id\"),\n       date = example_html |&gt; \n         html_element(\".pull_right.date.details\") |&gt; \n         html_attr(\"title\"),\n       signature = example_html |&gt;\n         html_element(\".signature.details\") |&gt; \n         html_text2(),\n       text = example_html |&gt; \n         html_element(\".text\") |&gt;\n         html_text2()\n)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#вложенные-элементы",
    "href": "scrape.html#вложенные-элементы",
    "title": "8  Веб-скрапинг",
    "section": "8.5 Вложенные элементы",
    "text": "8.5 Вложенные элементы\nДо сих пор наша задача упрощалась тем, что мы имели дело с игрушечным html для единственного сообщения. В настоящем html тег div повторяется на разных уровнях, и нам надо извлечь только такие div, которым соответствует определенный класс. Также не будем забывать, что архив выгрузился в виде трех html-файлов, так что понадобится наше знание итераций в purrr. Пока пробуем на одном из них:\n\narchive_1 &lt;- antibarbari_archive[[1]]\n\narchive_1 |&gt;\n  html_elements(\"div.message.default\") |&gt; \n  head()\n\n{xml_nodeset (6)}\n[1] &lt;div class=\"message default clearfix\" id=\"message3\"&gt;\\n\\n      &lt;div class= ...\n[2] &lt;div class=\"message default clearfix\" id=\"message5\"&gt;\\n\\n      &lt;div class= ...\n[3] &lt;div class=\"message default clearfix\" id=\"message6\"&gt;\\n\\n      &lt;div class= ...\n[4] &lt;div class=\"message default clearfix\" id=\"message7\"&gt;\\n\\n      &lt;div class= ...\n[5] &lt;div class=\"message default clearfix\" id=\"message8\"&gt;\\n\\n      &lt;div class= ...\n[6] &lt;div class=\"message default clearfix\" id=\"message9\"&gt;\\n\\n      &lt;div class= ...\n\n\nУже из этого списка можем доставать все остальное.\n\narchive_1_tbl &lt;- tibble(id = archive_1 |&gt; \n         html_elements(\"div.message.default\") |&gt; \n         html_attr(\"id\"),\n       date = archive_1 |&gt; \n         html_elements(\"div.message.default\") |&gt; \n         html_element(\".pull_right.date.details\") |&gt; \n         html_attr(\"title\"),\n       signature = archive_1 |&gt;\n         html_elements(\"div.message.default\") |&gt; \n         html_element(\".signature.details\") |&gt; \n         html_text2(),\n       text = archive_1 |&gt; \n         html_elements(\"div.message.default\") |&gt; \n         html_element(\".text\") |&gt;\n         html_text2()\n)\n\narchive_1_tbl\n\n\n  \n\n\n\nОбратите внимание, что мы сначала извлекаем нужные элементы при помощи html_elements(), а потом применяем к каждому из них html_element(). Это гарантирует, что в каждом столбце нашей таблицы равное число наблюдений, т.к. функция html_element(), если она не может найти, например, подпись, возвращает NA.\nКак вы уже поняли, теперь нам надо проделать для двух других файлов из архива антиварваров, а значит пришло время превратить наш код в функцию.\n\nlibrary(rvest)\nscrape_antibarbari &lt;- function(html_file){\n  messages_tbl &lt;- tibble(\n    id = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_attr(\"id\"),\n    date = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_element(\".pull_right.date.details\") |&gt;\n      html_attr(\"title\"),\n    signature = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_element(\".signature.details\") |&gt;\n      html_text2(),\n    text = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_element(\".text\") |&gt;\n      html_text2()\n  )\n  messages_tbl\n}\n\n\nmessages_tbl &lt;- map_df(antibarbari_archive, scrape_antibarbari)\n\nВот что у нас получилось.\n\nmessages_tbl",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#разведывательный-анализ",
    "href": "scrape.html#разведывательный-анализ",
    "title": "8  Веб-скрапинг",
    "section": "8.6 Разведывательный анализ",
    "text": "8.6 Разведывательный анализ\nСоздатели канала не сразу разрешили подписывать посты, поэтому для первых нескольких десятков подписи не будет. Кроме того, в некоторых постах только фото, для них в столбце text – NA, их можно сразу отсеять.\n\nmessages_tbl &lt;- messages_tbl |&gt;\n  filter(!is.na(text))\n\nmessages_tbl\n\n\n  \n\n\n\nТакже преобразуем столбец, в котором хранится дата и время. Разделим его на два и выясним, в какое время и день недели чаще всего публикуются сообщения.\n\n\n\n\n\n\nЗадание\n\n\n\nИз курса Getting and Cleaning Data в swirl будет полезно пройти урок Dates and Times with lubridate.\n\n\n\nmessages_tbl2 &lt;- messages_tbl |&gt; \n  separate(date, into = c(\"date\", \"time\", NA), sep = \" \") |&gt; \n  mutate(date = dmy(date), \n         time = hms(time)) |&gt; \n  mutate(year = year(date), \n        month = month(date, label = TRUE),\n        wday = wday(date, label = TRUE),\n        hour = hour(time),\n        length = str_count(text, \" \") + 1) |&gt; \n  mutate(wday = factor(wday, levels = c(\"Sun\", \"Sat\", \"Fri\", \"Thu\", \"Wed\", \"Tue\", \"Mon\")))\n\n\nmessages_tbl2\n\n\n  \n\n\n\n\nsummary1 &lt;- messages_tbl2 |&gt; \n  group_by(year, month) |&gt; \n  summarise(n = n()) \n\nsummary1\n\n\n  \n\n\nsummary2 &lt;- messages_tbl2 |&gt; \n  group_by(year, hour) |&gt; \n  summarise(n = n()) |&gt; \n  mutate(hour = case_when(hour == 0 ~ 24,\n                          .default = hour))\n\nsummary2\n\n\n  \n\n\nsummary3 &lt;- messages_tbl2 |&gt; \n   group_by(wday) |&gt; \n   summarise(n = n())\n\nsummary3\n\n\n  \n\n\n\n\nlibrary(gridExtra)\nlibrary(grid)\n\np1 &lt;- summary1 |&gt; \n  ggplot(aes(month, n, color = as.factor(year), group = year)) +\n  geom_line(show.legend = FALSE, linewidth = 1.2, alpha = 0.8) +\n  labs(title = \"Число постов в месяц\") +\n  theme(legend.title = element_blank(), \n        legend.position = c(0.8, 0.3),\n        title = element_text(face=\"italic\")) +\n  labs(x = NULL, y = NULL) +\n  scale_color_viridis_d()\n\n\np2 &lt;- summary2 |&gt; \n  ggplot(aes(hour, n, color = as.factor(year), group = year)) + \n  geom_line(linewidth = 1.2, alpha = 0.8) +\n  scale_x_continuous(breaks = seq(1,24,1)) +\n  labs(x = NULL, y = NULL, title = \"Время публикации поста\") + \n  theme(legend.title = element_blank(), \n        legend.position = \"left\",\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        title = element_text(face=\"italic\")\n        ) +\n  coord_polar(start = 0) +\n  scale_color_viridis_d()\n\n\np3 &lt;- summary3 |&gt; \n  ggplot(aes(wday, n, fill = wday)) + \n  geom_bar(stat = \"identity\", \n           show.legend = FALSE) + \n  coord_flip() + \n  labs(x = NULL, y = NULL, title  = \"Публикации по дням недели\") +\n  theme(title = element_text(face=\"italic\"))\n\n\np4 &lt;- messages_tbl2 |&gt; \n  ggplot(aes(as.factor(year), length, fill = as.factor(year))) +\n  geom_boxplot(show.legend = FALSE) +\n  labs(title = \"Длина поста по годам\") + \n  labs(x = NULL, y = NULL) + \n  scale_fill_viridis_d() + \n  theme(title = element_text(face=\"italic\"))\n\n\ngrid.arrange(p1, p2, p3, p4, nrow = 2,\n             top =  textGrob(\"Телеграм-канал Antibarbari HSE\",\n                    gp=gpar(fontsize=16)),\n             bottom = textGrob(\"@Rantiquity\",\n                    gp = gpar(fontface = 3, fontsize = 9), hjust = 1, x = 1))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#эмотиконы",
    "href": "scrape.html#эмотиконы",
    "title": "8  Веб-скрапинг",
    "section": "8.7 Эмотиконы",
    "text": "8.7 Эмотиконы\nВ постах довольно много эмотиконов. Я их удалю, но сначала скажу о полезном пакете, который позволяет их все извлечь и, например, посчитать.\n\nlibrary(emoji)\n\nmessages_tbl |&gt; \n  mutate(emoji = emoji_extract_all(text)) |&gt; \n  pull(emoji) |&gt; \n  unlist() |&gt; \n  as_tibble() |&gt;\n  count(value) |&gt; \n  arrange(-n) \n\n\n  \n\n\n\nЗаменяем их все на пробелы.\n\nmessages_tbl &lt;- messages_tbl |&gt; \n  mutate(text = emoji_replace_all(text, \" \"))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#рутинная-уборка",
    "href": "scrape.html#рутинная-уборка",
    "title": "8  Веб-скрапинг",
    "section": "8.8 Рутинная уборка",
    "text": "8.8 Рутинная уборка\nПодготовка текста для анализа включает в себя удаление сносок, иногда хэштегов, чисел, имейлов, возможно имен и т.п. В нашем случае ситуация осложняется тем, что тексты включают цитаты на латыни и древнегреческом, некоторые технические сокращения, номера страниц и др. Вот так, например, выглядит типичный пост:\n\nexample &lt;- messages_tbl$text[340]\n\nexample\n\n[1] \"🎞 Теэтет #10 149b7-150b8\\nСократ продолжает засыпать семнадцатилетнего математика подробностями из области акушерства и гинекологии, и мы вместе с ним терпеливо изучаем, чем сводничество отличается от сватовства. Верните квадратные корни. #платон #теэтет\\nhttps://vk.com/video-211800158_456239238\"\n\n\nВот так вылавливается гиперссылка.\n\nstr_extract_all(example, \"(http|https)(\\\\S+)\")\n\n[[1]]\n[1] \"https://vk.com/video-211800158_456239238\"\n\n\nВот так вылавливается пагинация и номер семинара (и некоторые другие числа).\n\nstr_extract_all(example, \"#?\\\\d{2,3}\\\\w?\\\\d?-?\")\n\n[[1]]\n[1] \"#10\"    \"149b7-\" \"150b8\"  \"21180\"  \"0158\"   \"45623\"  \"9238\"  \n\n\nПохожим образом можно выловить даты, имейлы и т.п. Все это удаляем из текста.\n\nmessages_clean &lt;- messages_tbl |&gt; \n  mutate(text = str_replace_all(text, \"(http|https)(\\\\S+)\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"\\\\d{2}\\\\.\\\\d{2}\\\\.\\\\d{4}\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"\\\\W[-A-Za-z0-9_.%]+\\\\@[-A-Za-z0-9_.%]+\\\\.[A-Za-z]\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"#?\\\\d{2,3}\\\\w?\\\\d?-?\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"\\\\n+\", \" \"))\n\nОстались еще сокращения вроде “г.”, но токены из одной буквы можно будет удалить после разделения на слова. Знаки пунктуации можно оставить или убрать – иногда они бывают интересным стилистическим маркером. В любом случае лучше это делать после лемматизации, т.к. на тексте без знаков препинания анализатор покажет себя хуже.\n\nmessages_clean |&gt; \n  filter(row_number() == 340)\n\n\n  \n\n\n\nЧисло id и число текстов не совпадает, поскольку для некоторых постов текста нет (NA), а у других он совпадает (“Пост выходного дня”). Это надо сразу исправить, чтобы результат лемматизации можно было потом соединить с данными о подписи. Я просто уберу очень короткие посты, поскольку для анализа они неинтересны.\n\nmessages_clean &lt;- messages_clean |&gt;\n  filter(nchar(text) &gt; 19)\n\n\ndim(messages_clean)\n\n[1] 1362    4\n\n\nПереименуем первый столбец и переназначим id, чтобы можно было потом соединить с результатами лемматизации.\n\nmessages_clean &lt;- messages_clean |&gt; \n  rename(doc_id = id) |&gt; \n  mutate(doc_id = paste0(\"doc\", row_number()))",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#html-таблицы",
    "href": "scrape.html#html-таблицы",
    "title": "8  Веб-скрапинг",
    "section": "8.7 Html таблицы",
    "text": "8.7 Html таблицы\nЕсли вам повезет, то ваши данные уже будут храниться в HTML-таблице, и их можно будет просто считать из этой таблицы. Распознать таблицу в браузере обычно несложно: она имеет прямоугольную структуру из строк и столбцов, и ее можно скопировать и вставить в такой инструмент, как Excel.\nТаблицы HTML строятся из четырех основных элементов: &lt;table&gt;, &lt;tr&gt; (строка таблицы), &lt;th&gt; (заголовок таблицы) и &lt;td&gt; (данные таблицы). Мы достанем программу курса “Количественные методы в гуманитарных науках: критическое введение” (2023/2024).\n\nhtml &lt;- read_html(\"http://criticaldh.ru/program/\")\nmy_table &lt;- html |&gt;  \n  html_table() |&gt; \n  pluck(1)\n\nmy_table\n\n\n  \n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nС сайта Новой философской энциклопедии извлеките список слов на букву П. Используйте map_df() для объединения таблиц.\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nСколько всего слов на букву П в НФЭ?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#wikisource",
    "href": "scrape.html#wikisource",
    "title": "8  Веб-скрапинг",
    "section": "8.8 Wikisource",
    "text": "8.8 Wikisource\nМногие тексты доступны на сайте Wikisource.org. Попробуем извлечь все сказки Салтыкова-Щедрина.\n\nurl &lt;- \"https://ru.wikisource.org/wiki/%D0%9C%D0%B8%D1%85%D0%B0%D0%B8%D0%BB_%D0%95%D0%B2%D0%B3%D1%80%D0%B0%D1%84%D0%BE%D0%B2%D0%B8%D1%87_%D0%A1%D0%B0%D0%BB%D1%82%D1%8B%D0%BA%D0%BE%D0%B2-%D0%A9%D0%B5%D0%B4%D1%80%D0%B8%D0%BD\"\nhtml = read_html(url)\n\nДля того, чтобы справиться с такой страницей, пригодится Selector Gadget (расширение для Chrome). Вот тут можно посмотреть короткое видео, как его установить. При помощи селектора выбираем нужные уровни.\n\ntoc &lt;- html |&gt; \n  html_elements(\"ul:nth-child(22) a\")\n\nhead(toc)\n\n{xml_nodeset (6)}\n[1] &lt;a href=\"/wiki/%D0%9F%D0%BE%D0%B2%D0%B5%D1%81%D1%82%D1%8C_%D0%BE_%D1%82%D ...\n[2] &lt;a href=\"/wiki/%D0%93%D0%BE%D0%B4%D0%BE%D0%B2%D1%89%D0%B8%D0%BD%D0%B0_(%D ...\n[3] &lt;a href=\"/wiki/%D0%9F%D1%80%D0%BE%D0%BF%D0%B0%D0%BB%D0%B0_%D1%81%D0%BE%D0 ...\n[4] &lt;a href=\"/wiki/%D0%94%D0%B8%D0%BA%D0%B8%D0%B9_%D0%BF%D0%BE%D0%BC%D0%B5%D1 ...\n[5] &lt;a href=\"/wiki/%D0%9F%D1%80%D0%B5%D0%BC%D1%83%D0%B4%D1%80%D1%8B%D0%B9_%D0 ...\n[6] &lt;a href=\"/wiki/%D0%A1%D0%B0%D0%BC%D0%BE%D0%BE%D1%82%D0%B2%D0%B5%D1%80%D0% ...\n\n\nТеперь у нас есть список ссылок.\n\ntales &lt;- tibble(\n  title = toc |&gt;\n    html_attr(\"title\"),\n  href = toc |&gt; \n    html_attr(\"href\")\n)\n\nДанных о годе публикации под тегом  нет; надо подняться на уровень выше:\n\ntoc2 &lt;- html |&gt; \n  html_elements(\"ul:nth-child(22) li\")\n\nhead(toc2)\n\n{xml_nodeset (6)}\n[1] &lt;li&gt;\\n&lt;a href=\"/wiki/%D0%9F%D0%BE%D0%B2%D0%B5%D1%81%D1%82%D1%8C_%D0%BE_%D ...\n[2] &lt;li&gt;\\n&lt;a href=\"/wiki/%D0%93%D0%BE%D0%B4%D0%BE%D0%B2%D1%89%D0%B8%D0%BD%D0% ...\n[3] &lt;li&gt;\\n&lt;a href=\"/wiki/%D0%9F%D1%80%D0%BE%D0%BF%D0%B0%D0%BB%D0%B0_%D1%81%D0 ...\n[4] &lt;li&gt;\\n&lt;a href=\"/wiki/%D0%94%D0%B8%D0%BA%D0%B8%D0%B9_%D0%BF%D0%BE%D0%BC%D0 ...\n[5] &lt;li&gt;\\n&lt;a href=\"/wiki/%D0%9F%D1%80%D0%B5%D0%BC%D1%83%D0%B4%D1%80%D1%8B%D0% ...\n[6] &lt;li&gt;\\n&lt;a href=\"/wiki/%D0%A1%D0%B0%D0%BC%D0%BE%D0%BE%D1%82%D0%B2%D0%B5%D1% ...\n\n\n\ntoc2 |&gt;\n  html_text2()\n\n [1] \"Повесть о том, как один мужик двух генералов прокормил, 1869\"\n [2] \"Годовщина, 1869\"                                             \n [3] \"Пропала совесть, 1869\"                                       \n [4] \"Дикий помещик, 1869\"                                         \n [5] \"Премудрый пискарь, 1883\"                                     \n [6] \"Самоотверженный заяц, 1883\"                                  \n [7] \"Бедный волк, 1883\"                                           \n [8] \"Добродетели и Пороки, 1884\"                                  \n [9] \"Медведь на воеводстве, 1884\"                                 \n[10] \"Обманщик-газетчик и легковерный читатель, 1884\"              \n[11] \"Вяленая вобла, 1884\"                                         \n[12] \"Орёл-меценат, 1884\"                                          \n[13] \"Карась-идеалист, 1884\"                                       \n[14] \"Игрушечного дела людишки, 1879, 1886\"                        \n[15] \"Чижиково горе, 1884\"                                         \n[16] \"Верный Трезор, 1885\"                                         \n[17] \"Недреманное око, конец 1885 или начало 1886\"                 \n[18] \"Дурак, 1885\"                                                 \n[19] \"Соседи, 1885\"                                                \n[20] \"Здравомысленный заяц, 1885\"                                  \n[21] \"Либерал, 1885\"                                               \n[22] \"Баран-непомнящий, 1885\"                                      \n[23] \"Коняга, 1855\"                                                \n[24] \"Кисель, 1855\"                                                \n[25] \"Праздный разговор, 1886\"                                     \n[26] \"Деревенский пожар, 1885\"                                     \n[27] \"Путём-дорогою, 1886\"                                         \n[28] \"Богатырь, 1886\"                                              \n[29] \"Гиена, 1886\"                                                 \n[30] \"Приключение с Крамольниковым, 1886\"                          \n[31] \"Христова ночь, 1886\"                                         \n[32] \"Ворон-челобитчик, 1886\"                                      \n[33] \"Рождественская сказка, 1886\"                                 \n\n\nСоединяем:\n\ntales &lt;- tibble(\n  title_year = toc2 |&gt;\n    html_text2(),\n  href = toc |&gt; \n    html_attr(\"href\")\n)\n\ntales\n\n\n  \n\n\n\nДальше можно достать текст для каждой сказки. Потренируемся на одной. Снова привлекаем Selector Gadget для составления правила.\n\nurl_test &lt;- tales |&gt; \n  filter(row_number() == 1) |&gt; \n  mutate(link = paste0(\"https://ru.wikisource.org\", href)) |&gt; \n  pull(link)\n\ntext &lt;- read_html(url_test) |&gt; \n  html_elements(\".indent p\") |&gt; \n  html_text2() \n\ntext[1]\n\n[1] \"Жили да были два генерала, и так как оба были легкомысленны, то в скором времени, по щучьему велению, по моему хотению, очутились на необитаемом острове.\"\n\ntext[length(text)]\n\n[1] \"Однако, и об мужике не забыли; выслали ему рюмку водки да пятак серебра: веселись, мужичина!\"\n\n\nПервый и последний параграф достали верно; можно обобщать.\n\ntales &lt;- tales |&gt; \n    mutate(href = paste0(\"https://ru.wikisource.org\", href))\n\n\nurls &lt;- tales |&gt; \n  pull(href)\n\nФункция для извлечения текстов.\n\nget_text &lt;- function(url) {\n  read_html(url) |&gt; \n  html_elements(\".indent p\") |&gt; \n  html_text2() |&gt; \n  paste(collapse= \" \")\n}\n\n\ntales_text &lt;- map(urls, get_text)\n\nНесколько сказок не выловились: там другая структура html, но в целом все получилось.\n\ntales_text &lt;- tales_text |&gt;\n  flatten_chr() |&gt; \n  as_tibble()\n\ntales &lt;- tales |&gt; \n  bind_cols(tales_text)\n\n\ntales\n\n\n  \n\n\n\nДальше можно разделить столбец с названием и годом и, например, удалить ссылку, она больше не нужна. Разделить по запятой не получится, т.к. она есть в некоторых названиях.\n\ntales &lt;- tales |&gt; \n  select(-href) |&gt; \n  separate(title_year, into = c(\"title\", \"year\"), sep = -5) |&gt; \n  mutate(title = str_remove(title, \",$\"))\n\n\ntales\n\n\n  \n\n\n\nНедостающие две сказки я не буду пытаться извлечь, но логику вы поняли.\n\nПоздравляем, на этом закончился первый большой раздел нашего курса “Основы работы в R” 🎆. За восемь уроков вы познакомились с основными структурами данных в R, научились собирать и трансформировать данные, строить графики, писать функции и циклы, а также готовить html-отчеты о своих исследованиях. Впереди нас ждут методы анализа текстовых данных.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#footnotes",
    "href": "scrape.html#footnotes",
    "title": "8  Веб-скрапинг",
    "section": "",
    "text": "https://r4ds.hadley.nz/webscraping#tables↩︎",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#парсинг-html-отдельные-элементы",
    "href": "scrape.html#парсинг-html-отдельные-элементы",
    "title": "8  Веб-скрапинг",
    "section": "8.4 Парсинг html: отдельные элементы",
    "text": "8.4 Парсинг html: отдельные элементы\nНа следующем этапе важно понять, какие именно элементы нужны. Рассмотрим на примере одного сообщения. Для примера я сохраню этот элемент как небольшой отдельный html; rvest позволяет это сделать (но внутри двойных кавычек должны быть только одинарные):\n\nexample_html &lt;-  minimal_html(\"\n&lt;div class='message default clearfix' id='message83'&gt;\n      &lt;div class='pull_left userpic_wrap'&gt;\n       &lt;div class='userpic userpic2' style='width: 42px; height: 42px'&gt;\n        &lt;div class='initials' style='line-height: 42px'&gt;\nA\n        &lt;/div&gt;\n       &lt;/div&gt;\n      &lt;/div&gt;\n      &lt;div class='body'&gt;\n       &lt;div class='pull_right date details' title='19.05.2022 11:18:07 UTC+03:00'&gt;\n11:18\n       &lt;/div&gt;\n       &lt;div class='from_name'&gt;\nAntibarbari HSE \n       &lt;/div&gt;\n       &lt;div class='text'&gt;\nЭтот пост открывает серию переложений из «Дайджеста платоновских идиом» Джеймса Ридделла (1823–1866), английского филолога-классика, чей научный путь был связан с Оксфордским университетом. По приглашению Бенджамина Джоветта он должен был подготовить к изданию «Апологию», «Критон», «Федон» и «Пир». Однако из этих четырех текстов вышла лишь «Апология» с предисловием и приложением в виде «Дайджеста» (ссылка) — уже после смерти автора. &lt;br&gt;&lt;br&gt;«Дайджест» содержит 326 параграфов, посвященных грамматическим, синтаксическим и риторическим особенностям языка Платона. Знакомство с этим теоретическим материалом позволяет лучше почувствовать уникальный стиль философа и добиться большей точности при переводе. Ссылки на «Дайджест» могут быть уместны и в учебных комментариях к диалогам Платона. Предлагаемая здесь первая часть «Дайджеста» содержит «идиомы имен» и «идиомы артикля» (§§ 1–39).&lt;br&gt;&lt;a href='http://antibarbari.ru/2022/05/19/digest_1/'&gt;http://antibarbari.ru/2022/05/19/digest_1/&lt;/a&gt;\n       &lt;/div&gt;\n       &lt;div class='signature details'&gt;\nOlga Alieva\n       &lt;/div&gt;\n      &lt;/div&gt;\n     &lt;/div&gt;\n\")\n\nИз всего этого мне может быть интересно id сообщения (\\&lt;div class='message default clearfix' id='message83'\\&gt;), текст сообщения (\\&lt;div class='text'\\&gt;), дата публикации (\\&lt;div class='pull_right date details' title='19.05.2022 11:18:07 UTC+03:00'\\&gt;), а также, если указан, автор сообщения (\\&lt;div class='signature details'\\&gt;). Извлекаем текст (для этого рекомендуется использовать функцию html_text2()):\n\nexample_html |&gt;\n  html_element(\".text\") |&gt; \n  html_text2()\n\n[1] \"Этот пост открывает серию переложений из «Дайджеста платоновских идиом» Джеймса Ридделла (1823–1866), английского филолога-классика, чей научный путь был связан с Оксфордским университетом. По приглашению Бенджамина Джоветта он должен был подготовить к изданию «Апологию», «Критон», «Федон» и «Пир». Однако из этих четырех текстов вышла лишь «Апология» с предисловием и приложением в виде «Дайджеста» (ссылка) — уже после смерти автора.\\n\\n«Дайджест» содержит 326 параграфов, посвященных грамматическим, синтаксическим и риторическим особенностям языка Платона. Знакомство с этим теоретическим материалом позволяет лучше почувствовать уникальный стиль философа и добиться большей точности при переводе. Ссылки на «Дайджест» могут быть уместны и в учебных комментариях к диалогам Платона. Предлагаемая здесь первая часть «Дайджеста» содержит «идиомы имен» и «идиомы артикля» (§§ 1–39).\\nhttp://antibarbari.ru/2022/05/19/digest_1/\"\n\n\nВ классе signature details есть пробел, достаточно на его месте поставить точку:\n\nexample_html |&gt;\n  html_element(\".signature.details\") |&gt; \n  html_text2()\n\n[1] \"Olga Alieva\"\n\n\nОсталось добыть дату и message id:\n\nexample_html |&gt; \n  html_element(\".pull_right.date.details\") |&gt; \n  html_attr(\"title\")\n\n[1] \"19.05.2022 11:18:07 UTC+03:00\"\n\n\n\nexample_html |&gt;\n  html_element(\"div\") |&gt; \n  html_attr(\"id\")\n\n[1] \"message83\"\n\n\nТеперь мы можем сохранить все нужные нам данные в таблицу.\n\ntibble(id = example_html |&gt; \n         html_element(\"div\") |&gt; \n         html_attr(\"id\"),\n       date = example_html |&gt; \n         html_element(\".pull_right.date.details\") |&gt; \n         html_attr(\"title\"),\n       signature = example_html |&gt;\n         html_element(\".signature.details\") |&gt; \n         html_text2(),\n       text = example_html |&gt; \n         html_element(\".text\") |&gt;\n         html_text2()\n)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "scrape.html#парсинг-html-вложенные-элементы",
    "href": "scrape.html#парсинг-html-вложенные-элементы",
    "title": "8  Веб-скрапинг",
    "section": "8.5 Парсинг html: вложенные элементы",
    "text": "8.5 Парсинг html: вложенные элементы\nДо сих пор наша задача упрощалась тем, что мы имели дело с игрушечным html для единственного сообщения. В настоящем html тег div повторяется на разных уровнях, и нам надо извлечь только такие div, которым соответствует определенный класс. Также не будем забывать, что архив выгрузился в виде трех html-файлов, так что понадобится наше знание итераций в purrr. Пока пробуем на одном из них:\n\narchive_1 &lt;- antibarbari_archive[[1]]\n\narchive_1 |&gt;\n  html_elements(\"div.message.default\") |&gt; \n  head()\n\n{xml_nodeset (6)}\n[1] &lt;div class=\"message default clearfix\" id=\"message3\"&gt;\\n\\n      &lt;div class= ...\n[2] &lt;div class=\"message default clearfix\" id=\"message5\"&gt;\\n\\n      &lt;div class= ...\n[3] &lt;div class=\"message default clearfix\" id=\"message6\"&gt;\\n\\n      &lt;div class= ...\n[4] &lt;div class=\"message default clearfix\" id=\"message7\"&gt;\\n\\n      &lt;div class= ...\n[5] &lt;div class=\"message default clearfix\" id=\"message8\"&gt;\\n\\n      &lt;div class= ...\n[6] &lt;div class=\"message default clearfix\" id=\"message9\"&gt;\\n\\n      &lt;div class= ...\n\n\nУже из этого набора узлов можем доставать все остальное.\n\narchive_1_tbl &lt;- tibble(id = archive_1 |&gt; \n         html_elements(\"div.message.default\") |&gt; \n         html_attr(\"id\"),\n       date = archive_1 |&gt; \n         html_elements(\"div.message.default\") |&gt; \n         html_element(\".pull_right.date.details\") |&gt; \n         html_attr(\"title\"),\n       signature = archive_1 |&gt;\n         html_elements(\"div.message.default\") |&gt; \n         html_element(\".signature.details\") |&gt; \n         html_text2(),\n       text = archive_1 |&gt; \n         html_elements(\"div.message.default\") |&gt; \n         html_element(\".text\") |&gt;\n         html_text2()\n)\n\narchive_1_tbl\n\n\n  \n\n\n\nОбратите внимание, что мы сначала извлекаем нужные элементы при помощи html_elements(), а потом применяем к каждому из них html_element(). Это гарантирует, что в каждом столбце нашей таблицы равное число наблюдений, т.к. функция html_element(), если она не может найти, например, подпись, возвращает NA.\nКак вы уже поняли, теперь нам надо проделать то же самое для двух других файлов из архива антиварваров, а значит пришло время превратить наш код в функцию.\n\nscrape_antibarbari &lt;- function(html_file){\n  messages_tbl &lt;- tibble(\n    id = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_attr(\"id\"),\n    date = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_element(\".pull_right.date.details\") |&gt;\n      html_attr(\"title\"),\n    signature = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_element(\".signature.details\") |&gt;\n      html_text2(),\n    text = html_file |&gt;\n      html_elements(\"div.message.default\") |&gt;\n      html_element(\".text\") |&gt;\n      html_text2()\n  )\n  messages_tbl\n}\n\n\nmessages_tbl &lt;- map_df(antibarbari_archive, scrape_antibarbari)\n\nВот что у нас получилось.\n\nmessages_tbl",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html",
    "href": "tokenize.html",
    "title": "9  Синтаксический парсинг",
    "section": "",
    "text": "9.1 Токенизация\nТокенизация — процесс разделения текста на составляющие (их называют «токенами»). Токенами могут быть слова, символьные или словесные энграмы (n-grams), то есть сочетания символов или слов, даже предложения или параграфы.\nТокенизировать можно в базовом R с использованием регулярных выражений, и Jockers (2014) прекрасно показывает, как это можно делать. Но мы воспользуемся двумя пакетами, которые предназначены специально для работы с текстовыми данными и разделяют идеологию tidyverse: tidytext (Silge и Robinson 2017) и tokenizers (Hvitfeldt и Silge 2022).\nlibrary(tidyverse) \nlibrary(tidytext)\nlibrary(tokenizers)\nДля анализа воспользуемся датасетом c латинским текстом “Записок о Галльской войне”, который мы подготовили в предыдущем уроке. Его можно забрать отсюда.\nload(\"../data/caesar.RData\")\ncaesar &lt;- caesar |&gt; \n  rename(text = value) |&gt; \n  select(-link)\n\ncaesar\nФункция unnest_tokens() из пакета tidytext принимает на входе тиббл, название столбца, в котором хранится текст для токенизации, а также название нового столбца, куда будут “сложены” отдельные токены (зачастую это слова, но не обязательно).\nАргумент token принимает следующие значения:\nИспользуя уже знакомую функцию map, можно запустить unnest_tokens() с разными аргументами:\ntest &lt;- tibble(text = \"Gallia est omnis divisa in partes tres, quarum unam incolunt Belgae, aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur. Hi omnes lingua, institutis, legibus inter se differunt.\")\nparams &lt;- tribble(\n  ~tbl, ~output, ~input, ~token,\n  test, \"word\", \"text\", \"words\", \n  test, \"sentence\", \"text\", \"sentences\",\n  test, \"char\", \"text\", \"characters\", \n)\n\nparams\nparams |&gt; \n  pmap(unnest_tokens) \n\n[[1]]\n# A tibble: 29 × 1\n   word    \n   &lt;chr&gt;   \n 1 gallia  \n 2 est     \n 3 omnis   \n 4 divisa  \n 5 in      \n 6 partes  \n 7 tres    \n 8 quarum  \n 9 unam    \n10 incolunt\n# ℹ 19 more rows\n\n[[2]]\n# A tibble: 2 × 1\n  sentence                                                                      \n  &lt;chr&gt;                                                                         \n1 gallia est omnis divisa in partes tres, quarum unam incolunt belgae, aliam aq…\n2 hi omnes lingua, institutis, legibus inter se differunt.                      \n\n[[3]]\n# A tibble: 166 × 1\n   char \n   &lt;chr&gt;\n 1 g    \n 2 a    \n 3 l    \n 4 l    \n 5 i    \n 6 a    \n 7 e    \n 8 s    \n 9 t    \n10 o    \n# ℹ 156 more rows\nСледующие значения аргумента token требуют также аргумента n:\nparams &lt;- tribble(\n  ~tbl, ~output, ~input, ~token, ~n,\n  test, \"ngram\", \"text\", \"ngrams\", 3,\n  test, \"shingles\", \"text\", \"character_shingles\", 3\n)\n\nparams  |&gt; \n  pmap(unnest_tokens)  |&gt; \n  head()\n\n[[1]]\n# A tibble: 27 × 1\n   ngram                \n   &lt;chr&gt;                \n 1 gallia est omnis     \n 2 est omnis divisa     \n 3 omnis divisa in      \n 4 divisa in partes     \n 5 in partes tres       \n 6 partes tres quarum   \n 7 tres quarum unam     \n 8 quarum unam incolunt \n 9 unam incolunt belgae \n10 incolunt belgae aliam\n# ℹ 17 more rows\n\n[[2]]\n# A tibble: 164 × 1\n   shingles\n   &lt;chr&gt;   \n 1 gal     \n 2 all     \n 3 lli     \n 4 lia     \n 5 iae     \n 6 aes     \n 7 est     \n 8 sto     \n 9 tom     \n10 omn     \n# ℹ 154 more rows\nДальше мы будем работать со словами, поэтому сохраним токенизированный текст “Записок” в виде “опрятного” датасета (одно наблюдение - один ряд).\ncaesar_tokens &lt;- caesar |&gt; \n  unnest_tokens(\"word\", \"text\")\n\ncaesar_tokens\nПри работе с данными в текстовом формате unnest_tokens() опирается на пакет tokenizers, из которого в нашем случае подтягивает функцию tokenize_words. У этой функции есть несколько полезных аргументов: strip_non_alphanum (удаляет пробельные символы и пунктуацию), strip_punct (удаляет пунктуацию), strip_numeric (удаляет числа).\nЭти аргументы мы тоже можем задать через unnest_tokens(), поскольку у функции есть аргумент ... (загляните в документацию, чтобы убедиться).\ncaesar |&gt; \n  unnest_tokens(\"word\", \"text\", strip_punct = FALSE)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#токенизация-в-tidytext",
    "href": "tokenize.html#токенизация-в-tidytext",
    "title": "9  Токенизация и лемматизация",
    "section": "",
    "text": "unnest_tokens(\n  tbl,\n  output,\n  input,\n  token = \"words\",\n  format = c(\"text\", \"man\", \"latex\", \"html\", \"xml\"),\n  to_lower = TRUE,\n  drop = TRUE,\n  collapse = NULL,\n  ...\n)\n\n\n“words” (default),\n“characters”,\n“character_shingles”,\n“ngrams”,\n“skip_ngrams”,\n“sentences”,\n“lines”,\n“paragraphs”,\n“regex”,\n“ptb” (Penn Treebank).\n\n\n\n\n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nВоспроизведите код из книги Silge и Robinson (2017) (ниже). Объясните, что делает каждая строчка кода. Разбейте книги на словесные и символьные энграмы.\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nКакая словесная 3-грама чаще всего встречается в первой главе “Pride & Prejudice”? Впишите в поле ниже (после последней буквы не должно быть пробела). Если ответов несколько, впишите любой.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "tokenize.html#токенизация-в-tokenizers",
    "href": "tokenize.html#токенизация-в-tokenizers",
    "title": "9  Токенизация и лемматизация",
    "section": "9.2 Токенизация в tokenizers",
    "text": "9.2 Токенизация в tokenizers\nПри работе с данными в текстовом формате unnest_tokens() опирается на пакет tokenizers, но tokenize_words требует на входе вектор, а не тиббл. Несколько полезных аргументов, о которых стоит помнить: strip_non_alphanum (удаляет пробельные символы и пунктуацию), strip_punct (удаляет пунктуацию), strip_numeric (удаляет числа).\n\nwords_no_punct &lt;- tokenize_words(test$text, strip_punct = T)\nwords_no_punct\n\n[[1]]\n [1] \"филеб\"         \"семинар\"       \"3\"             \"марта\"        \n [5] \"2022\"          \"сократ\"        \"и\"             \"протарх\"      \n [9] \"решают\"        \"следовать\"     \"за\"            \"логосом\"      \n[13] \"который\"       \"указывает\"     \"что\"           \"невозможно\"   \n[17] \"надежное\"      \"познание\"      \"ненадежных\"    \"вещей\"        \n[21] \"познанию\"      \"же\"            \"надежного\"     \"и\"            \n[25] \"чистого\"       \"уделяются\"     \"прекраснейшие\" \"имена\"        \n[29] \"ум\"            \"и\"             \"разумение\"     \"https\"        \n[33] \"youtu.be\"      \"dwbnvtoi4we\"  \n\n\n\nwords_punct &lt;- tokenize_words(test$text, strip_punct = F)\nwords_punct\n\n[[1]]\n [1] \"филеб\"         \".\"             \"семинар\"       \"3\"            \n [5] \"марта\"         \"2022\"          \".\"             \"сократ\"       \n [9] \"и\"             \"протарх\"       \"решают\"        \"следовать\"    \n[13] \"за\"            \"логосом\"       \",\"             \"который\"      \n[17] \"указывает\"     \",\"             \"что\"           \"невозможно\"   \n[21] \"надежное\"      \"познание\"      \"ненадежных\"    \"вещей\"        \n[25] \".\"             \"познанию\"      \"же\"            \"надежного\"    \n[29] \"и\"             \"чистого\"       \"уделяются\"     \"\\\"\"           \n[33] \"прекраснейшие\" \"\\\"\"            \"имена\"         \":\"            \n[37] \"ум\"            \"и\"             \"разумение\"     \".\"            \n[41] \"https\"         \":\"             \"/\"             \"/\"            \n[45] \"youtu.be\"      \"/\"             \"dwbnvtoi4we\"  \n\n\n\n\n\n\n\n\nЗадание\n\n\n\nВызовите документацию к unnest_tokens() и уточните, можно ли передать ей аргументы функций из пакета tokenizers. Модифицируйте код выше, чтобы узнать, сколько раз встречается запятая в пятой главе “Sense & Sensibility”.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "tokenize.html#скипграмы",
    "href": "tokenize.html#скипграмы",
    "title": "9  Токенизация и лемматизация",
    "section": "9.3 Скипграмы",
    "text": "9.3 Скипграмы\nСкипграмы, или n-грамы с пропусками, применяются в некоторых языковых моделях.\n\nskipgrams &lt;- tokenize_skip_ngrams(test$text, n=3) \nskipgrams[[1]][1:21]\n\n [1] \"филеб\"                \"филеб семинар\"        \"филеб 3\"             \n [4] \"филеб семинар 3\"      \"филеб семинар марта\"  \"филеб 3 марта\"       \n [7] \"филеб 3 2022\"         \"семинар\"              \"семинар 3\"           \n[10] \"семинар марта\"        \"семинар 3 марта\"      \"семинар 3 2022\"      \n[13] \"семинар марта 2022\"   \"семинар марта сократ\" \"3\"                   \n[16] \"3 марта\"              \"3 2022\"               \"3 марта 2022\"        \n[19] \"3 марта сократ\"       \"3 2022 сократ\"        \"3 2022 и\"            \n\n\nФункция считает все энграмы длиной до трех включительно (при этом по умолчанию аргумент k, т.е. величина “пропуска” = 1). Чтобы считать только 3-грамы, надо немного поправить код:\n\nskipgrams &lt;- tokenize_skip_ngrams(test$text, n=3, n_min = 3) \nskipgrams[[1]][1:12]\n\n [1] \"филеб семинар 3\"      \"филеб семинар марта\"  \"филеб 3 марта\"       \n [4] \"филеб 3 2022\"         \"семинар 3 марта\"      \"семинар 3 2022\"      \n [7] \"семинар марта 2022\"   \"семинар марта сократ\" \"3 марта 2022\"        \n[10] \"3 марта сократ\"       \"3 2022 сократ\"        \"3 2022 и\"            \n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПосчитайте скипграмы (n = 3, k = 1) в “Pride & Prejudice”. Сколько уникальных энграм вы получили?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "tokenize.html#лемматизация-и-частеречная-разметка",
    "href": "tokenize.html#лемматизация-и-частеречная-разметка",
    "title": "9  Синтаксический парсинг",
    "section": "9.2 Лемматизация и частеречная разметка",
    "text": "9.2 Лемматизация и частеречная разметка\nЛемматизация – приведение слов к начальной форме (лемме). Как правило, она сопровождается частеречной разметкой слов (POS-tagging). В R это умеет делать, например, пакет udpipe (Universal Dependencies Pipeline). Он позволяет работать со множеством языков (всего 65), для многих из которых представлено несколько моделей, обученных на разных данных.\nПрежде всего нужно выбрать и загрузить модель (список); в нашем случае это модель Perseus, но можно попробовать и другие доступные на сайте https://universaldependencies.org/.\n\nlibrary(udpipe)\n\n#  скачиваем модель в рабочую директорию\nudpipe_download_model(language = \"latin-perseus\")\n\n# загружаем модель\nlatin_perseus &lt;- udpipe_load_model(file = \"latin-perseus-ud-2.5-191206.udpipe\")\n\n# аннотируем\ncaesar_annotate &lt;- udpipe_annotate(latin_perseus, caesar$text)\n\nРезультат возвращается в формате CONLL-U; это широко применяемый формат представления результат морфологического и синтаксического анализа текстов. Вот пример разбора предложения:\n\nCтроки слов содержат следующие поля:\n\nID: индекс слова, целое число, начиная с 1 для каждого нового предложения; может быть диапазоном токенов с несколькими словами.\nFORM: словоформа или знак препинания.\nLEMMA: Лемма или основа словоформы.\nUPOSTAG: универсальный тег части речи.\nXPOSTAG: тег части речи для конкретного языка.\nFEATS: список морфологических характеристик.\nHEAD: заголовок текущего токена, который является либо значением ID, либо нулем (0).\nDEPREL: Universal Stanford dependency relation к (root iff HEAD = 0) или определенному зависящему от языка подтипу.\nDEPS: Список вторичных зависимостей.\nMISC: любая другая аннотация.\n\nДля работы данные удобнее трансформировать в прямоугольный формат.\n\ncaesar_pos &lt;- as_tibble(caesar_annotate) |&gt; \n  select(-paragraph_id)\n\ncaesar_pos",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#морфологическая-разметка",
    "href": "tokenize.html#морфологическая-разметка",
    "title": "9  Токенизация и лемматизация",
    "section": "9.5 Морфологическая разметка",
    "text": "9.5 Морфологическая разметка\nМорфологическая разметка, которую мы получили, дает возможность выбирать и группировать различные части речи. Например, прилагательные.\n\npropn &lt;- antibarbari_ann_tbl |&gt; \n  filter(upos == \"ADJ\") |&gt; \n  select(token, lemma, upos)\n\npropn\n\n\n  \n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nАннотируйте первую главу романа “Гордость и предубеждение” с использованием English EWT. Достаньте все наречия и посчитайте их число. Какое наречие встречается чаще всего?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "tokenize.html#распределение-частей-речи",
    "href": "tokenize.html#распределение-частей-речи",
    "title": "9  Токенизация и лемматизация",
    "section": "9.6 Распределение частей речи",
    "text": "9.6 Распределение частей речи\nКак-то раз Бен Блатт задался целью проверить знаменитый афоризм Стивена Кинга о том, что «дорога в ад вымощена наречиями». Правда ли, что великие писатели реже используют наречия на -ly? Он получил достаточно любопытные результаты, в частности выяснилось, что Генри Мелвилл и Джейн Остин представляют собой скорее исключение из этого правила, но с двумя важными оговорками: во-первых, в 19 в. наречия в целом используют чаще, чем 20-м; а во-вторых, в признанных шедеврах отдельных авторов наречий, действительно, бывает меньше. Например, в романе Стейнбека «Зима тревоги нашей» их меньше всего. Больше всего наречий у авторов фанфиков, непрофессиональных писателей.\nПосчитать части речи (расшифровка тегов UPOS по ссылке) можно так:\n\nantibarbari_pos_counts &lt;- antibarbari_ann_tbl |&gt; \n  group_by(upos) |&gt; \n  count() |&gt; \n  arrange(-n)\n\nantibarbari_pos_counts\n\n\n  \n\n\n\nСтолбиковая диаграмма позволяет наглядно представить такого рода данные:\n\nantibarbari_pos_counts |&gt; \n  ggplot(aes(x = reorder(upos, n), y = n, fill = upos)) +\n  geom_bar(stat = \"identity\", show.legend = F) +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\nЗа буквой X скрываются иностранные языки, но сюда могут попасть и теги, и гиперссылки. Проверим.\n\nantibarbari_ann_tbl |&gt; \n  filter(upos == \"X\") |&gt; \n  select(lemma) |&gt; \n  count(lemma) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\nЗа SYM скрываются эмотиконы и математические символы.\n\nantibarbari_ann_tbl |&gt; \n  filter(upos == \"SYM\") |&gt; \n  select(lemma) |&gt; \n  count(lemma) |&gt; \n  arrange(-n)\n\n\n  \n\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nПостройте такую же диаграмму… вы уже поняли, для какого романа 💔 (или одной главы).\n\n\nМожно отобрать наиболее частотные слова для любой части речи.\n\nnouns &lt;- antibarbari_ann_tbl  |&gt; \n  filter(upos %in% c(\"NOUN\", \"PROPN\")) |&gt; \n  count(lemma) |&gt; \n  arrange(-n) |&gt; \n  filter(lemma != \"NA\") |&gt; \n  filter(nchar(lemma) &gt; 2) |&gt; \n  slice_head(n = 100)\n\nnouns\n\n\n  \n\n\n\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\nlibrary(RColorBrewer)\n\npal &lt;- RColorBrewer::brewer.pal(8, \"Dark2\")\n\nnouns %&gt;%\n  with(wordcloud(lemma, n, max.words = 100, colors = pal))",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "tokenize.html#совместная-встречаемость-слов",
    "href": "tokenize.html#совместная-встречаемость-слов",
    "title": "9  Синтаксический парсинг",
    "section": "9.8 Совместная встречаемость слов",
    "text": "9.8 Совместная встречаемость слов\nФункция cooccurence() из пакета udpipe позволяет выяснить, сколько раз некий термин встречается совместно с другим термином, например:\n\nслова встречаются в одном и том же документе/предложении/параграфе;\nслова следуют за другим словом;\nслова находятся по соседству с другим словом на расстоянии n слов.\n\nКод ниже позволяет выяснить, какие существительные встречаются в одном предложении:\n\ncaesar_subset &lt;-  subset(caesar_pos2, upos == \"NOUN\")\ncooc &lt;- cooccurrence(caesar_subset, term = \"lemma\", group = c(\"doc_id\", \"sentence_id\")) |&gt;   as_tibble() |&gt; \n  filter(cooc &gt; 25)\n\ncooc\n\n\n  \n\n\n\nЭтот результат легко визуализировать, используя пакет ggraph (подробнее о нем мы будем говорить в следующих уроках):\n\nlibrary(igraph)\nlibrary(ggraph)\n\nwordnetwork &lt;- graph_from_data_frame(cooc)\nggraph(wordnetwork, layout = \"fr\") +\n  geom_edge_link(aes(width = cooc), alpha = 0.8, edge_colour = \"grey90\", show.legend=FALSE) +\n  geom_node_label(aes(label = name), col = \"#1f78b4\", size = 4) +\n  theme_void() +\n  labs(title = \"Совместная встречаемость существительных\", subtitle = \"De Bello Gallico 1-7\")\n\n\n\n\n\n\n\n\nЧтобы узнать, какие слова чаще стоят рядом, используем ту же функцию, но с другими аргументами:\n\ncooc2 &lt;- cooccurrence(caesar_subset$lemma, relevant = caesar_subset$upos %in% c(\"NOUN\", \"ADJ\"), skipgram = 1) |&gt; \n  as_tibble() |&gt; \n  filter(cooc &gt; 10)\n\ncooc2\n\n\n  \n\n\n\n\nwordnetwork &lt;- graph_from_data_frame(cooc2)\n\nggraph(wordnetwork, layout = \"fr\") +\n  geom_edge_link(aes(width = cooc), edge_colour = \"grey90\", edge_alpha=0.8, show.legend = F) +\n  geom_node_label(aes(label = name), col = \"#1f78b4\", size = 4) +\n  labs(title = \"Слова, стоящие рядом в тексте\", subtitle = \"De Bello Gallico 1-7\") +\n  theme_void()\n\n\n\n\n\n\n\n\n\n\n\n\nHvitfeldt, Emil, и Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. Taylor; Francis.\n\n\nJockers, Matthew L. 2014. Text Analysis with R for Students of Literature. Springer.\n\n\nSilge, Julia, и David Robinson. 2017. Text Mining with R. O’Reilly. http://www.tidytextmining.com.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#синтаксическая-разметка",
    "href": "tokenize.html#синтаксическая-разметка",
    "title": "9  Токенизация и лемматизация",
    "section": "9.8 Синтаксическая разметка",
    "text": "9.8 Синтаксическая разметка\nДля анализа выберем одно предложение.\n\nantibarbari_sent &lt;- antibarbari_ann_tbl |&gt; \n  filter(doc_id == \"doc367\", sentence_id == 3) |&gt; \n  select(sentence, sentence_id, token_id, head_token_id, dep_rel, token_id, token, upos)\n\nantibarbari_sent  |&gt; \n  select(-sentence)\n\n\n  \n\n\n\nА вот все предложение.\n\nantibarbari_sent |&gt; \n  distinct(sentence) |&gt; \n  pull(sentence)\n\n[1] \"Сегодня мы вспомним о тыкве, ведь греки охотно ее выращивали.\"\n\n\nСвязь между токенами определяется в полях token_id и head_token_id, отношение зависимости определено в dep_rel. Корневой токен имеет значение 0, то есть ни от чего не зависит. Графически изобразить связи поможет пакет textplot.\n\nlibrary(textplot)\ntextplot_dependencyparser(antibarbari_sent)\n\n\n\n\n\n\n\n\nПостроить граф можно и при помощи библиотек igraph и ggraph, но мы сейчас не будем этого делать.\n\n\n\n\nHvitfeldt, Emil, и Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. Taylor; Francis.\n\n\nJockers, Matthew L. 2014. Text Analysis with R for Students of Literature. Springer.\n\n\nSilge, Julia, и David Robinson. 2017. Text Mining with R. O’Reilly. http://www.tidytextmining.com.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "tokenize.html#footnotes",
    "href": "tokenize.html#footnotes",
    "title": "9  Токенизация и лемматизация",
    "section": "",
    "text": "https://smltar.com/tokenization.html#what-is-a-token↩︎\nhttps://universaldependencies.org/treebanks/ru_syntagrus/index.html↩︎\nhttps://cran.r-project.org/web/packages/udpipe/vignettes/udpipe-usecase-postagging-lemmatisation.html↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Токенизация и лемматизация</span>"
    ]
  },
  {
    "objectID": "scrape.html#selector-gadget",
    "href": "scrape.html#selector-gadget",
    "title": "8  Веб-скрапинг",
    "section": "8.8 Selector Gadget",
    "text": "8.8 Selector Gadget\nМногие тексты доступны на сайте &lt;wikisource.org&gt;. Попробуем извлечь латинский текст “Записок о Галльской войне” Цезаря: он пригодится нам в следующем уроке.\n\nurl &lt;- \"https://la.wikisource.org/wiki/Commentarii_de_bello_Gallico\"\nhtml = read_html(url)\n\nДля того, чтобы справиться с такой страницей, пригодится Selector Gadget (расширение для Chrome). Вот тут можно посмотреть короткое видео, как его установить. При помощи селектора выбираем нужные уровни.\n\ntoc &lt;- html |&gt; \n  html_elements(\"td , #toc a\")\n\ntoc\n\n{xml_nodeset (11)}\n [1] &lt;td class=\"fr-text\" style=\"vertical-align: middle;\"&gt;Accuracy&lt;/td&gt;\\n\n [2] &lt;td class=\"fr-value40\" style=\"vertical-align: middle;\"&gt;Spot checked&lt;/td&gt;\n [3] &lt;td align=\"center\" style=\"background: #efefef\"&gt;\\n&lt;a href=\"/wiki/Commenta ...\n [4] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_I\" title=\"Commentarii  ...\n [5] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_II\" title=\"Commentarii ...\n [6] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_III\" title=\"Commentari ...\n [7] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_IV\" title=\"Commentarii ...\n [8] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_V\" title=\"Commentarii  ...\n [9] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_VI\" title=\"Commentarii ...\n[10] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_VII\" title=\"Commentari ...\n[11] &lt;a href=\"/wiki/Commentarii_de_bello_Gallico/Liber_VIII\" title=\"Commentar ...\n\n\nИзвлекаем путь и имя файла для web-страниц.\n\nlibri &lt;- tibble(\n  title = toc |&gt;\n    html_attr(\"title\"),\n  href = toc |&gt; \n    html_attr(\"href\")\n) |&gt; \n  filter(!is.na(title))\n\nlibri\n\n\n  \n\n\n\nТеперь добавляем протокол доступа и доменное имя для каждой страницы.\n\nlibri &lt;- libri |&gt; \n  mutate(link = paste0(\"https://la.wikisource.org\", href)) |&gt; \n  select(-href)\n\nlibri\n\n\n  \n\n\n\nДальше необходимо достать текст для каждой книги. Потренируемся на одной. Снова привлекаем Selector Gadget для составления правила.\n\nurls &lt;- libri |&gt; \n  pull(link)\n\ntext &lt;- read_html(urls[1]) |&gt; \n  html_elements(\".mw-heading3+ p\") |&gt; \n  html_text2() \n\ntext[1]\n\n[1] \"Gallia est omnis divisa in partes tres, quarum unam incolunt Belgae, aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur. Hi omnes lingua, institutis, legibus inter se differunt. Gallos ab Aquitanis Garumna flumen, a Belgis Matrona et Sequana dividit. Horum omnium fortissimi sunt Belgae, propterea quod a cultu atque humanitate provinciae longissime absunt, minimeque ad eos mercatores saepe commeant atque ea quae ad effeminandos animos pertinent important, proximique sunt Germanis, qui trans Rhenum incolunt, quibuscum continenter bellum gerunt. Qua de causa Helvetii quoque reliquos Gallos virtute praecedunt, quod fere cotidianis proeliis cum Germanis contendunt, cum aut suis finibus eos prohibent aut ipsi in eorum finibus bellum gerunt. Eorum una pars, quam Gallos obtinere dictum est, initium capit a flumine Rhodano, continetur Garumna flumine, Oceano, finibus Belgarum, attingit etiam ab Sequanis et Helvetiis flumen Rhenum, vergit ad septentriones. Belgae ab extremis Galliae finibus oriuntur, pertinent ad inferiorem partem fluminis Rheni, spectant in septentrionem et orientem solem. Aquitania a Garumna flumine ad Pyrenaeos montes et eam partem Oceani quae est ad Hispaniam pertinet; spectat inter occasum solis et septentriones.\"\n\n\nУбедившись, что параграфы извлечены верно, обобщаем: пишем функцию для извлечения текстов и применяем ее ко всем книгам.\n\nget_text &lt;- function(url) {\n  read_html(url) |&gt; \n  html_elements(\".mw-heading3+ p\") |&gt; \n  html_text2() |&gt; \n  paste(collapse= \" \")\n}\n\nЭто займет некоторое время.\n\nlibri_text &lt;- map(urls, get_text)\n\nСоединим две таблицы.\n\nlibri_text &lt;- libri_text |&gt;\n  flatten_chr() |&gt; \n  as_tibble()\n\ncaesar &lt;- libri |&gt; \n  bind_cols(libri_text) |&gt; \n  mutate(title = str_remove(title, \"Commentarii de bello Gallico/\"))\n\ncaesar\n\n\n  \n\n\n\nСохраним подготовленный датасет для дальнейшего анализа.\n\nsave(caesar, file = \"../data/caesar.Rdata\")\n\n\nПоздравляем, на этом закончился первый большой раздел нашего курса “Основы работы в R” 🎑. За восемь уроков вы познакомились с основными структурами данных в R, научились собирать и трансформировать данные, строить графики, писать функции и циклы, а также готовить html-отчеты о своих исследованиях. Впереди нас ждут методы анализа текстовых данных.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Веб-скрапинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#токенизация",
    "href": "tokenize.html#токенизация",
    "title": "9  Синтаксический парсинг",
    "section": "",
    "text": "unnest_tokens(\n  tbl,\n  output,\n  input,\n  token = \"words\",\n  format = c(\"text\", \"man\", \"latex\", \"html\", \"xml\"),\n  to_lower = TRUE,\n  drop = TRUE,\n  collapse = NULL,\n  ...\n)\n\n\n“words” (default),\n“characters”,\n“character_shingles”,\n“ngrams”,\n“skip_ngrams”,\n“sentences”,\n“lines”,\n“paragraphs”,\n“regex”,\n“ptb” (Penn Treebank).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#обучение-модели",
    "href": "tokenize.html#обучение-модели",
    "title": "9  Синтаксический парсинг",
    "section": "9.3 Обучение модели",
    "text": "9.3 Обучение модели\nМожно заметить, что модель Perseus 2.5 справилась не безупречно: все бельги оказались женского рода, а кельты и вовсе признаны глаголом. Есть ошибки в падежах и числах: например, “provinciae” в четвертом предложении, конечно, не именительный, а родительный падеж. Множество топонимов не опознано в качестве имен собственных.\nЗдесь есть два пути. Первый: пробовать другие модели, доступные в пакете udpipe. Например, для латыни это PROIEl, обученная не только на классических авторах, но и на Вульгате, или ITTB, обученная на сочинениях Фомы.\nВторой путь - обучить модель самостоятельно. Например, для трибанка Perseus доступны более свежие версии (2.13 на момент написания этой главы) на GitHub. Вот некоторые изменения:\n\nпоявилась метка dep_rel для ablativus absolutus (advcl:abs);\nисправлены аннотации для супина (VerbForm=Conv, Aspect=Prosp), а также герундия и герундива (VerbForm=Part, Aspect=Prosp);\nдобавлен тип для местоимения (PronType) и вид для глагола (Aspect) и др.\n\nИнструкцию по обучению модели можно найти здесь. По сути трибанк представляет собой коллекцию проверенных вручную CONLL-U файлов, которые передаются нейросети. Следуя этой инструкции и используя трибанк Perseus 2.13, мы обучили новую модель (это заняло около 8 часов на персональном компьютере), которую можно загрузить и использовать для аннотации.\nНадо иметь в виду, что само по себе обновление трибанка еще не гарантирует того, что модель будет лучше справляться с парсингом: многое зависит от параметров обучения. В нашем случае, впрочем, некоторые улучшения есть: например, “provinciae” корректно опознано как родительный падеж. Но есть и потери: “fortissimi” в том же предложении выше - это nominativus pluralis, который ошибочно опознан как генитив единственного числа.\n\nlatin_perseus_new &lt;- udpipe_load_model(\"../latin_model/la_perseus-2.13-20231115.udpipe\")\n\ncaesar_annotate2 &lt;- udpipe_annotate(latin_perseus_new, caesar$text[1])\n\ncaesar_pos2 &lt;- as_tibble(caesar_annotate2) |&gt; \n  select(-paragraph_id)\n\n\ncaesar_pos2\n\n\n  \n\n\n\nПока для наших задач достигнутой точности хватит, но можно попробовать построить нейросеть с более сложной архитектурой. Например, в 2024 г. такая архитектура была предложена и для латинского языка.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#поле-upos",
    "href": "tokenize.html#поле-upos",
    "title": "9  Синтаксический парсинг",
    "section": "9.4 Поле UPOS",
    "text": "9.4 Поле UPOS\nМорфологическая аннотация, которую мы получили, дает возможность выбирать и группировать различные части речи. Например, местоимения.\n\ncaesar_pos2 |&gt; \n  filter(upos == \"PRON\") |&gt; \n  select(token, lemma, upos, xpos)\n\n\n  \n\n\n\nПосчитать части речи можно так:\n\nupos_counts &lt;- caesar_pos2 |&gt; \n  group_by(upos) |&gt; \n  count() |&gt; \n  arrange(-n)\n\nupos_counts\n\n\n  \n\n\n\nСтолбиковая диаграмма позволяет наглядно представить результаты подсчетов:\n\nupos_counts |&gt; \n  ggplot(aes(x = reorder(upos, n), y = n, fill = upos)) +\n  geom_bar(stat = \"identity\", show.legend = F) +\n  coord_flip() +\n  labs(x = NULL) +\n  theme_bw() \n\n\n\n\n\n\n\n\nОтберем наиболее частотные имена и имена собственные.\n\nnouns &lt;- caesar_pos2  |&gt; \n  filter(upos %in% c(\"NOUN\", \"PROPN\")) |&gt; \n  count(lemma) |&gt; \n  arrange(-n) \n\nnouns\n\n\n  \n\n\n\n\nlibrary(wordcloud)\n\nLoading required package: RColorBrewer\n\nlibrary(RColorBrewer)\n\npal &lt;- RColorBrewer::brewer.pal(8, \"Dark2\")\n\nwordcloud(nouns$lemma, nouns$n, colors = pal, max.words = 130)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#поле-feats",
    "href": "tokenize.html#поле-feats",
    "title": "9  Синтаксический парсинг",
    "section": "9.5 Поле FEATS",
    "text": "9.5 Поле FEATS\nДопустим, нам нужны не все местоимения, а лишь определенные их формы: например, относительные.\n\nrel_pron &lt;- caesar_pos2  |&gt; \n  filter(str_detect(feats, \"PronType=Rel\")) \n\nrel_pron\n\n\n  \n\n\n\nПосмотрим на некоторые местоимения в контексте. Для этого добавим html-теги:\nhighlight_string &lt;- function(idx) str_replace_all(\n  rel_pron$sentence[idx], \n  str_glue(\"(?&lt;= ){rel_pron$token[idx]}(?=\\\\W)\"),\n  str_glue(\"&lt;mark&gt;{rel_pron$token[idx]}&lt;/mark&gt;\"))\n\nhighlight_string(1)\n[1] “Gallia est omnis divisa in partes tres, quarum unam incolunt Belgae, aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur.”\nhighlight_string(13)\n[1] “In eo itinere persuadet Castico, Catamantaloedis filio, Sequano, cuius pater regnum in Sequanis multos annos obtinuerat et a senatu populi Romani amicus appellatus erat, ut regnum in civitate sua occuparet, quod pater ante habuerit;”",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#поле-xpos",
    "href": "tokenize.html#поле-xpos",
    "title": "9  Синтаксический парсинг",
    "section": "9.6 Поле XPOS",
    "text": "9.6 Поле XPOS\nЧтение xpos требует сноровки: например причастие sublata там описывается так: v-srppfb-, где\n\nv = verbum;\n- на месте лица;\ns = singularis;\nr = perfectum (не p, потому что p = praesens);\np = participium;\np = passivum;\nf = femininum;\nb = ablativus (не a, потому что a = accusativus).\n\nСравним с описанием личной формы глагола differunt v3ppia---:\n\nv = verbum;\n3 = 3. persona;\np = pluralis;\np = praesens;\ni = indicativus;\na = activum;\n-- на месте рода и падежа, т.к. форма неличная.\n\nПоследнее “место” (Degree) у глаголов всегда свободно; в первой книге там стоит s (superlativus) лишь у florentissimis, что явно ошибка, потому что это не глагол.\n\n\n\n\n\n\nНа заметку\n\n\n\nСпецификацию всех xpos-тегов для латинского языка можно найти по ссылке.\n\n\nДля удобства разобьем xpos на 9 столбцов.\n\ncaesar_pos2_sep &lt;- caesar_pos2 |&gt; \n  separate(xpos, into = c(\"POS\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"persona\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"numerus\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"tempus\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"modus\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"vox\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"genus\", \"xpos\"), sep = 1) |&gt; \n  separate(xpos, into = c(\"casus\", \"gradus\"), sep = 1)\n\ncaesar_pos2_sep\n\n\n  \n\n\n\nЭти столбцы тоже можно использовать для поиска конкретных признаков. Посмотрим, например, в каком числе и падеже чаще всего стоит относительное местоимения.\n\npron_rel_sum &lt;- caesar_pos2_sep  |&gt; \n  filter(upos == \"PRON\") |&gt; \n  filter(str_detect(feats, \"PronType=Rel\")) |&gt; \n  group_by(numerus, casus) |&gt; \n  summarise(n = n()) |&gt; \n  arrange(-n)\n\npron_rel_sum\n\n\n  \n\n\n\nДля удобства преобразуем сокращения.\n\npron_rel_sum &lt;- pron_rel_sum |&gt; \n  filter(casus != \"-\") |&gt; \n  mutate(casus = case_when(casus == \"n\" ~ \"nom\",\n                           casus == \"g\" ~ \"gen\",\n                           casus == \"d\" ~ \"dat\",\n                           casus == \"a\" ~ \"acc\",\n                           casus == \"b\" ~ \"abl\")) |&gt; \n  mutate(numerus = case_when(numerus == \"s\" ~ \"sing\",\n                              numerus == \"p\" ~ \"plur\"))\n\npron_rel_sum\n\n\n  \n\n\n\nФункция facet_wrap позволяет разбить график на две части на основании значения переменной numerus.\n\npron_rel_sum |&gt; \n  ggplot(aes(casus, n, fill = casus)) +\n  geom_bar(stat = \"identity\", show.legend = FALSE) +\n  coord_flip() +\n  theme_light() +\n  facet_wrap(~numerus) +\n  labs(x = NULL, y = NULL, title = \"Относительные местоимения в BG 1-7\")",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "tokenize.html#поле-dep_rel",
    "href": "tokenize.html#поле-dep_rel",
    "title": "9  Синтаксический парсинг",
    "section": "9.7 Поле DEP_REl",
    "text": "9.7 Поле DEP_REl\nАналогичным образом можно отбирать синтаксические признаки и их комбинации, а также визуализировать деревья зависимостей для отдельных предложений.\nДерево зависимостей – это направленный граф, который имеет единственную корневую вершину (сказуемое главного предложения) без входящих дуг (рёбер), при этом все остальные вершины имеют ровно одну входящую дугу. Иными словами, каждое слово зависит от другого, но только от одного. Это выглядит примерно так:\n\nlibrary(textplot)\n\nsent &lt;- caesar_pos |&gt; \n  filter(doc_id == \"doc1\", sentence_id == 10) \n\nsent |&gt; \n  distinct(sentence) |&gt; \n  pull(sentence) \n\n[1] \"Apud Helvetios longe nobilissimus fuit et ditissimus Orgetorix.\"\n\ntextplot_dependencyparser(sent, size = 3)\n\n\n\n\n\n\n\n\nМожно поспорить с тем, что nobilissiumus и ditissimus - это глаголы, хотя модель Perseus 2.5 верно опознала их в качестве именной части сказуемого при подлежащем “Оргеториг”. Информация, которая на графе представлена стрелками, хранится в таблице в полях token_id и head_token_id и dep_rel. Корневой токен всегда имеет значение 0, то есть ни от чего не зависит.\n\nsent |&gt; \n  select(token_id, token, head_token_id, dep_rel)\n\n\n  \n\n\n\n\nПравила синтаксической разметки для латинского языка доступны по ссылке, а расшифровку сокращений (для всех языков) надо смотреть здесь.\n\nВообще латынь (как и древнегреческий ) – не очень ресурсный язык; для многих языков доступны хорошие предобученные модели.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Синтаксический парсинг</span>"
    ]
  },
  {
    "objectID": "count.html",
    "href": "count.html",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "",
    "text": "10.1 Подготовка данных\nЗа основу для всех эти вычислений мы возьмем три философских трактата, написанных на английском языке. Это хронологически и тематически близкие тексты:\nИсточники для этого урока доступны в библиотеке Gutengerg; чтобы их извлечь, следует выяснить gutenberg_id. Пример ниже; таким же образом можно найти id для трактатов Локка и Беркли.\n# install.packages(\"gutenbergr\")\nlibrary(gutenbergr)\nlibrary(tidyverse)\nlibrary(stringr)\n\ngutenberg_works(str_detect(author, \"Hume\"), languages = \"en\")\nКогда id найдены, gutenbergr позволяет загрузить сочинения; на этом этапе часто возникают ошибки – в таком случае надо воспользоваться одним из зеркал. Список зеркал доступен по ссылке: https://www.gutenberg.org/MIRRORS.ALL.\nmy_corpus &lt;- gutenberg_download(meta_fields = c(\"author\", \"title\"), c(9662, 4723, 10615), mirror = \"https://www.gutenberg.org/dirs/\")\n\nmy_corpus\nВ этом тиббле хранятся все три текста, которые нам нужны. Уточнить уникальные называния можно при помощи функции distinct() из tidyverse.\nmy_corpus |&gt; \n  distinct(author)\nПрежде чем приступать к анализу, придется немного прибраться. Для этого используем инструменты tidyverse, о которых шла речь в главе про опрятные данные.\nmy_corpus &lt;- my_corpus |&gt; \n  select(-gutenberg_id) |&gt; \n  select(-title) |&gt; \n  relocate(text, .after = author) |&gt; \n  mutate(author = str_remove(author, \",.+$\")) |&gt; \n  filter(text != \"\")\n\nmy_corpus\nВ случае с Юмом отрезаем предисловия, оглавление и индексы, а также номера разделов (везде прописными). Многие слова, которые в оригинале были выделены курсивом, окружены знаками подчеркивания (_), их тоже удаляем.\nHume &lt;- my_corpus |&gt; \n  filter(author == \"Hume\")|&gt; \n  filter(!row_number() %in% c(1:25),\n         !row_number() %in% c(4814:nrow(my_corpus))) |&gt; \n  mutate(text = str_replace_all(text, \"[[:digit:]]\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"_\", \" \")) |&gt; \n  filter(!str_detect(text, \"SECTION .{1,4}\"))\nВ случае с Беркли отрезаем метаданные и посвящение в самом начале, а также удаляем нумерацию параграфов. Кроме того, текст содержит примечания следующего вида: [Note: Vide Hobbes’ Tripos, ch. v. sect. 6.]1, от них тоже следует избавиться.\nBerkeley &lt;- my_corpus |&gt; \n  filter(author == \"Berkeley\") |&gt; \n  filter(!row_number() %in% c(1:38)) |&gt; \n  mutate(text = str_replace_all(text, \"[[:digit:]]+?\\\\.\", \" \"))  |&gt; \n  mutate(text = str_replace_all(text, \"\\\\[.+?\\\\]\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"[[:digit:]]+\", \" \"))\nЧто касается Локка, то здесь удаляем метаданные и оглавление в самом начале, а также посвящение и подчеркивания вокруг слов. “Письмо к читателю” уже содержит некоторые философские положения, и его можно оставить.\nLocke &lt;- my_corpus  |&gt;  \n  filter(author == \"Locke\") |&gt; \n  filter(!row_number() %in% c(1:135)) |&gt; \n  mutate(text = str_replace_all(text, \"_\", \" \")) |&gt; \n  mutate(text = str_replace_all(text, \"[[:digit:]]\", \" \"))\nСоединив обратно все три текста, замечаем некоторые орфографические нерегулярности; исправляем.\ncorpus_clean &lt;- bind_rows(Hume, Berkeley, Locke) |&gt; \n  mutate(text = str_replace_all(text, c(\"[Mm]an’s\" = \"man's\", \"[mM]en’s\" = \"men's\", \"[hH]ath\" = \"has\")))\n\ncorpus_clean\nПосле этого делим корпус на слова.\nlibrary(tidytext)\n\ncorpus_words &lt;- corpus_clean |&gt; \n  unnest_tokens(word, text)\n\ncorpus_words\nПодготовленный таким образом корпус можно скачать по ссылке.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#подготовка-данных",
    "href": "count.html#подготовка-данных",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "",
    "text": "“Опыт о человеческом разумении” Джона Локка (1690), первые две книги;\n“Трактат о принципах человеческого знания” Джорджа Беркли (1710);\n“Исследование о человеческом разумении” Дэвида Юма (1748).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#cтоп-слова",
    "href": "count.html#cтоп-слова",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.2 Cтоп-слова",
    "text": "10.2 Cтоп-слова\nБольшая часть слов, которые мы сейчас видим в корпусе, нам пока не интересна – это шумовые слова, или стоп-слова, не несущие смысловой нагрузки. Функция anti_join() позволяет от них избавиться; в случае с английским языком список стоп-слов уже доступен в пакете tidytext; в других случаях их следует загружать отдельно. Для многих языков стоп-слова доступны в пакете stopwords.\nФункция anti_join() работает так:\n\n\nother &lt;- c(\"section\", \"chapter\", 0:40, \"edit\", 1710, \"v.g\", \"v.g.a\")\n\ncorpus_words_tidy &lt;- corpus_words  |&gt;  \n  anti_join(stop_words) |&gt; \n  filter(!word %in% other)\n\ncorpus_words_tidy\n\n\n  \n\n\n\nУборка закончена, мы готовы к подсчетам.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#абсолютная-частотность",
    "href": "count.html#абсолютная-частотность",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.3 Абсолютная частотность",
    "text": "10.3 Абсолютная частотность\nДля начала посмотрим на самые частотные слова во всем корпусе.\n\nlibrary(ggplot2)\n\ncorpus_words_tidy |&gt; \n  count(word, sort = TRUE)  |&gt; \n  slice_head(n = 15) |&gt; \n  ggplot(aes(reorder(word, n), n, fill = word)) +\n  geom_col(show.legend = F) + \n  coord_flip() \n\n\n\n\n\n\n\n\nЭтот график уже дает общее представление о тематике нашего корпуса: это теория познания, в центре которой для всех трех авторов стоит понятие “idea”.\nОднако можно заподозрить, что высокие показатели для слов “simple”, “distinct” и “powers” – это заслуга прежде всего Локка, который вводит понятия “простой идеи” и “отчетливой идеи”, а также говорит о “силах” вещей, благодаря которым они воздействуют как друг на друга, так и на разум. Силы для Локка – это причины идей, и как таковые они часто упоминаются в его тексте. Понятие врожденности (“innate”) также занимает в первую очередь его: вся первая книга “Опыта” – это опровержение теории врожденных идей. Беркли о врожденности не говорит вообще, а Юм – очень кратко.\nКроме того, хотя мы взяли только две книги из “Опыта” Локка – это самый длинный текст в нашем корпусе, что создает значительный перекос:\n\ncorpus_words_tidy |&gt; \n  group_by(author) |&gt; \n  summarise(sum = n())\n\n\n  \n\n\n\nПосмотрим статистику по отдельным авторам.\n\ncorpus_words_tidy  |&gt; \n  group_by(author) |&gt; \n  count(word, sort = TRUE)  |&gt; \n  slice_head(n = 15) |&gt; \n  ggplot(aes(reorder_within(word, n, author), n, fill = word)) +\n  geom_col(show.legend = F) + \n  facet_wrap(~author, scales = \"free\") +\n  scale_x_reordered() +\n  coord_flip() +\n  labs(x = NULL, y = NULL)\n\n\n\n\n\n\n\n\nНаиболее частотные слова (при условии удаления стоп-слов) дают вполне адекватное представление о тематике каждого из трех трактатов.\nСогласно Локку, объектом мышления является идея (желательно отчетливая, но тут уж как получится). Все идеи приобретены умом из опыта, направленного на либо на внешние предметы (ощущения, или чувства), либо на внутренние действия разума (рефлексия, или внутреннее чувство). Никаких врожденных идей у человека нет, изначально его душа похожа на чистый лист (антинативизм). Идеи могут быть простыми и сложными; они делятся на модусы, субстанции и отношения. К числу простых модусов относятся пространство, в котором находятся тела, а также продолжительность; измеренная продолжительность представляет собой время.\nБеркли спорит с мнением, согласно котором ум способен образовывать абстрактные идеи. В том числе, утверждает он, невозможна абстрактная идея движения, отличная от движущегося тела. Он пытается устранить заблуждение Локка, согласно которому слова являются знаками абстрактных общих идей. В мыслящей душе (которую он также называет умом и духом) существуют не абстрактные идеи, а ощущения, и существование немыслящих вещей безотносительно к их воспринимаемости совершенно невозможно. Нет иной субстанции, кроме духа; немыслящие вещи ее совершенно лишены. По этой причине нельзя допустить, что существует невоспринимающая протяженная субстанция, то есть материя. Идеи ощущений возникают в нас согласно с некоторыми правилами, которые мы называем законами природы. Действительные вещи – это комбинации ощущений, запечатлеваемые в нас могущественным духом.\nСогласно Юму, все объекты, доступные человеческому разуму, могут быть разделены на два вида, а именно: на отношения между идеями и факты. К суждениям об отношениях можно прийти благодаря одной только мыслительной деятельности, в то время как все заключения о фактах основаны на отношениях причины и действия. В свою очередь знание о причинности возникает всецело из опыта: только привычка заставляет нас ожидать наступления одного события при наступлении другого. Прояснение этого позволяет добиться большей ясности и точности в философии.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#стемминг",
    "href": "count.html#стемминг",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.4 Стемминг",
    "text": "10.4 Стемминг\nПоскольку мы не лемматизировали текст, то единственное и множественное число слова idea рассматриваются как разные токены. Один из способов справиться с этим - стемминг.\nСтемминг (англ. stemming “поиск происхождения”) — это процесс нахождения основы слова для заданного исходного слова. Основа слова не обязательно совпадает с морфологическим корнем слова. Стемминг применяется в поисковых системах для расширения поискового запроса пользователя, является частью процесса нормализации текста. Один из наиболее популярных алгоритмов стемминга был написан Мартином Портером и опубликован в 1980 году.\nВ R стеммер Портера доступен в пакете snowball. К сожалению, он поддерживает не все языки, но русский, французский, немецкий и др. там есть. Не для всех языков, впрочем, и не для всех задач стемминг – это хорошая идея. Но попробуем применить его к нашему корпусу.\n\nlibrary(SnowballC)\n\ncorpus_stems &lt;- corpus_words_tidy |&gt; \n  mutate(stem = wordStem(word)) \n\ncorpus_stems |&gt; \n  count(stem, sort = TRUE)  |&gt; \n  slice_head(n = 15) |&gt; \n  ggplot(aes(reorder(stem, n), n, fill = stem)) +\n  geom_col(show.legend = F) + \n  coord_flip() \n\n\n\n\n\n\n\n\nВсе слова немного покромсаны, но вполне узнаваемы. При этом общее количество уникальных токенов стало значительно меньше:\n\n# до стемминга\nn_distinct(corpus_words_tidy$word)\n\n[1] 8132\n\n# после стемминга\nn_distinct(corpus_stems$stem)\n\n[1] 5229\n\n\nСтемминг применяется в некоторых алгоритмах машинного обучения, но сегодня - все реже, потому что современные компьютеры прекрасно справляются с лемматизацией.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#относительная-частотность",
    "href": "count.html#относительная-частотность",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.5 Относительная частотность",
    "text": "10.5 Относительная частотность\nАбсолютная частотность – плохой показатель для текстов разной длины. Чтобы тексты было проще сравнивать, разделим показатели частотности на общее число токенов в тексте.\nCначала считаем частотность для всех токенов по авторам.\n\nauthor_word_counts &lt;- corpus_words  |&gt; \n  count(author, word, sort = T) |&gt; \n  filter(!word %in% other) |&gt; \n  ungroup()\n\nauthor_word_counts\n\n\n  \n\n\n\nЗатем - число токенов в каждой книге.\n\ntotal_counts &lt;- author_word_counts |&gt; \n  group_by(author) |&gt; \n  summarise(total = sum(n))\n\ntotal_counts\n\n\n  \n\n\n\nСоединяем два тиббла:\n\nauthor_word_counts &lt;- author_word_counts |&gt; \n  left_join(total_counts)\n\nauthor_word_counts\n\n\n  \n\n\n\nСчитаем относительную частотность:\n\nauthor_word_tf &lt;- author_word_counts |&gt; \n  mutate(tf = round((n / total), 5))\n\nauthor_word_tf\n\n\n  \n\n\n\nНаиболее частотные слова – это служебные части речи. На графике видно, что подавляющее большинство слов встречается очень редко, а слов с высокой частотностью - мало.\n\nauthor_word_tf |&gt; \n  ggplot(aes(tf, fill = author)) +\n  geom_histogram(show.legend = FALSE) +\n  facet_wrap(~author, scales = \"free_y\")",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#закон-ципфа",
    "href": "count.html#закон-ципфа",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.6 Закон Ципфа",
    "text": "10.6 Закон Ципфа\nПодобная картина характерна для естественных языков. Распределения слов в них подчиняются закону Ципфа. Этот закон носит имя американского лингвиста Джорджа Ципфа (George Zipf) и утверждает следующее: если все слова языка или длинного текста упорядочить по убыванию частоты использования, частота (tf) n-го слова в списке окажется обратно пропорциональной его рангу (r) в степени α. Это значит (в самом общем случае), что если ранг увеличится в n раз, то частотность во столько же раз должна упасть: второе слово в корпусе встречается примерно в два раза реже, чем первое (Savoy 2020, 24).\n\\[tf_{r_i} = \\frac{c}{r^α_i}\\]\nЗдесь c - это константа, которая оценивается для каждого случая отдельно, как и параметр α. Иначе говоря:\n\\[ tf_{r_i} \\times r^α_i = c \\] Посмотрим на ранги и частотность первых 50 слов.\n\nauthor_word_tf_rank &lt;- author_word_tf |&gt; \n  group_by(author) |&gt; \n  mutate(rank = row_number()) \n\nauthor_word_tf_rank |&gt; \n  ggplot(aes(rank, tf, color = author)) +\n  geom_line(size = 1.1, alpha = 0.7) +\n  coord_cartesian(xlim = c(NA, 50)) +\n  scale_x_continuous(breaks = seq(0,50,5))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nВспомнив, что логарифм дроби равен разности логарифмов числителя и знаменателя, запишем:\n\\[log(tf_{r_i}) = c - α \\times log(r_i) \\] Таким образом, мы получаем близкую к линейность зависимость, где константа c определяет точку пересечения оси y, a коэффициентα - угол наклона прямой. Графически это выглядит так:\n\nauthor_word_tf_rank |&gt; \n  ggplot(aes(rank, tf, color = author)) +\n  geom_line(size = 1.1, alpha = 0.7) +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\n\n\nЧтобы узнать точные коэффициенты, придется подогнать линейную модель (об этом поговорим подробнее в следующих уроках):\n\nlm_zipf &lt;- lm(data = author_word_tf_rank, \n              formula = log10(tf) ~ log10(rank))\n\ncoefficients(lm_zipf)\n\n(Intercept) log10(rank) \n -0.2501025  -1.2728170 \n\n\nМы получили коэффициент наклона α чуть больше -1 (на практике точно -1 встречается редко). Добавим линию регрессии на график:\n\nauthor_word_tf_rank |&gt; \n  ggplot(aes(rank, tf, color = author)) +\n  geom_line(size = 1.1, alpha = 0.7) +\n  geom_abline(intercept = coefficients(lm_zipf)[1],\n              slope = coefficients(lm_zipf)[2], \n              linetype = 2, \n              color = \"grey50\") +\n  scale_x_log10() +\n  scale_y_log10()\n\n\n\n\n\n\n\n\nЗдесь видно, что отклонения наиболее заметны в “хвостах” графика. Это характерно для многих корпусов: как очень редких, так и самых частотных слов не так много, как предсказывает закон Ципфа. Кроме того, внизу кривая почти всегда приобретает ступенчатый вид, потому что слова встречаются в корпусе дискретное число раз: ранг у них разный, а частотности одинаковые.\n\n\n\n\n\n\nВопрос\n\n\n\nДальше всего вправо уходит кривая Локка. Почему?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#меры-лексического-разнообразия",
    "href": "count.html#меры-лексического-разнообразия",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.7 Меры лексического разнообразия",
    "text": "10.7 Меры лексического разнообразия\nКоэффициент наклона α для кривой Ципфа колеблется в достаточно узком диапазоне между 0.7 и 2 и, как полагают, может быть связан с “когнитивным усилием” говорящего: например, для устной речи α чуть больше, для письменной - ниже. Однако рассматривать этот наклон как индивидуальную характеристику стиля не стоит: как и другие меры лексического разнообразия, он сильно коррелирует с длиной текста.\nДело в том, что редкие слова (события) встречаются очень часто; это явление известно под названием Large Number of Rare Events (LNRE). И чем длиннее текст, тем больше в нем будет редких слов, но скорость их прибавления постепенно уменьшается: чем дальше, тем сложнее встретить слово, которого еще не было.\nЧтобы в этом убедиться, взглянем на наиболее известную мера лексического разнообразия под названием type-token ratio (TTR).\n\\[ TTR(T) = \\frac{Voc(T)}{n} \\] Здесь n - общее число токенов, а Voc (т.е. словарь) - число уникальных токенов (типов).\nВ пакете languageR, написанном лингвистом Гаральдом Баайеном, есть функция, позволяющая быстро производить такие вычисления. Она требует на входе вектор, а не тиббл, поэтому для эксперимента извлечем один из текстов.\n\nlocke_words &lt;- corpus_words %&gt;% \n  filter(author == \"Locke\") %&gt;% \n  pull(word)\n\nlength(locke_words)\n\n[1] 148171\n\n\nФункция считает различные меры лексического разнообразия, из которых нас сейчас будет интересовать наклон Ципфа и TTR.\n\nlibrary(languageR)\nlocke.growth = growth.fnc(text = locke_words, size = 1000, nchunks = 40)\n\n........................................\n\ngrowth_df &lt;- locke.growth@data$data \ngrowth_df\n\n\n  \n\n\n\nБыстро визуализировать результат можно при помощи plot(locke.growth), но мы воспользуемся ggplot2.\n\nlibrary(gridExtra)\n\np1 &lt;- growth_df |&gt; \n  ggplot(aes(Tokens, Types)) + \n  geom_point(color = \"steelblue\")\n\np2 &lt;- growth_df |&gt; \n  ggplot(aes(Tokens, Zipf)) + \n  geom_point(color = \"#B44682\") +\n  ylab(\"Zipf Slope\")\n\np3 &lt;- growth_df |&gt; \n  ggplot(aes(Tokens, TypeTokenRatio)) + \n  geom_point(color = \"#81B446\")\n\np4 &lt;- growth_df |&gt; \n  ggplot(aes(Tokens, HapaxLegomena / Tokens)) + \n  geom_point(color = \"#B47846\") +\n  ylab(\"Growth Rate\")\n\ngrid.arrange(p1, p2, p3, p4, nrow=2)\n\n\n\n\n\n\n\n\nПодробнее о различных мерах лексического разнообразия см.: (Baayen 2008, 222–36) и (Savoy 2020).",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#tf-idf",
    "href": "count.html#tf-idf",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.8 TF-IDF",
    "text": "10.8 TF-IDF\nНаиболее частотные слова (с низким рангом) наименее подвержены влиянию тематики, поэтому их используют для стилометрического анализа. Если отобрать наиболее частотные после удаления стоп-слов, то мы получим достаточно адекватное отражение тематики документов. Если же мы необходимо найти наиболее характерные для документов токены, то применяется другая мера, которая называется tf-idf (term frequency - inverse document frequency).\n\nЛогарифм единицы равен нулю, поэтому если слово встречается во всех документах, его tf-idf равно нулю. Чем выше tf-idf, тем более характерно некое слово для документа. При этом относительная частотность тоже учитывается! Например, Беркли один раз упоминает “сахарные бобы”, а Локк – “миндаль”, но из-за редкой частотности tf-idf для подобных слов будет низкой.\nФункция bind_tf_idf() принимает на входе тиббл с абсолютной частотностью для каждого слова.\n\nauthor_word_tfidf &lt;- author_word_tf |&gt; \n  bind_tf_idf(word, author, n)\n\nauthor_word_tfidf\n\n\n  \n\n\n\nВыбираем слова с высокой tf-idf:\n\nauthor_word_tfidf |&gt; \n  select(-total) |&gt; \n  arrange(desc(tf_idf))\n\n\n  \n\n\n\nСнова визуализируем.\n\nauthor_word_tfidf |&gt; \n  arrange(-tf_idf) |&gt; \n  group_by(author) |&gt; \n  top_n(15) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(reorder_within(word, tf_idf, author), tf_idf, fill = author)) +\n  geom_col(show.legend = F) +\n  labs(x = NULL, y = \"tf-idf\") +\n  facet_wrap(~author, scales = \"free\") +\n  scale_x_reordered() +\n  coord_flip()\n\n\n\n\n\n\n\n\nНа таком графике авторы совсем не похожи друг на друга, но будьте осторожны: все то, что их сближает (а это не только служебные части речи!), сюда просто не попало. Можно также заметить, что ряд характерных слов связаны не столько с тематикой, сколько со стилем: чтобы этого избежать, можно использовать лемматизацию или задать правило для замены вручную.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#сравнение-при-помощи-диаграммы-рассеяния",
    "href": "count.html#сравнение-при-помощи-диаграммы-рассеяния",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "10.9 Сравнение при помощи диаграммы рассеяния",
    "text": "10.9 Сравнение при помощи диаграммы рассеяния\nСтолбиковая диаграмма - не единственный способ сравнить частотности слов. Еще один наглядный метод - это диаграмма рассеяния с относительными частотностями. Сначала “расширим” наш тиббл.\n\nspread_freq &lt;- author_word_tf  |&gt; \n  anti_join(stop_words) |&gt; \n  filter(!word %in% other) |&gt; \n  filter(tf &gt; 0.0001) |&gt; \n  select(-n, -total) |&gt; \n  pivot_wider(names_from = author, values_from = tf, values_fill = 0) \n\nspread_freq\n\n\n  \n\n\n\nТеперь “удлиним”.\n\nlong_freq &lt;- spread_freq |&gt; \n  pivot_longer(c(\"Hume\", \"Locke\"), names_to = \"author\", values_to = \"tf\")\n\nlong_freq\n\n\n  \n\n\n\nМожно визуализировать.\n\nlibrary(scales)\n\nlong_freq |&gt; \n  ggplot(aes(x = tf, y = Berkeley)) +\n  geom_abline(color = \"grey40\", lty = 2) +\n  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, \n              height = 0.3, color = \"darkblue\") +\n  geom_text(aes(label = word), check_overlap = TRUE, \n            vjust = 1.5, color = \"grey30\") +\n  scale_x_log10(labels = percent_format()) +\n  scale_y_log10(labels = percent_format()) +\n  facet_wrap(~author, ncol = 2) +\n  theme(legend.position = \"none\") +\n  theme_minimal() +\n  labs(y = \"Berkeley\", x = NULL)\n\n\n\n\n\n\n\n\nСлова, расположенные ближе к линии, примерно одинаково представлены в обоих текстах (например, “ум” и “душа” у Беркли и Локка); слова, которые находятся дальше от линии, более свойственны одному из двух авторов: например, у Беркли чаще встречается “абстрактный” по сравнению с первой книгой Локка, а у Локка чаще используется слово “простой”.\n\n\n\n\nBaayen, R. H. 2008. Analyzing Linguistic Data: A Practical Introduction to Statistics using R. Cambridge University Press.\n\n\nSavoy, Jacques. 2020. Machine Learning Methods for Stylometry. Springer.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  },
  {
    "objectID": "count.html#footnotes",
    "href": "count.html#footnotes",
    "title": "10  Распределения слов и анализ частотностей",
    "section": "",
    "text": "https://www.gutenberg.org/cache/epub/4723/pg4723.txt↩︎",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Распределения слов и анализ частотностей</span>"
    ]
  }
]